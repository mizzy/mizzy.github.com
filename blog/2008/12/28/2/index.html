<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>ScalableStorageWithOSS00 - Gosuke Miyashita</title>
<link rel="stylesheet" href="/css/fonts.css" type="text/css" charset="utf-8">
<link rel="stylesheet/tass" type="text/x-tass" href="/css/style.tass"/>
<script type="text/javascript" src="/js/tass.js"></script>
<link href="/atom.xml" rel="alternate" title="Gosuke Miyashita" type="application/atom+xml">
</head>
<body>
<h1 class="site-title"><a href="/">Gosuke Miyashita</a></h1>

<div class="content autopagerize_page_element">

  <time>Dec 28<span>th</span>, 2008</time>
  <h1 class="entry-title"><a href="/blog/2008/12/28/2">ScalableStorageWithOSS00</a></h1>

  <div class="content">
    <p><a href="http://trac.mizzy.org/public/wiki/HowToBuildAScalableStorageSystemWithOSS">TLUG Meeting 2008/09 で発表した How to build a scalable storage system with OSS</a> なんですが、発表では概要しか触れてなくて、じゃあいったいどうやって構築するのよ、という部分が全然ないので、ぼちぼちこのブログで書いていくことにします。</p>

<p>で、スケーラブルというだけだと曖昧なので、以下のような要件を満たすものを、スケーラブルなストレージと想定することにします。</p>

<ul>
<li>特殊なソフトウェアを必要とせずに、OS からファイルシステムとしてマウントできるもの。なので MogileFS、Hadoop Distributed File System、Google File System 等は対象外。（FUSE 使えばやれないこともないけど…）</li>
<li>容量をオンラインでダイナミックに追加できる。</li>
<li>SPOF がない。</li>
<li>複数のサーバから同時にマウントすることができる。</li>
<li>物理的に I/O を柔軟に分散することができる。</li>
<li>無駄な空きスペースができにくい。</li>
</ul>

<p>で、こういったストレージを、高価なハードウェアを買わずに、オープンソースソフトウェアだけで構築することができないか、と考えて、こんな感じで実現できそうだなあー、というのを発表したのが TLUG でのプレゼンの内容。このプレゼンで出てきたキーワードとその概要をおさらいすると、以下のような感じ。</p>

<ul>
<li><a href="http://sources.redhat.com/cluster/cman/">cman</a>

<ul>
<li>Cluster Manager</li>
<li>Red Hat Cluster Suite の一コンポーネント</li>
<li>クラスタのメンバーシップ管理とノード間のメッセージング</li>
<li>以下に出てくる、CLVM や GFS2 を使うために必要</li>
</ul></li>
<li><a href="http://sources.redhat.com/cluster/clvm/">CLVM</a>

<ul>
<li>Cluster Logical Volume Manager</li>
<li>LVM2 のクラスタ版</li>
<li>LVM2 のメタデータをクラスタノード間で自動的にシェアする</li>
<li>CLVM で作成された論理ボリュームは、すべてのクラスタノードから参照できる</li>
</ul></li>
<li><a href="http://sourceware.org/cluster/gnbd/">GNBD</a>

<ul>
<li>Global Network Block Device</li>
<li>TCP/IP ネットワーク経由でのブロックデバイスアクセス</li>
<li>iSCSI と同じようなもの</li>
<li>iSCSI との違いは、フェンシング機能を持っていること（フェンシングについては機会があれば説明します）</li>
</ul></li>
<li><a href="http://sources.redhat.com/cluster/gfs/">GFS2</a>

<ul>
<li>Global File System 2</li>
<li>クラスタファイルシステム</li>
<li>複数ノードから同時にマウントしてアクセスすることが可能</li>
<li>cman の DLM(Distributed Lock Manager) を利用して排他制御し、ファイルの整合性を保つ</li>
<li>OCFS(Oracle Cluster File System) なんかも同類</li>
</ul></li>
<li><a href="http://www.drbd.org/">DRBD</a>

<ul>
<li>Ditributed Replicated Block Device</li>
<li>要するにネットワーク越しの RAID1</li>
</ul></li>
<li><a href="http://www.redhat.com/docs/manuals/csgfs/browse/4.6/DM_Multipath/index.html">DM-MP</a>

<ul>
<li>Device-Mapper Multipath</li>
<li>複数の I/O 経路を仮想的にひとつに見せかけることができる</li>
<li>Active/Passive、Active/Active どちらでも対応可</li>
</ul></li>
</ul>

<p><a href="http://www.slideshare.net/mizzy/how-to-build-a-scalable-storage-system-at-tlug-meeting-20080913-presentation">TLUG での発表資料</a> では、それぞれを図で説明していたり、これらをどう組み合わせて利用するのかを説明しているので、ご参照ください。</p>

<p>で、これらを組み合わせて構築したストレージがとりあえず動くことは確認できたのだけど、実用に耐えうるかどうかは謎。特に以下の点が気になるところ。</p>

<ul>
<li>協調動作するコンポーネントが多くて、トラブルが起こりやすそう。</li>
<li>安定性。</li>
<li>パフォーマンス。</li>
<li>ストレージとなるサーバを追加して容量を増やした場合のオーバーヘッドの増加具合。</li>
</ul>

<p>なので、今後実際に使うかどうかはまだ決めかねてるのですが、一通り動かせるところまでは試してみたので、次回から実際の構築手順を書いていこうと思います。</p>

<h1>関連エントリ</h1>

<ul>
<li>[wiki:ScalableStorageWithOSS01 OSS だけでスケーラブルなストレージを安価に構築する方法 #1]</li>
<li>[wiki:ScalableStorageWithOSS02 OSS だけでスケーラブルなストレージを安価に構築する方法 #2]</li>
<li>[wiki:ScalableStorageWithOSS03 OSS だけでスケーラブルなストレージを安価に構築する方法 #3]</li>
<li>[wiki:ScalableStorageWithOSS04 OSS だけでスケーラブルなストレージを安価に構築する方法 #4]</li>
<li>[wiki:ScalableStorageWithOSS05 OSS だけでスケーラブルなストレージを安価に構築する方法 #5]</li>
</ul>

  </div>


  <div class="pagination">
    
    <a href="/blog/2008/12/28/1" rel="next">next post</a>
    
    
    
    <a href="/blog/2008/12/28/3">previous post</a>
    
  </div>

</div>

<div class="autopagerize_insert_before"></div>

</body>
</html>
