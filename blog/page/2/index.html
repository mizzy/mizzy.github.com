
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Gosuke Miyashita</title>
  <meta name="author" content="Gosuke Miyashita">

  
  <meta name="description" content="FFFTP開発終了で大騒ぎしている人たちへ にて、 SSL証明書がまともなものでないと接続時にエラーが出るのですが、ロリポップなんかだと
このエラーを無視するように公式ドキュメントに書いてあるので、かなり悪質です。 と書かれていますので、これについて説明させて頂きます。 この方が指摘されているのは &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mizzy.org/blog/page/2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Gosuke Miyashita" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-53984-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Gosuke Miyashita</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mizzy.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/09/03/SSLCertOfLolipop/">SSLCertOfLolipop</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-09-03T01:41:19+09:00" pubdate>Sep 3<span>rd</span>, 2011</time>
        
         | <a href="/blog/2011/09/03/SSLCertOfLolipop/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://blog2.or6.jp/ftpisdead">FFFTP開発終了で大騒ぎしている人たちへ</a> にて、</p>

<pre><code>SSL証明書がまともなものでないと接続時にエラーが出るのですが、ロリポップなんかだと
このエラーを無視するように公式ドキュメントに書いてあるので、かなり悪質です。
</code></pre>

<p>と書かれていますので、これについて説明させて頂きます。</p>

<p>この方が指摘されているのは、<del><a href="http://lolipop.jp/manual/hp/w-fz/">Win FileZillaの設定 / ホームページ / マニュアル - ロリポップ！</a> </del>(FileZilla非推奨のため現在は削除されています)の中の、</p>

<pre><code> 証明書の確認を行います。『今後もこの証明書を常に信用する(A)』にチェックを入れて、『OK』をクリックします。
</code></pre>

<p>という部分だと思われるのですが、確かに、無条件で信用するにチェックを入れるようお客様に指示するのは大変良くないですね。</p>

<p>ロリポップでは <a href="http://www.digicert.ne.jp/">DigiCert Inc社</a> によって発行されている証明書を利用しているのですが、Filezillaでは警告が出てしまうようです。</p>

<p>調べてみたところ、FilezillaはルートCAの証明書を保持しておらず、どのような証明書であっても、ユーザが「信用する」にチェックを入れなければ警告が出る仕様となっているようです。</p>

<p><a href="http://forum.filezilla-project.org/viewtopic.php?f=2&amp;t=20767">how to install root CA certificate on Filezilla</a></p>

<p>OR6 blog 様のご指摘により、このような証明書の検証をきちんと行っていないソフトウェアをお客様に推奨すべきではないと判断いたしましたので、Windows/Mac版ともに存在し、証明書の検証をきちんと行っている <a href="http://cyberduck.ch/">Cyberduck</a> を推奨するよう、マニュアルを変更させて頂くことになりました。</p>

<p>また、蛇足ですが、ロリポップの <a href="http://lolipop.jp/service/plan-chicappa/">チカッパプラン</a> では SSH サービスを提供していますので、FTPS の代わりに SCP/SFTP もご利用頂けます。</p>

<p>OR6 blog 様、この度はご指摘誠にありがとうございました。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/08/18/MaglicaInternalCloudTool/">MaglicaInternalCloudTool</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-08-18T17:25:28+09:00" pubdate>Aug 18<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/08/18/MaglicaInternalCloudTool/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Overview</h1>

<p><a href="https://github.com/mizzy/maglica">Maglica</a> is a Python library and command-line tool for an internal cloud. (This tool is very primitive beta now.)</p>

<p>This is very simple and based on libvirt, virt-clone and zeromq (for RPC).</p>

<p>The name &#8220;Maglica&#8221; is derived from a Bosnian word that means &#8220;Nebula.&#8221;</p>

<p>I&#8217;m developing this tool because other internal cloud tools(CloudStack, OpenStack, Eucalyptus and so on) are so complicated for internal use.I need a simple tool.</p>

<hr />

<h1>Architecture of Maglica</h1>

<p>Maglica has four components.</p>

<ol>
<li>Library</li>
<li>CLI</li>
<li>Client worker</li>
<li>Host workers</li>
</ol>


<p>Maglica library is a main component of Maglica.Maglica CLI calls the library
to do the jobs.The library talks to libvirtd on other hosts directly to get
virtual machines information.</p>

<p>Maglica client worker is running on the same host on which CLI runs.
Client worker binds zeromq PUB socket to tcp://<em>:5555 and REP socket
to tcp://</em>:5556.</p>

<p>Client worker recieves requests from library through REP socket and throws
request to host workers through PUB socket.Also REP socket recives job results
from host workers.</p>

<p>Host workers are running on hosts which virtual machines are running on.</p>

<p>Host workers connect to the PUB socket of a client worker to receive job
requests and the REP socket of a client worker to throw job results.</p>

<p>[[Image(http://mizzy.org/img/maglica_architecture.jpg)]]</p>

<hr />

<h1>How to use Maglica</h1>

<p>You must setup libvirtd running on host machines and accessible through
tcp port. (See http://libvirt.org/remote.html)</p>

<p>Clone Maglica on a host machine and run the host worker.</p>

<pre><code># git clone git://github.com/mizzy/maglica.git
# cd maglica
# cp etc/maglica.conf.example etc/maglica.conf
</code></pre>

<p>Edit etc/maglica.conf that points to the correct client worker host and port.</p>

<pre><code># ./scripts/maglica_host_worker
</code></pre>

<p>Clone Maglica on a client machine.</p>

<pre><code># git clone git://github.com/mizzy/maglica.git
# cd maglica
# cp etc/maglica.conf.example etc/maglica.conf
</code></pre>

<p>Edit etc/maglica.conf that points to host machines.</p>

<p>Run the client worker.</p>

<pre><code># ./scripts/maglica_client_worker
</code></pre>

<p>Run maglica command to list up &#8220;original images&#8221;(which name is end with
the string &#8220;oroginal&#8221;).</p>

<pre><code># PYTHONPATH=. ./scripts/maglica image list
Name                                     Host
---------------------------------------------------------
SL6.0-x86_64.original                    host0.example.jp  
SL6.1-x86_64.original                    host0.example.jp  
SL6.0-x86_64.original                    host1.example.jp  
SL6.1-x86_64.original                    host1.example.jp  
</code></pre>

<p>Run maclica command to clone a virtual machine image.</p>

<pre><code># ./scripts/maglica vm clone --image=SL6.1-x86_64.original --hostname=vm0.example.jp
</code></pre>

<p>This command clones the image on a host and rewrites network setting of the image with libguestfs.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/24/HowToGetGraphiteWorkingOnScientificLinux6/">HowToGetGraphiteWorkingOnScientificLinux6</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-24T23:18:15+09:00" pubdate>Jul 24<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/24/HowToGetGraphiteWorkingOnScientificLinux6/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I found a interest tool, <a href="http://graphite.wikidot.com/">Graphite</a> when I was exploring https://github.com/etsy .(<a href="http://graphite.wikidot.com/screen-shots">Screen Shots of Graphite</a>.)</p>

<h1>Install Carbon</h1>

<p><a href="http://graphite.wikidot.com/carbon">Carbon</a> is a backend storage application for Graphite.</p>

<pre><code># wget http://launchpad.net/graphite/1.0/0.9.8/+download/carbon-0.9.8.tar.gz
# tar zxvf carbon-0.9.8.tar.gz
# pushd carbon-0.9.8
# python setup.py install
# popd
</code></pre>

<h1>Install Whisper</h1>

<p><a href="http://graphite.wikidot.com/whisper">Whisper</a> is an alternate to RRD.</p>

<pre><code># wget http://launchpad.net/graphite/1.0/0.9.8/+download/whisper-0.9.8.tar.gz
# tar zxvf whisper-0.9.8.tar.gz
# pushd whisper-0.9.8
# python setup.py install
# popd
</code></pre>

<h1>Install Graphite</h1>

<pre><code># wget http://launchpad.net/graphite/1.0/0.9.8/+download/graphite-web-0.9.8.tar.gz
# tar zxvf graphite-web-0.9.8.tar.gz
# pushd graphite-web-0.9.8      
</code></pre>

<p>Run check-dependencies.py.</p>

<pre><code># ./check-dependencies.py 
[FATAL] Unable to import the 'cairo' module, do you have pycairo installed for python 2.6.5?
[FATAL] Unable to import the 'django' module, do you have Django installed for python 2.6.5?
[WARNING] Unable to import the 'mod_python' module, do you have mod_python installed for python 2.6.5?
This means you will only be able to run graphite in the development server mode, which is not
recommended for production use.
[WARNING]
Unable to import the 'memcache' module, do you have python-memcached installed for python 2.6.5?
This feature is not required but greatly improves performance.

[WARNING]
Unable to import the 'ldap' module, do you have python-ldap installed for python 2.6.5?
Without python-ldap, you will not be able to use LDAP authentication in the graphite webapp.

[WARNING]
Unable to import the 'twisted' package, do you have Twisted installed for python 2.6.5?
Without Twisted, you cannot run carbon on this server.
[WARNING]
Unable to import the 'txamqp' module, this is required if you want to use AMQP.
Note that txamqp requires python 2.5 or greater.
2 necessary dependencies not met. Graphite will not function until these dependencies are fulfilled.
5 optional dependencies not met. Please consider the warning messages before proceeding.
</code></pre>

<p>I use a development server included in Graphite, so mod_python is not needed.</p>

<p>Install packages other than mod_python.</p>

<pre><code># yum install pycairo
# rpm -ivh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-5.noarch.rpm
# yum install Django python-twisted python-memcached python-ldap
# yum install python-setuptools gcc python-devel
# easy_install txamqp
</code></pre>

<p>You need bitmap fonts, so intall it.</p>

<pre><code># yum install bitmap-console-fonts
</code></pre>

<p>Install Graphite and setup it.</p>

<pre><code># python setup.py install
# python /opt/graphite/webapp/graphite/manage.py syncdb
# pushd /opt/graphite/conf
# cp carbon.conf.example carbon.conf
# cp storage-schemas.conf.example storage-schemas.conf
# cp dashboard.conf.example dashboard.conf
</code></pre>

<p>Edit dashborad.conf and uncomment these.</p>

<pre><code>[ui]
default_graph_width = 400
default_graph_height = 250
automatic_variants = true
refresh_interval = 60
</code></pre>

<p>Start Carbon.</p>

<pre><code># /opt/graphite/bin/carbon-cache.py start
</code></pre>

<p>Start example-client included in Graphite source code to send load average data to Carbon.</p>

<pre><code># popd
# python ./examples/example-client.py
</code></pre>

<p>Start a develepment server of Graphite.</p>

<pre><code># /opt/graphite/bin/run-graphite-devel-server.py /opt/graphite  
</code></pre>

<p>Access to port 8080 of this server and you&#8217;ll see the screen of Graphite.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/17/HowDotCloudLazyCopyImplementsCopyOnWrite/">HowDotCloudLazyCopyImplementsCopyOnWrite</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-17T23:44:34+09:00" pubdate>Jul 17<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/17/HowDotCloudLazyCopyImplementsCopyOnWrite/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://github.com/dotcloud/lazycopy">dotcloud/lazycopy</a> is a copy-on-write version of cp.It&#8217;s based on <a href="http://aufs.sourceforge.net/">aufs</a>.</p>

<p>Scientific Linux 5 has aufs rpm on its base repo.So I tried aufs and lazycopy on SL5.CentOS and SL6 don&#8217;t have aufs rpm.</p>

<p>I created source directories and files in them first.</p>

<pre><code># mkdir /tmp/source0
# mkdir /tmp/source1
# mkdir /tmp/source2
# echo source0 &gt; /tmp/source0/0
# echo source1 &gt; /tmp/source1/1
# echo source2 &gt; /tmp/source2/2
</code></pre>

<p>And copied these directories to /tmp/dest with lazycopy command.</p>

<pre><code># lazycopy /tmp/source0 /tmp/source1 /tmp/source2 /tmp/dest
['/tmp/source0', '/tmp/source1', '/tmp/source2'] -&gt; /tmp/dest
</code></pre>

<p>Confirmed that three files wiere there and the content of one of the files.</p>

<pre><code># ls /tmp/dest/
0  1  2
# cat /tmp/dest/0
source0
</code></pre>

<p>Changed the content of /tmp/dest/0 and confirmed that /tmp/source0/0 was not changed.</p>

<pre><code># echo dest &gt; /tmp/dest/0 
# cat /tmp/dest/0 
dest
# cat /tmp/source0/0 
source0
</code></pre>

<p>Lazycopy implements copy-on-write by mounting directories with aufs like this.</p>

<pre><code># mount
...
none on /tmp/dest type aufs (rw,br:/tmp/dest/.aufs/0=rw:/tmp/source0=ro:/tmp/source1=ro:/tmp/source2=ro)
</code></pre>

<p>Lazycopy creates .aufs/0 directory in the destination directory if it doesn&#8217;t exist and mounts it with rw mode as one of the aufs branch.Other source directories are mounted with ro mode, so files in these directories will not be changed.</p>

<p>Changed files and newly created files are saved under /tmp/dest/.aufs/0 directory.So you can see the directory structures like this after unmounting /tmp/dest.</p>

<pre><code># touch /tmp/dest/3
# umount /tmp/dest
# tree -a /tmp/dest
/tmp/dest
`-- .aufs
    `-- 0
        |-- .wh..wh..tmp
        |-- .wh..wh.aufs
        |-- .wh..wh.plnk
        |-- 0
        `-- 3
</code></pre>

<p>So if you unmount /tmp/dest directory and run lazycopy with same options again, you can see the changed files and created files again.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/17/LinuxContainer00/">LinuxContainer00</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-17T16:33:08+09:00" pubdate>Jul 17<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/17/LinuxContainer00/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Make and install lxc rpm packages</h1>

<p>The spec file for lxc is included in lxc source code.So you can make rpm packages of lxc easily.</p>

<pre><code># yum -y update kernel
# reboot
# yum -y install rpm-build libcap-devel docbook-utils kernel-devel gcc make
# wget http://lxc.sourceforge.net/download/lxc/lxc-0.7.4.2.tar.gz
# tar zxvf lxc-0.7.4.2.tar.gz
# mkdir -p ~/rpmbuild/SOURCES
# cp lxc-0.7.4.2.tar.gz ~/rpmbuild/SOURCES
# chown root:root lxc-0.7.4.2/lxc.spec
# rpmbuild -ba lxc-0.7.4.2/lxc.spec --define 'ksrc /usr/src/kernels/`uname -r`'
# rpm -Uvh ~/rpmbuild/RPMS/x86_64/lxc-0.7.4.2-1.x86_64.rpm
</code></pre>

<hr />

<h1>Check whether this os is lxc ready or not</h1>

<p>All statuses should be &#8220;enabled&#8221;.</p>

<pre><code># lxc-checkconfig 
Kernel config /proc/config.gz not found, looking in other places...
Found kernel config file /boot/config-2.6.32-131.2.1.el6.x86_64
--- Namespaces ---
Namespaces: enabled
Utsname namespace: enabled
Ipc namespace: enabled
Pid namespace: enabled
User namespace: enabled
Network namespace: enabled
Multiple /dev/pts instances: enabled

--- Control groups ---
Cgroup: enabled
Cgroup namespace: enabled
Cgroup device: enabled
Cgroup sched: enabled
Cgroup cpu account: enabled
Cgroup memory controller: enabled
Cgroup cpuset: enabled

--- Misc ---
Veth pair device: enabled
Macvlan: enabled
Vlan: enabled
File capabilities: enabled
enabled
</code></pre>

<hr />

<h1>Quick Start</h1>

<p>In the man of lxc, you can get how to start lxc quickly.</p>

<pre><code>QUICK START
       You are in a hurry, and you don’t want to read this man page. Ok, with-
       out warranty, here are the commands to launch a  shell  inside  a  con-
       tainer   with   a  predefined  configuration  template,  it  may  work.
       /usr/bin/lxc-execute -n foo -f /usr/share/doc/lxc/examples/
       lxc-macvlan.conf /bin/bash
</code></pre>

<p>But before running lxc-execute, you should mount croup.</p>

<pre><code># mount -t cgroup cgroup /cgroup
# /usr/bin/lxc-execute -n foo -f /usr/share/doc/lxc/examples/lxc-macvlan.conf /bin/bash
</code></pre>

<p>In the container, processes are like this.</p>

<pre><code># ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 10:54 ttyS0    00:00:00 /usr/lib64/lxc/lxc-init -- /bin/
root         2     1  0 10:54 ttyS0    00:00:00 /bin/bash
root        11     2  0 10:55 ttyS0    00:00:00 ps -ef
</code></pre>

<p>You can also see the processes in the container from the outside of the container.</p>

<pre><code># lxc-ps --name=foo
CONTAINER    PID TTY          TIME CMD
foo         1654 ttyS0    00:00:00 lxc-init
foo         1656 ttyS0    00:00:00 bash
</code></pre>

<p>The sample lxc conf is like this.</p>

<pre><code># cat /usr/share/doc/lxc/examples/lxc-macvlan.conf 
# Container with network virtualized using the macvlan device driver
lxc.utsname = alpha
lxc.network.type = macvlan
lxc.network.flags = up
lxc.network.link = eth0
lxc.network.hwaddr = 4a:49:43:49:79:bd
lxc.network.ipv4 = 1.2.3.4/24
lxc.network.ipv6 = 2003:db8:1:0:214:1234:fe0b:3596
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/12/DotCloudCliSourceCodeReading00/">DotCloudCliSourceCodeReading00</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-12T01:43:32+09:00" pubdate>Jul 12<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/12/DotCloudCliSourceCodeReading00/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I wonder how &#8220;dotcloud push&#8221; acts, especially on uploading files, so I read the <a href="http://pypi.python.org/pypi/dotcloud.cli">dotcloud.cli source code</a>.</p>

<p>If you execute &#8220;dotcloud push&#8221; with &#8211;export option, you&#8217;ll get the response like this.</p>

<pre><code>$ dotcloud --export push helloworldapp
{
    "data": [
        [
            "upload", 
            ".", 
            "ssh://dotcloud@uploader.dotcloud.com:21122/helloworldapp", 
            {
                "rsync": {
                    "excludes": [
                        "*.pyc", 
                        ".git", 
                        ".hg"
                    ]
                }, 
                "check": true
            }
        ], 
        [
            "call", 
            "deploy helloworldapp.default"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>So you know that dotcloud command will run Remote.upload() method.(See DotCloudCliBehaviorOverView.)</p>

<p>You can see the upload() method in dotcloud/cli/remote.py.</p>

<pre><code>#!python
    def upload(self, local_dir, destination, args):
        if args.get('check'):
            local_dir = self.check_pushdir(local_dir)
        self.info('# upload {0} {1}'.format(local_dir, destination))
        if os.path.isdir(os.path.join(local_dir, '.hg')):
            return self.hg(local_dir, destination, args.get('hg', {}))
        if os.path.isdir(os.path.join(local_dir, '.git')):
            return self.git(local_dir, destination, args.get('git', {}))
        return self.rsync(local_dir, destination, args.get('rsync', {}))
</code></pre>

<p>If you have .hg directory, dotcloud command runs self.hg().If you have .git directory, dotcloud command runs self.git().Otherwise dotcloud command runs self.rsync().</p>

<p>You can see these methods in the same file.</p>

<pre><code>#!python
    def rsync(self, local_dir, destination, args):
        self.info('# rsync')
        excludes = args.get('excludes')
        url = utils.parse_url(destination)
        ssh = ' '.join(self._ssh_options)
        ssh += ' -p {0}'.format(url['port'])
        if not os.path.isfile(local_dir) and not local_dir.endswith('/'):
            local_dir += '/'
        rsync = (
                    'rsync', '-lpthrvz', '--delete', '--safe-links',
                ) + tuple('--exclude={0}'.format(e) for e in excludes) + (
                    '-e', ssh, local_dir,
                    '{user}@{host}:{dest}/'.format(user=url['user'],
                        host=url['host'], dest=url['path'])
                )
        try:
            ret = subprocess.call(rsync, close_fds=True)
            if ret != 0:
                self.warning_ssh()
            return ret
        except OSError:
            self.die('rsync')

    def hg(self, local_dir, destination, args):
        self.info('# hg')
        with utils.cd(local_dir):
            try:
                ssh = ' '.join(self._ssh_options)
                args = ('hg', 'push', '--ssh', ssh, '-f', destination)
                ret = subprocess.call(args, close_fds=True)
                if ret != 0:
                    self.warning_ssh()
                return ret
            except OSError:
                self.die('hg')

    def git(self, local_dir, destination, args):
        self.info('# git')
        with utils.cd(local_dir):
            try:
                os.environ['GIT_SSH'] = '__dotcloud_git_ssh'
                os.environ['DOTCLOUD_SSH_KEY'] = config.CONFIG_KEY
                ret = subprocess.call(('git', 'push', '-f', '--all',
                    destination), close_fds=True)
                if ret != 0:
                    self.warning_ssh()
                return ret
            except OSError:
                self.die('git')
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/10/DotCloudCliBehaviorOverView/">DotCloudCliBehaviorOverView</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-10T20:20:07+09:00" pubdate>Jul 10<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/10/DotCloudCliBehaviorOverView/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Now I&#8217;m investigating the behavior of <a href="http://pypi.python.org/pypi/dotcloud.cli">dotcloud.cli</a>.I will write down the things I found.</p>

<p>With &#8211;export option, you can see the raw response of dotcloud API.</p>

<p>For example, if you execute dotcloud command for the first time with &#8211;export option, you will see the result like this.</p>

<pre><code>$ dotcloud --export
Warning: /Users/miya/.dotcloud/dotcloud.conf does not exist.
Enter your api key (You can find it at http://www.dotcloud.com/account/settings): XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
{
    "data": [
        [
            "key", 
            "-----BEGIN DSA PRIVATE KEY-----\nXXXXXXXXXX...\n-----END DSA PRIVATE KEY-----\n"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>If &#8216;&#8220;type&#8221;: &#8220;cmd&#8221;&#8217; is given, dotcloud command call the appropriate method.In this case, key() method of Remote class in dotcloud/cli/remote.py will be called and SSH key string will be written to ~/.dotcloud/dotcloud.key.</p>

<p>Which method is called are defined in dotcloud/cli/cli.py like this.</p>

<pre><code>#!python
def run_remote(cmd):
    r = remote.Remote()
    handlers = {
            'set_url': r.set_url,
            'run': r.run,
            'script': r.run_script,
            'sftp': r.sftp,
            'pull': r.pull,
            'push': r.push,
            'rsync': r.rsync,
            'git': r.git,
            'hg': r.hg,
            'upload': r.upload,
            'loop': lambda *x: run_loop(*x),
            'confirm': local.confirm,
            'call': lambda x: run_command(x, True),
            'echo': lambda x: sys.stdout.write('{0}\n'.format(x)),
            'echo_error': lambda x: sys.stderr.write('{0}\n'.format(x)),
            'set_verbose': r.set_verbose,
            'key': r.key
            }
</code></pre>

<p>Let&#8217;s see another command option.</p>

<pre><code>$ dotcloud --export create helloworldapp
{
    "data": "Created repos \"helloworldapp\"", 
    "type": "success"
}
</code></pre>

<p>In this case, type is not cmd, so dotcloud command will do nothing anymore.</p>

<p>In the case of option push, API response is like this.</p>

<pre><code>$ dotcloud --export push helloworldapp
{
    "data": [
        [
            "upload", 
            ".", 
            "ssh://dotcloud@uploader.dotcloud.com:21122/helloworldapp", 
            {
                "rsync": {
                    "excludes": [
                        "*.pyc", 
                        ".git", 
                        ".hg"
                    ]
                }, 
                "check": true
            }
        ], 
        [
            "call", 
            "deploy helloworldapp.default"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>&#8220;type&#8221; is &#8220;cmd&#8221;, so Remote.upload() will be called and run_command(&#8216;deploy helloworldapp.default&#8217;, True) will be called.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/10/ProPuppet00/">ProPuppet00</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-10T10:12:32+09:00" pubdate>Jul 10<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/10/ProPuppet00/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>!html</h1>

<pre><code>&lt;img src="http://www.apress.com/media/catalog/product/cache/9/image/9df78eab33525d08d6e5fb8d27136e95/A/9/A9781430230571-3d_11.png" /&gt;
</code></pre>

<p>[wiki:ManagingInfrastructureWithPuppet Managing Infrastructure With Puppet] の中でも少しだけ触れた、<a href="http://www.apress.com/9781430230571">Pro Puppet</a> についてメモ。</p>

<p>こちらは内容盛りだくさんで、Puppet をヘビーに使っている人でも読みごたえがあるんじゃないかと。たとえば、バージョン違いの Puppet を混在させる方法、といったところもフォローされていたり。</p>

<p>ただし、Puppet や、Git といった周辺ツールのインストール方法まで詳細に書かれていて、この辺は自分には必要ないなー、と思ったりもした。</p>

<p>とはいえ、最近の Puppet 動向を追いかけていない自分には、とても有意義な内容が多かったので、その辺についてメモしてみる。</p>

<p>（あんまり書きすぎると出版社の人に怒られそうなんで、さらっと。あと、量が多くなりそうなので、何度かにわけて書く。）</p>

<hr />

<h1>モジュール化について</h1>

<p>Puppet 解説書なんで、当然のことながらマニフェストの書き方が最初の方に出てくるんだけど、本書ではいきなりモジュールを作成するところから始めていて驚いた。</p>

<p>このことで思ったのは、マニフェストはとにかく全部モジュール化しちゃう、というのがベストプラクティスなのかもしれない、ということ。</p>

<p><a href="http://gihyo.jp/admin/serial/01/puppet/0008">第8回　Puppet実践テクニック（その3）</a> の中で書いているデータファイルの構造は、modules ディレクトリはあるものの、すべてをモジュール化することは想定していないため、menifests ディレクトリの下に、クラス毎にマニフェストファイルを置いている。</p>

<p>このやり方だと、dist の下にもクラス毎にスタティックなファイルがあったり、templates の下にもクラス毎にテンプレートがあったりで、同じクラスで利用するマニフェスト、スタティックファイル、テンプレートがばらばらな場所にあって、非常にさがしづらい、といったはめになる。（なので上の記事の内容は今となっては真似しない方がいい。）</p>

<p>これがすべてモジュール化されていると、</p>

<pre><code>modules/
  |
  +--- ssh/
  |     |
  |     +--- files/
  |     |
  |     +--- manifets/
  |     |
  |     +--- templates/
  |
  +--- postfix/
        |
        +--- files/
        |
        +--- manifests/
        |
        +--- templates/
</code></pre>

<p>といった形で、関連するマニフェスト、スタティックファイル、テンプレートが1カ所にまとまっていて、非常に見通しが良い。</p>

<hr />

<h1>モジュールのマニフェストファイルとクラスの分け方</h1>

<p>本書では以下のようにマニフェストファイルをわけている。(ssh モジュールの例。ファイル内容は本とは少し変えてる。)</p>

<pre><code>ssh/
 |
 +--- manifets/
        |
        +--- init.pp
        |
        +--- params.pp
        |
        +--- install.pp
        |
        +--- config.pp
        |
        +--- service.pp
</code></pre>

<p>で、各ファイルの内容は以下のような感じ。</p>

<p><em>init.pp</em></p>

<p>ssh モジュールを利用をするために include ssh すると、このファイルが読み込まれ ssh モジュールが適用される。</p>

<p>このファイルでは、さらにモジュール内で細分化されたクラスを include しているだけ。</p>

<pre><code>class ssh {
    include ssh::params, ssh::install, ssh::config, ssh::service
}
</code></pre>

<ul>
<li>params.pp*</li>
</ul>


<p>環境毎に異なるパラメータをまとめるためのファイル。このファイル内にパラメータをまとめることによって、モジュール全体の見通しを良くする。</p>

<pre><code>class ssh::params {
    case $operatingsystem {
        Solaris: {
            $package_name = 'openssh'
            $service_name = 'sshd'
        }
        ...
    }
}
</code></pre>

<p><em>install.pp</em></p>

<p>必要なパッケージをインストールするためのマニフェスト。</p>

<pre><code>class ssh::install {
    package { $ssh::params::package_name: ensure =&gt; installed }
}
</code></pre>

<p><em>config.pp</em></p>

<p>設定ファイル用マニフェスト。</p>

<pre><code>class ssh::config {
    file { '/etc/ssh/sshd_config':
        ensure  =&gt; present,
        source  =&gt; 'puppet:///modules/ssh/sshd_config',
        require =&gt; Class['ssh::install'],
        notify  =&gt; Class['ssh::service'],
    }
}
</code></pre>

<p><em>service.pp</em></p>

<p>サービス用マニフェスト。</p>

<pre><code>class ssh::service {
    ensure  =&gt; running,
    enable  =&gt; true,
    require =&gt; Class['ssh::config'],
}
</code></pre>

<p>こういった形で、ssh モジュールの中でも、ssh::params, ssh::install, ssh::config, ssh::service といった形でクラスを役割毎に細分化して、ファイルもクラス毎に作成、といった形で、一ファイル内の見通しを良くする、というやり方が紹介されている。</p>

<p>もうひとつのポイントは、require や notify で Class 指定していること。（Class を require とかするのって以前のバージョンからできるんだっけ？）</p>

<p>たとえば、sercice.pp では、</p>

<pre><code>require =&gt; Class['ssh::config'],
</code></pre>

<p>といった指定があるが、これは以下のように、Class ではなく File でも指定できる。</p>

<pre><code>require =&gt; File['/etc/ssh/sshd_config'],
</code></pre>

<p>ひとつの設定ファイルから構成されているようなモジュールであればこれでも良いが、複数の設定ファイルから構成されるようなモジュールだと、変更に対して脆くなってしまう。例えば postfix モジュールで考えてみる。</p>

<p>最初は main.cf のみ Puppet で管理して、他の設定ファイルはデフォルトのまま、という状態を想定すると、マニフェストは以下のようになる。</p>

<pre><code>class postfix::config {
    file { '/etc/postfix/main.cf':
        source =&gt; 'file:///modules/postfix/main.cf',
    }
}

class postfix::service {
    service { 'postfix':
        ensure  =&gt; running,
        enable  =&gt; true,
        require =&gt; File['/etc/postfix/main.cf'],
    }
}
</code></pre>

<p>後から、master.cf もデフォルトのままではなくなったので、Puppet で管理することにすると、マニフェストは以下のように、postfix::config と postfix::service の両方を書き換えることになる。</p>

<pre><code>#!diff
diff --git a/postfix.pp b/postfix.pp
index f55234e..a032d65 100644
--- a/postfix.pp
+++ b/postfix.pp
@@ -2,12 +2,16 @@ class postfix::config {
     file { '/etc/postfix/main.cf':
         source =&gt; 'file:///modules/postfix/main.cf',
     }
+    file { '/etc/postfix/master.cf':
+        source =&gt; 'file:///modules/postfix/master.cf',
+    }
 }

 class postfix::service {
     service { 'postfix':
         ensure  =&gt; running,
         enable  =&gt; true,
-        require =&gt; File['/etc/postfix/main.cf'],
+        require =&gt; [ File['/etc/postfix/main.cf'], File['/etc/postfix/master.cf
     }
 }
</code></pre>

<p>もし、Class を require するようになっていれば、main.cf だけを管理する最初の状態では、マニフェストは</p>

<pre><code>class postfix::config {
    file { '/etc/postfix/main.cf':
        source =&gt; 'file:///modules/postfix/main.cf',
    }
}

class postfix::service {
    service { 'postfix':
        ensure  =&gt; running,
        enable  =&gt; true,
        require =&gt; Class['postfix::config'],
    }
}
</code></pre>

<p>となっており、master.cf を追加した場合、差分は</p>

<pre><code>#!diff
diff --git a/postfix.pp b/postfix.pp
index 9745478..e82621c 100644
--- a/postfix.pp
+++ b/postfix.pp
@@ -2,6 +2,9 @@ class postfix::config {
     file { '/etc/postfix/main.cf':
         source =&gt; 'file:///modules/postfix/main.cf',
     }
+    file { '/etc/postfix/master.cf':
+        source =&gt; 'file:///modules/postfix/master.cf',
+    }
 }

 class postfix::service {
</code></pre>

<p>だけになり、postfix::service はまったく変更する必要がない。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/08/ManagingInfrastructureWithPuppet/">ManagingInfrastructureWithPuppet</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-08T02:36:30+09:00" pubdate>Jul 8<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/08/ManagingInfrastructureWithPuppet/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>!html</h1>

<pre><code>&lt;img src="http://covers.oreilly.com/images/0636920020875/lrg.jpg" /&gt;
</code></pre>

<hr />

<p><a href="http://twitter.com/#!/kdmsnr">@kdmsnr さん</a> の tweet で、<a href="http://oreilly.com/catalog/0636920020875">Managing Infrastructure with Puppet</a> と <a href="http://www.apress.com/9781430230571">Pro Puppet</a> が発売されている事を知ったので読んでみた。まずは Managing Infrastructure with Puppet について。</p>

<p>この本はとても薄い。全体で40ページ強くらい。なので、Puppet をまったく知らない人には全体像を知るためには良い本だけど、既に知っている人には物足りないと思う。</p>

<p>とは言っても、自分は最近の Puppet の動向を追えてないので、その辺の知識不足を補ってくれるような内容もあって、そこは良かった。</p>

<p>また、<a href="http://www.puppetlabs.com/mcollective/introduction/">MCollective</a> についても書かれていて、元々は Puppet Labs とは別なところで開発されていたツールなんで、Puppet とは完全に独立したツールだと思ってたんだけど、Puppet Labs 配下になってから統合が進められたようで、その辺の情報が得られたのがよかった。</p>

<p>以下、内容で気になったところなんかのメモ。</p>

<hr />

<h1>puppet コマンド</h1>

<p>0.25 の次は 2.6 という風にバージョン体系が変わり、それまで puppetmasterd や puppetd といった形で独立していたコマンドが puppet コマンドに統一された、ってことは <a href="http://twitter.com/#!/tnmt">ペパボのイケメンインフラエンジニアの tnmt くん</a> が<a href="http://blog.tnmt.info/2010/11/23/puppet-2-6/">既にブログに書いてある</a> んだけど、それに伴い、コマンドオプションも増えて、やれることが増えてる模様。その中で特に気になったオプションを紹介。</p>

<h2>puppet describe</h2>

<p>リソースタイプのリストを表示してくれたり、指定したリソースタイプに関する説明を表示してくれる。</p>

<p><em>リソースタイプのリスト</em></p>

<pre><code>$ puppet describe --list
These are the types known to puppet:
augeas          - Apply the changes (single or array of changes ...
computer        - Computer object management using DirectorySer ...
cron            - Installs and manages cron jobs
exec            - Executes external commands
file            - Manages local files, including setting owners ...
filebucket      - A repository for backing up files
group           - Manage groups
host            - Installs and manages host entries
k5login         - Manage the `
...
</code></pre>

<p><em>package リソースタイプの説明</em></p>

<pre><code>$ puppet describe package

package
=======
Manage packages.  There is a basic dichotomy in package
support right now:  Some package types (e.g., yum and apt) can
retrieve their own package files, while others (e.g., rpm and sun) cannot. 
For those package formats that cannot retrieve
their own files, you can use the `source` parameter to point to
the correct file.

Puppet will automatically guess the packaging format that you are
using based on the platform you are on, but you can override it
using the `provider` parameter; each provider defines what it
requires in order to function, and you must meet those requirements
to use a given provider.
</code></pre>

<p><strong>Autorequires:</strong> If Puppet is managing the files specified as a package&#8217;s</p>

<pre><code>`adminfile`, `responsefile`, or `source`, the package resource will
autorequire
those files.


Parameters
----------

- **adminfile**
    A file containing package defaults for installing packages.
    This is currently only used on Solaris.  The value will be
    validated according to system rules, which in the case of
    Solaris means that it should either be a fully qualified path
    or it should be in `/var/sadm/install/admin`.

...
</code></pre>

<p>詳しくは puppet describe &#8211;help を参照。</p>

<h2>puppet resource</h2>

<p>コマンドを実行してるマシンの指定されたリソースの状態を、Puppet マニフェストで表示してくれる。</p>

<p><em>host リソースの表示</em></p>

<p>/etc/hosts の内容を Puppet マニフェストで表示。</p>

<pre><code>$ puppet resource host
host { 'localhost.localdomain':
  ensure       =&gt; 'present',
  host_aliases =&gt; ['localhost'],
  ip           =&gt; '127.0.0.1',
  target       =&gt; '/etc/hosts',
}
host { 'localhost6.localdomain6':
  ensure       =&gt; 'present',
  host_aliases =&gt; ['localhost6'],
  ip           =&gt; '::1',
  target       =&gt; '/etc/hosts',
}
</code></pre>

<p><em>service リソースの表示</em></p>

<p>サービスの状態を Puppet マニフェストで表示。</p>

<pre><code>$ puppet resource service
service { 'NetworkManager':
  ensure =&gt; 'stopped',
  enable =&gt; 'false',
}
service { 'acpid':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}
service { 'anacron':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}
service { 'atd':
  ensure =&gt; 'running',
  enable =&gt; 'true',
}
service { 'autofs':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}

...
</code></pre>

<p>既に環境構築されたマシンから Puppet マニフェストの雛形を生成する、とかいった目的に使えそう。</p>

<h2>puppet apply</h2>

<p>Puppet マニフェストを即座に適用できる。</p>

<p><em>test.pp 内のマニフェストを適用する</em></p>

<pre><code>$ puppet apply test.pp
</code></pre>

<p><em>直接マニフェストを文字列で指定するが &#8211;noop つけてるので実際には何もしない</em></p>

<pre><code>$ puppet apply --noop -e 'file { "/etc/passwd": mode =&gt; 600 }'
notice: /Stage[main]//File[/etc/passwd]/mode: current_value 644, should be 600 (noop)
notice: Finished catalog run in 0.05 seconds
</code></pre>

<p>ちょっとした動作確認なんかするのに便利そう。</p>

<hr />

<h1>Parameterized Classes</h1>

<p>define でリソース定義して、呼び出すときにパラメータを渡す、なんてことは以前からできてたけど、2.6 からは Class にパラメータを渡すことができるようになったらしい。</p>

<p>クラス定義はこんな感じ。</p>

<pre><code>class ruby ( $version = '1.8.7') {
    package { 'ruby': ensure =&gt; $version }
}
</code></pre>

<p>Parameterized Classes ではない、従来のクラスの呼び出し方。これだと、Ruby 1.8.7 がインストールされる。</p>

<pre><code>node 'test.example.jp' {
    include ruby
}
</code></pre>

<p>パラメータを渡してやると、Ruby 1.9.2 がインストールされる。</p>

<pre><code>node 'test.example.jp' {
    class { 'ruby': version =&gt; '1.9.2' }
}
</code></pre>

<p>便利そうだけど、従来の include とだいぶ書式が変わるので、混乱しそう。</p>

<hr />

<h1>Puppet Forge</h1>

<p>Puppet モジュールを集めた <a href="http://forge.puppetlabs.com/">Puppet Forge</a> なんてサイトができてたんだね。Puppet 版 CPAN といった感じ。<a href="http://github.com/puppetlabs/puppet-module-tool">puppet-module-tool</a> というコマンドラインツールを使って、モジュールのインストールとかパッケージングとか色々できるようなんだけど、この本には詳しい説明がなかった。Pro Puppet には詳しい説明があったので、Pro Puppet についての感想を書くときに、この辺について少し詳しく書くつもり。</p>

<hr />

<h1>MCollective</h1>

<p>MCollective は、複数のホストに対して同じ処理を並列実行するためのもの。<a href="https://fedorahosted.org/func/">Func</a> とか <a href="http://fabfile.org/">Fabric</a> とか <a href="http://www.capify.org/">Capistrano</a> みたいな位置づけ。</p>

<p>こんな感じで実行できる。（apache2 を再起動する例。）</p>

<pre><code>$ mc-service --with-class apache2 apache2 restart
$ mc-service --with-class apache2 --with-fact architecture=x86_64 apache2 restart
</code></pre>

<p>Puppet の特定のクラスを include してるホストでのみ実行とか、特定の fact (facter によって得られる値) にマッチするホストでのみ実行、という感じで Puppet と連動できる。</p>

<p><a href="http://projects.puppetlabs.com/projects/mcollective-plugins/wiki/AgentPuppetd">Puppetd Agent</a> というプラグインもあって、これを使うと、各ホストの puppet agent の操作を MCollective 経由でできる。つまり、puppet kick(古いバージョンだと puppetrun)の代わりに使える。これの何がうれしいのかというと、puppetrun では特定のクラスを include したホストだけを対象にする、ということをやろうと思うと、LDAP Nodes が必須だった（2.6 でもそうなのかは知らん）けど、このプラグインだとそれが不要になりそう、ってあたりかな。</p>

<p>あと、<a href="http://projects.puppetlabs.com/projects/mcollective-plugins/wiki/ToolPuppetcommander">Puppet Commander</a> というプラグインを使うと、puppet agent の同時起動数を制御できて、puppet master へ同時アクセスが集中しないようにコントロールできるらしい。大量にホストがある環境では良さそうですね。</p>

<p>それから、<a href="http://docs.puppetlabs.com/mcollective/simplerpc/agents.html">MCollective プラグインを書くためのドキュメントへのリンク</a> も載ってた。が本では詳しい説明はなし。</p>

<hr />

<p>というわけで、<a href="http://oreilly.com/catalog/0636920020875">Managing Infrastructure with Puppet</a> について気になった点は以上。次は <a href="http://www.apress.com/9781430230571">Pro Puppet</a> について、気が向いたら書きます。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/06/29/SubsonicThroughApacheProxy/">SubsonicThroughApacheProxy</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-06-29T22:40:54+09:00" pubdate>Jun 29<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/06/29/SubsonicThroughApacheProxy/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://twitter.com/#!/earlcyborg">@earlcyborg くん</a> に教えてもらった <a href="http://www.subsonic.org/pages/index.jsp">Subsonic</a> がよさげなので、家の中に環境作り、Apache mod_proxy 経由でアクセスしようとしたらはまったのでメモ。</p>

<p>結論: ProxyPreserveHost On を入れないとはまる。</p>

<p>最初、</p>

<pre><code>&lt;VirtualHost *&gt;
ServerName subsonic.mizzy.org
ProxyPass / http://192.168.10.14:4040/
ProxyPassReverse / http://192.168.10.14:4040/
&lt;/VirtualHost&gt;
</code></pre>

<p>という設定で http://subsonic.mizzy.org/ にアクセスしたら、http://192.168.10.14:4040/login.view? にリダイレクトされてしまった。Subsonic にホスト名を設定するところもなさそう。そこで、おそらく Host ヘッダに設定されたホストがリダイレクト先になるんじゃなかろうか、と仮説を立てて、以下のように設定してみた。</p>

<pre><code>&lt;VirtualHost *&gt;
ServerName subsonic.mizzy.org
ProxyPreserveHost On
ProxyPass / http://192.168.10.14:4040/
ProxyPassReverse / http://192.168.10.14:4040/
&lt;/VirtualHost&gt;
</code></pre>

<p>これでうまくいった。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/3/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2011/12/20/lunar-eclipse/">Lunar Eclipse</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/20/a-picture-of-geminids/">A Picture of Geminids</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/13/maglica-presentation-at-hatena/">Maglica Presentation At Hatena</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/11/15/octopress-on-heteml/">How to deploy a blog made by Octopress to Heteml</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/11/05/maglica-web/">Maglica Web</a>
      </li>
    
  </ul>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2011 - Gosuke Miyashita -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'mizzyorg';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
