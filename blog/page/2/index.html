
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Gosuke Miyashita</title>
  <meta name="author" content="Gosuke Miyashita">

  
  <meta name="description" content="dotcloud/lazycopy is a copy-on-write version of cp.It&#8217;s based on aufs. Scientific Linux 5 has aufs rpm on its base repo.So I tried aufs and &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mizzy.org/blog/page/2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Gosuke Miyashita" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-53984-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Gosuke Miyashita</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mizzy.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/17/HowDotCloudLazyCopyImplementsCopyOnWrite/">HowDotCloudLazyCopyImplementsCopyOnWrite</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-17T23:44:34+09:00" pubdate>Jul 17<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/17/HowDotCloudLazyCopyImplementsCopyOnWrite/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://github.com/dotcloud/lazycopy">dotcloud/lazycopy</a> is a copy-on-write version of cp.It&#8217;s based on <a href="http://aufs.sourceforge.net/">aufs</a>.</p>

<p>Scientific Linux 5 has aufs rpm on its base repo.So I tried aufs and lazycopy on SL5.CentOS and SL6 don&#8217;t have aufs rpm.</p>

<p>I created source directories and files in them first.</p>

<pre><code># mkdir /tmp/source0
# mkdir /tmp/source1
# mkdir /tmp/source2
# echo source0 &gt; /tmp/source0/0
# echo source1 &gt; /tmp/source1/1
# echo source2 &gt; /tmp/source2/2
</code></pre>

<p>And copied these directories to /tmp/dest with lazycopy command.</p>

<pre><code># lazycopy /tmp/source0 /tmp/source1 /tmp/source2 /tmp/dest
['/tmp/source0', '/tmp/source1', '/tmp/source2'] -&gt; /tmp/dest
</code></pre>

<p>Confirmed that three files wiere there and the content of one of the files.</p>

<pre><code># ls /tmp/dest/
0  1  2
# cat /tmp/dest/0
source0
</code></pre>

<p>Changed the content of /tmp/dest/0 and confirmed that /tmp/source0/0 was not changed.</p>

<pre><code># echo dest &gt; /tmp/dest/0 
# cat /tmp/dest/0 
dest
# cat /tmp/source0/0 
source0
</code></pre>

<p>Lazycopy implements copy-on-write by mounting directories with aufs like this.</p>

<pre><code># mount
...
none on /tmp/dest type aufs (rw,br:/tmp/dest/.aufs/0=rw:/tmp/source0=ro:/tmp/source1=ro:/tmp/source2=ro)
</code></pre>

<p>Lazycopy creates .aufs/0 directory in the destination directory if it doesn&#8217;t exist and mounts it with rw mode as one of the aufs branch.Other source directories are mounted with ro mode, so files in these directories will not be changed.</p>

<p>Changed files and newly created files are saved under /tmp/dest/.aufs/0 directory.So you can see the directory structures like this after unmounting /tmp/dest.</p>

<pre><code># touch /tmp/dest/3
# umount /tmp/dest
# tree -a /tmp/dest
/tmp/dest
`-- .aufs
    `-- 0
        |-- .wh..wh..tmp
        |-- .wh..wh.aufs
        |-- .wh..wh.plnk
        |-- 0
        `-- 3
</code></pre>

<p>So if you unmount /tmp/dest directory and run lazycopy with same options again, you can see the changed files and created files again.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/17/LinuxContainer00/">LinuxContainer00</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-17T16:33:08+09:00" pubdate>Jul 17<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/17/LinuxContainer00/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Make and install lxc rpm packages</h1>

<p>The spec file for lxc is included in lxc source code.So you can make rpm packages of lxc easily.</p>

<pre><code># yum -y update kernel
# reboot
# yum -y install rpm-build libcap-devel docbook-utils kernel-devel gcc make
# wget http://lxc.sourceforge.net/download/lxc/lxc-0.7.4.2.tar.gz
# tar zxvf lxc-0.7.4.2.tar.gz
# mkdir -p ~/rpmbuild/SOURCES
# cp lxc-0.7.4.2.tar.gz ~/rpmbuild/SOURCES
# chown root:root lxc-0.7.4.2/lxc.spec
# rpmbuild -ba lxc-0.7.4.2/lxc.spec --define 'ksrc /usr/src/kernels/`uname -r`'
# rpm -Uvh ~/rpmbuild/RPMS/x86_64/lxc-0.7.4.2-1.x86_64.rpm
</code></pre>

<hr />

<h1>Check whether this os is lxc ready or not</h1>

<p>All statuses should be &#8220;enabled&#8221;.</p>

<pre><code># lxc-checkconfig 
Kernel config /proc/config.gz not found, looking in other places...
Found kernel config file /boot/config-2.6.32-131.2.1.el6.x86_64
--- Namespaces ---
Namespaces: enabled
Utsname namespace: enabled
Ipc namespace: enabled
Pid namespace: enabled
User namespace: enabled
Network namespace: enabled
Multiple /dev/pts instances: enabled

--- Control groups ---
Cgroup: enabled
Cgroup namespace: enabled
Cgroup device: enabled
Cgroup sched: enabled
Cgroup cpu account: enabled
Cgroup memory controller: enabled
Cgroup cpuset: enabled

--- Misc ---
Veth pair device: enabled
Macvlan: enabled
Vlan: enabled
File capabilities: enabled
enabled
</code></pre>

<hr />

<h1>Quick Start</h1>

<p>In the man of lxc, you can get how to start lxc quickly.</p>

<pre><code>QUICK START
       You are in a hurry, and you don’t want to read this man page. Ok, with-
       out warranty, here are the commands to launch a  shell  inside  a  con-
       tainer   with   a  predefined  configuration  template,  it  may  work.
       /usr/bin/lxc-execute -n foo -f /usr/share/doc/lxc/examples/
       lxc-macvlan.conf /bin/bash
</code></pre>

<p>But before running lxc-execute, you should mount croup.</p>

<pre><code># mount -t cgroup cgroup /cgroup
# /usr/bin/lxc-execute -n foo -f /usr/share/doc/lxc/examples/lxc-macvlan.conf /bin/bash
</code></pre>

<p>In the container, processes are like this.</p>

<pre><code># ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 10:54 ttyS0    00:00:00 /usr/lib64/lxc/lxc-init -- /bin/
root         2     1  0 10:54 ttyS0    00:00:00 /bin/bash
root        11     2  0 10:55 ttyS0    00:00:00 ps -ef
</code></pre>

<p>You can also see the processes in the container from the outside of the container.</p>

<pre><code># lxc-ps --name=foo
CONTAINER    PID TTY          TIME CMD
foo         1654 ttyS0    00:00:00 lxc-init
foo         1656 ttyS0    00:00:00 bash
</code></pre>

<p>The sample lxc conf is like this.</p>

<pre><code># cat /usr/share/doc/lxc/examples/lxc-macvlan.conf 
# Container with network virtualized using the macvlan device driver
lxc.utsname = alpha
lxc.network.type = macvlan
lxc.network.flags = up
lxc.network.link = eth0
lxc.network.hwaddr = 4a:49:43:49:79:bd
lxc.network.ipv4 = 1.2.3.4/24
lxc.network.ipv6 = 2003:db8:1:0:214:1234:fe0b:3596
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/12/DotCloudCliSourceCodeReading00/">DotCloudCliSourceCodeReading00</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-12T01:43:32+09:00" pubdate>Jul 12<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/12/DotCloudCliSourceCodeReading00/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I wonder how &#8220;dotcloud push&#8221; acts, especially on uploading files, so I read the <a href="http://pypi.python.org/pypi/dotcloud.cli">dotcloud.cli source code</a>.</p>

<p>If you execute &#8220;dotcloud push&#8221; with &#8211;export option, you&#8217;ll get the response like this.</p>

<pre><code>$ dotcloud --export push helloworldapp
{
    "data": [
        [
            "upload", 
            ".", 
            "ssh://dotcloud@uploader.dotcloud.com:21122/helloworldapp", 
            {
                "rsync": {
                    "excludes": [
                        "*.pyc", 
                        ".git", 
                        ".hg"
                    ]
                }, 
                "check": true
            }
        ], 
        [
            "call", 
            "deploy helloworldapp.default"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>So you know that dotcloud command will run Remote.upload() method.(See DotCloudCliBehaviorOverView.)</p>

<p>You can see the upload() method in dotcloud/cli/remote.py.</p>

<pre><code>#!python
    def upload(self, local_dir, destination, args):
        if args.get('check'):
            local_dir = self.check_pushdir(local_dir)
        self.info('# upload {0} {1}'.format(local_dir, destination))
        if os.path.isdir(os.path.join(local_dir, '.hg')):
            return self.hg(local_dir, destination, args.get('hg', {}))
        if os.path.isdir(os.path.join(local_dir, '.git')):
            return self.git(local_dir, destination, args.get('git', {}))
        return self.rsync(local_dir, destination, args.get('rsync', {}))
</code></pre>

<p>If you have .hg directory, dotcloud command runs self.hg().If you have .git directory, dotcloud command runs self.git().Otherwise dotcloud command runs self.rsync().</p>

<p>You can see these methods in the same file.</p>

<pre><code>#!python
    def rsync(self, local_dir, destination, args):
        self.info('# rsync')
        excludes = args.get('excludes')
        url = utils.parse_url(destination)
        ssh = ' '.join(self._ssh_options)
        ssh += ' -p {0}'.format(url['port'])
        if not os.path.isfile(local_dir) and not local_dir.endswith('/'):
            local_dir += '/'
        rsync = (
                    'rsync', '-lpthrvz', '--delete', '--safe-links',
                ) + tuple('--exclude={0}'.format(e) for e in excludes) + (
                    '-e', ssh, local_dir,
                    '{user}@{host}:{dest}/'.format(user=url['user'],
                        host=url['host'], dest=url['path'])
                )
        try:
            ret = subprocess.call(rsync, close_fds=True)
            if ret != 0:
                self.warning_ssh()
            return ret
        except OSError:
            self.die('rsync')

    def hg(self, local_dir, destination, args):
        self.info('# hg')
        with utils.cd(local_dir):
            try:
                ssh = ' '.join(self._ssh_options)
                args = ('hg', 'push', '--ssh', ssh, '-f', destination)
                ret = subprocess.call(args, close_fds=True)
                if ret != 0:
                    self.warning_ssh()
                return ret
            except OSError:
                self.die('hg')

    def git(self, local_dir, destination, args):
        self.info('# git')
        with utils.cd(local_dir):
            try:
                os.environ['GIT_SSH'] = '__dotcloud_git_ssh'
                os.environ['DOTCLOUD_SSH_KEY'] = config.CONFIG_KEY
                ret = subprocess.call(('git', 'push', '-f', '--all',
                    destination), close_fds=True)
                if ret != 0:
                    self.warning_ssh()
                return ret
            except OSError:
                self.die('git')
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/10/DotCloudCliBehaviorOverView/">DotCloudCliBehaviorOverView</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-10T20:20:07+09:00" pubdate>Jul 10<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/10/DotCloudCliBehaviorOverView/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Now I&#8217;m investigating the behavior of <a href="http://pypi.python.org/pypi/dotcloud.cli">dotcloud.cli</a>.I will write down the things I found.</p>

<p>With &#8211;export option, you can see the raw response of dotcloud API.</p>

<p>For example, if you execute dotcloud command for the first time with &#8211;export option, you will see the result like this.</p>

<pre><code>$ dotcloud --export
Warning: /Users/miya/.dotcloud/dotcloud.conf does not exist.
Enter your api key (You can find it at http://www.dotcloud.com/account/settings): XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
{
    "data": [
        [
            "key", 
            "-----BEGIN DSA PRIVATE KEY-----\nXXXXXXXXXX...\n-----END DSA PRIVATE KEY-----\n"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>If &#8216;&#8220;type&#8221;: &#8220;cmd&#8221;&#8217; is given, dotcloud command call the appropriate method.In this case, key() method of Remote class in dotcloud/cli/remote.py will be called and SSH key string will be written to ~/.dotcloud/dotcloud.key.</p>

<p>Which method is called are defined in dotcloud/cli/cli.py like this.</p>

<pre><code>#!python
def run_remote(cmd):
    r = remote.Remote()
    handlers = {
            'set_url': r.set_url,
            'run': r.run,
            'script': r.run_script,
            'sftp': r.sftp,
            'pull': r.pull,
            'push': r.push,
            'rsync': r.rsync,
            'git': r.git,
            'hg': r.hg,
            'upload': r.upload,
            'loop': lambda *x: run_loop(*x),
            'confirm': local.confirm,
            'call': lambda x: run_command(x, True),
            'echo': lambda x: sys.stdout.write('{0}\n'.format(x)),
            'echo_error': lambda x: sys.stderr.write('{0}\n'.format(x)),
            'set_verbose': r.set_verbose,
            'key': r.key
            }
</code></pre>

<p>Let&#8217;s see another command option.</p>

<pre><code>$ dotcloud --export create helloworldapp
{
    "data": "Created repos \"helloworldapp\"", 
    "type": "success"
}
</code></pre>

<p>In this case, type is not cmd, so dotcloud command will do nothing anymore.</p>

<p>In the case of option push, API response is like this.</p>

<pre><code>$ dotcloud --export push helloworldapp
{
    "data": [
        [
            "upload", 
            ".", 
            "ssh://dotcloud@uploader.dotcloud.com:21122/helloworldapp", 
            {
                "rsync": {
                    "excludes": [
                        "*.pyc", 
                        ".git", 
                        ".hg"
                    ]
                }, 
                "check": true
            }
        ], 
        [
            "call", 
            "deploy helloworldapp.default"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>&#8220;type&#8221; is &#8220;cmd&#8221;, so Remote.upload() will be called and run_command(&#8216;deploy helloworldapp.default&#8217;, True) will be called.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/10/ProPuppet00/">ProPuppet00</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-10T10:12:32+09:00" pubdate>Jul 10<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/10/ProPuppet00/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>!html</h1>

<pre><code>&lt;img src="http://www.apress.com/media/catalog/product/cache/9/image/9df78eab33525d08d6e5fb8d27136e95/A/9/A9781430230571-3d_11.png" /&gt;
</code></pre>

<p>[wiki:ManagingInfrastructureWithPuppet Managing Infrastructure With Puppet] の中でも少しだけ触れた、<a href="http://www.apress.com/9781430230571">Pro Puppet</a> についてメモ。</p>

<p>こちらは内容盛りだくさんで、Puppet をヘビーに使っている人でも読みごたえがあるんじゃないかと。たとえば、バージョン違いの Puppet を混在させる方法、といったところもフォローされていたり。</p>

<p>ただし、Puppet や、Git といった周辺ツールのインストール方法まで詳細に書かれていて、この辺は自分には必要ないなー、と思ったりもした。</p>

<p>とはいえ、最近の Puppet 動向を追いかけていない自分には、とても有意義な内容が多かったので、その辺についてメモしてみる。</p>

<p>（あんまり書きすぎると出版社の人に怒られそうなんで、さらっと。あと、量が多くなりそうなので、何度かにわけて書く。）</p>

<hr />

<h1>モジュール化について</h1>

<p>Puppet 解説書なんで、当然のことながらマニフェストの書き方が最初の方に出てくるんだけど、本書ではいきなりモジュールを作成するところから始めていて驚いた。</p>

<p>このことで思ったのは、マニフェストはとにかく全部モジュール化しちゃう、というのがベストプラクティスなのかもしれない、ということ。</p>

<p><a href="http://gihyo.jp/admin/serial/01/puppet/0008">第8回　Puppet実践テクニック（その3）</a> の中で書いているデータファイルの構造は、modules ディレクトリはあるものの、すべてをモジュール化することは想定していないため、menifests ディレクトリの下に、クラス毎にマニフェストファイルを置いている。</p>

<p>このやり方だと、dist の下にもクラス毎にスタティックなファイルがあったり、templates の下にもクラス毎にテンプレートがあったりで、同じクラスで利用するマニフェスト、スタティックファイル、テンプレートがばらばらな場所にあって、非常にさがしづらい、といったはめになる。（なので上の記事の内容は今となっては真似しない方がいい。）</p>

<p>これがすべてモジュール化されていると、</p>

<pre><code>modules/
  |
  +--- ssh/
  |     |
  |     +--- files/
  |     |
  |     +--- manifets/
  |     |
  |     +--- templates/
  |
  +--- postfix/
        |
        +--- files/
        |
        +--- manifests/
        |
        +--- templates/
</code></pre>

<p>といった形で、関連するマニフェスト、スタティックファイル、テンプレートが1カ所にまとまっていて、非常に見通しが良い。</p>

<hr />

<h1>モジュールのマニフェストファイルとクラスの分け方</h1>

<p>本書では以下のようにマニフェストファイルをわけている。(ssh モジュールの例。ファイル内容は本とは少し変えてる。)</p>

<pre><code>ssh/
 |
 +--- manifets/
        |
        +--- init.pp
        |
        +--- params.pp
        |
        +--- install.pp
        |
        +--- config.pp
        |
        +--- service.pp
</code></pre>

<p>で、各ファイルの内容は以下のような感じ。</p>

<p><em>init.pp</em></p>

<p>ssh モジュールを利用をするために include ssh すると、このファイルが読み込まれ ssh モジュールが適用される。</p>

<p>このファイルでは、さらにモジュール内で細分化されたクラスを include しているだけ。</p>

<pre><code>class ssh {
    include ssh::params, ssh::install, ssh::config, ssh::service
}
</code></pre>

<ul>
<li>params.pp*</li>
</ul>


<p>環境毎に異なるパラメータをまとめるためのファイル。このファイル内にパラメータをまとめることによって、モジュール全体の見通しを良くする。</p>

<pre><code>class ssh::params {
    case $operatingsystem {
        Solaris: {
            $package_name = 'openssh'
            $service_name = 'sshd'
        }
        ...
    }
}
</code></pre>

<p><em>install.pp</em></p>

<p>必要なパッケージをインストールするためのマニフェスト。</p>

<pre><code>class ssh::install {
    package { $ssh::params::package_name: ensure =&gt; installed }
}
</code></pre>

<p><em>config.pp</em></p>

<p>設定ファイル用マニフェスト。</p>

<pre><code>class ssh::config {
    file { '/etc/ssh/sshd_config':
        ensure  =&gt; present,
        source  =&gt; 'puppet:///modules/ssh/sshd_config',
        require =&gt; Class['ssh::install'],
        notify  =&gt; Class['ssh::service'],
    }
}
</code></pre>

<p><em>service.pp</em></p>

<p>サービス用マニフェスト。</p>

<pre><code>class ssh::service {
    ensure  =&gt; running,
    enable  =&gt; true,
    require =&gt; Class['ssh::config'],
}
</code></pre>

<p>こういった形で、ssh モジュールの中でも、ssh::params, ssh::install, ssh::config, ssh::service といった形でクラスを役割毎に細分化して、ファイルもクラス毎に作成、といった形で、一ファイル内の見通しを良くする、というやり方が紹介されている。</p>

<p>もうひとつのポイントは、require や notify で Class 指定していること。（Class を require とかするのって以前のバージョンからできるんだっけ？）</p>

<p>たとえば、sercice.pp では、</p>

<pre><code>require =&gt; Class['ssh::config'],
</code></pre>

<p>といった指定があるが、これは以下のように、Class ではなく File でも指定できる。</p>

<pre><code>require =&gt; File['/etc/ssh/sshd_config'],
</code></pre>

<p>ひとつの設定ファイルから構成されているようなモジュールであればこれでも良いが、複数の設定ファイルから構成されるようなモジュールだと、変更に対して脆くなってしまう。例えば postfix モジュールで考えてみる。</p>

<p>最初は main.cf のみ Puppet で管理して、他の設定ファイルはデフォルトのまま、という状態を想定すると、マニフェストは以下のようになる。</p>

<pre><code>class postfix::config {
    file { '/etc/postfix/main.cf':
        source =&gt; 'file:///modules/postfix/main.cf',
    }
}

class postfix::service {
    service { 'postfix':
        ensure  =&gt; running,
        enable  =&gt; true,
        require =&gt; File['/etc/postfix/main.cf'],
    }
}
</code></pre>

<p>後から、master.cf もデフォルトのままではなくなったので、Puppet で管理することにすると、マニフェストは以下のように、postfix::config と postfix::service の両方を書き換えることになる。</p>

<pre><code>#!diff
diff --git a/postfix.pp b/postfix.pp
index f55234e..a032d65 100644
--- a/postfix.pp
+++ b/postfix.pp
@@ -2,12 +2,16 @@ class postfix::config {
     file { '/etc/postfix/main.cf':
         source =&gt; 'file:///modules/postfix/main.cf',
     }
+    file { '/etc/postfix/master.cf':
+        source =&gt; 'file:///modules/postfix/master.cf',
+    }
 }

 class postfix::service {
     service { 'postfix':
         ensure  =&gt; running,
         enable  =&gt; true,
-        require =&gt; File['/etc/postfix/main.cf'],
+        require =&gt; [ File['/etc/postfix/main.cf'], File['/etc/postfix/master.cf
     }
 }
</code></pre>

<p>もし、Class を require するようになっていれば、main.cf だけを管理する最初の状態では、マニフェストは</p>

<pre><code>class postfix::config {
    file { '/etc/postfix/main.cf':
        source =&gt; 'file:///modules/postfix/main.cf',
    }
}

class postfix::service {
    service { 'postfix':
        ensure  =&gt; running,
        enable  =&gt; true,
        require =&gt; Class['postfix::config'],
    }
}
</code></pre>

<p>となっており、master.cf を追加した場合、差分は</p>

<pre><code>#!diff
diff --git a/postfix.pp b/postfix.pp
index 9745478..e82621c 100644
--- a/postfix.pp
+++ b/postfix.pp
@@ -2,6 +2,9 @@ class postfix::config {
     file { '/etc/postfix/main.cf':
         source =&gt; 'file:///modules/postfix/main.cf',
     }
+    file { '/etc/postfix/master.cf':
+        source =&gt; 'file:///modules/postfix/master.cf',
+    }
 }

 class postfix::service {
</code></pre>

<p>だけになり、postfix::service はまったく変更する必要がない。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/07/08/ManagingInfrastructureWithPuppet/">ManagingInfrastructureWithPuppet</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-07-08T02:36:30+09:00" pubdate>Jul 8<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/07/08/ManagingInfrastructureWithPuppet/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>!html</h1>

<pre><code>&lt;img src="http://covers.oreilly.com/images/0636920020875/lrg.jpg" /&gt;
</code></pre>

<hr />

<p><a href="http://twitter.com/#!/kdmsnr">@kdmsnr さん</a> の tweet で、<a href="http://oreilly.com/catalog/0636920020875">Managing Infrastructure with Puppet</a> と <a href="http://www.apress.com/9781430230571">Pro Puppet</a> が発売されている事を知ったので読んでみた。まずは Managing Infrastructure with Puppet について。</p>

<p>この本はとても薄い。全体で40ページ強くらい。なので、Puppet をまったく知らない人には全体像を知るためには良い本だけど、既に知っている人には物足りないと思う。</p>

<p>とは言っても、自分は最近の Puppet の動向を追えてないので、その辺の知識不足を補ってくれるような内容もあって、そこは良かった。</p>

<p>また、<a href="http://www.puppetlabs.com/mcollective/introduction/">MCollective</a> についても書かれていて、元々は Puppet Labs とは別なところで開発されていたツールなんで、Puppet とは完全に独立したツールだと思ってたんだけど、Puppet Labs 配下になってから統合が進められたようで、その辺の情報が得られたのがよかった。</p>

<p>以下、内容で気になったところなんかのメモ。</p>

<hr />

<h1>puppet コマンド</h1>

<p>0.25 の次は 2.6 という風にバージョン体系が変わり、それまで puppetmasterd や puppetd といった形で独立していたコマンドが puppet コマンドに統一された、ってことは <a href="http://twitter.com/#!/tnmt">ペパボのイケメンインフラエンジニアの tnmt くん</a> が<a href="http://blog.tnmt.info/2010/11/23/puppet-2-6/">既にブログに書いてある</a> んだけど、それに伴い、コマンドオプションも増えて、やれることが増えてる模様。その中で特に気になったオプションを紹介。</p>

<h2>puppet describe</h2>

<p>リソースタイプのリストを表示してくれたり、指定したリソースタイプに関する説明を表示してくれる。</p>

<p><em>リソースタイプのリスト</em></p>

<pre><code>$ puppet describe --list
These are the types known to puppet:
augeas          - Apply the changes (single or array of changes ...
computer        - Computer object management using DirectorySer ...
cron            - Installs and manages cron jobs
exec            - Executes external commands
file            - Manages local files, including setting owners ...
filebucket      - A repository for backing up files
group           - Manage groups
host            - Installs and manages host entries
k5login         - Manage the `
...
</code></pre>

<p><em>package リソースタイプの説明</em></p>

<pre><code>$ puppet describe package

package
=======
Manage packages.  There is a basic dichotomy in package
support right now:  Some package types (e.g., yum and apt) can
retrieve their own package files, while others (e.g., rpm and sun) cannot. 
For those package formats that cannot retrieve
their own files, you can use the `source` parameter to point to
the correct file.

Puppet will automatically guess the packaging format that you are
using based on the platform you are on, but you can override it
using the `provider` parameter; each provider defines what it
requires in order to function, and you must meet those requirements
to use a given provider.
</code></pre>

<p><strong>Autorequires:</strong> If Puppet is managing the files specified as a package&#8217;s</p>

<pre><code>`adminfile`, `responsefile`, or `source`, the package resource will
autorequire
those files.


Parameters
----------

- **adminfile**
    A file containing package defaults for installing packages.
    This is currently only used on Solaris.  The value will be
    validated according to system rules, which in the case of
    Solaris means that it should either be a fully qualified path
    or it should be in `/var/sadm/install/admin`.

...
</code></pre>

<p>詳しくは puppet describe &#8211;help を参照。</p>

<h2>puppet resource</h2>

<p>コマンドを実行してるマシンの指定されたリソースの状態を、Puppet マニフェストで表示してくれる。</p>

<p><em>host リソースの表示</em></p>

<p>/etc/hosts の内容を Puppet マニフェストで表示。</p>

<pre><code>$ puppet resource host
host { 'localhost.localdomain':
  ensure       =&gt; 'present',
  host_aliases =&gt; ['localhost'],
  ip           =&gt; '127.0.0.1',
  target       =&gt; '/etc/hosts',
}
host { 'localhost6.localdomain6':
  ensure       =&gt; 'present',
  host_aliases =&gt; ['localhost6'],
  ip           =&gt; '::1',
  target       =&gt; '/etc/hosts',
}
</code></pre>

<p><em>service リソースの表示</em></p>

<p>サービスの状態を Puppet マニフェストで表示。</p>

<pre><code>$ puppet resource service
service { 'NetworkManager':
  ensure =&gt; 'stopped',
  enable =&gt; 'false',
}
service { 'acpid':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}
service { 'anacron':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}
service { 'atd':
  ensure =&gt; 'running',
  enable =&gt; 'true',
}
service { 'autofs':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}

...
</code></pre>

<p>既に環境構築されたマシンから Puppet マニフェストの雛形を生成する、とかいった目的に使えそう。</p>

<h2>puppet apply</h2>

<p>Puppet マニフェストを即座に適用できる。</p>

<p><em>test.pp 内のマニフェストを適用する</em></p>

<pre><code>$ puppet apply test.pp
</code></pre>

<p><em>直接マニフェストを文字列で指定するが &#8211;noop つけてるので実際には何もしない</em></p>

<pre><code>$ puppet apply --noop -e 'file { "/etc/passwd": mode =&gt; 600 }'
notice: /Stage[main]//File[/etc/passwd]/mode: current_value 644, should be 600 (noop)
notice: Finished catalog run in 0.05 seconds
</code></pre>

<p>ちょっとした動作確認なんかするのに便利そう。</p>

<hr />

<h1>Parameterized Classes</h1>

<p>define でリソース定義して、呼び出すときにパラメータを渡す、なんてことは以前からできてたけど、2.6 からは Class にパラメータを渡すことができるようになったらしい。</p>

<p>クラス定義はこんな感じ。</p>

<pre><code>class ruby ( $version = '1.8.7') {
    package { 'ruby': ensure =&gt; $version }
}
</code></pre>

<p>Parameterized Classes ではない、従来のクラスの呼び出し方。これだと、Ruby 1.8.7 がインストールされる。</p>

<pre><code>node 'test.example.jp' {
    include ruby
}
</code></pre>

<p>パラメータを渡してやると、Ruby 1.9.2 がインストールされる。</p>

<pre><code>node 'test.example.jp' {
    class { 'ruby': version =&gt; '1.9.2' }
}
</code></pre>

<p>便利そうだけど、従来の include とだいぶ書式が変わるので、混乱しそう。</p>

<hr />

<h1>Puppet Forge</h1>

<p>Puppet モジュールを集めた <a href="http://forge.puppetlabs.com/">Puppet Forge</a> なんてサイトができてたんだね。Puppet 版 CPAN といった感じ。<a href="http://github.com/puppetlabs/puppet-module-tool">puppet-module-tool</a> というコマンドラインツールを使って、モジュールのインストールとかパッケージングとか色々できるようなんだけど、この本には詳しい説明がなかった。Pro Puppet には詳しい説明があったので、Pro Puppet についての感想を書くときに、この辺について少し詳しく書くつもり。</p>

<hr />

<h1>MCollective</h1>

<p>MCollective は、複数のホストに対して同じ処理を並列実行するためのもの。<a href="https://fedorahosted.org/func/">Func</a> とか <a href="http://fabfile.org/">Fabric</a> とか <a href="http://www.capify.org/">Capistrano</a> みたいな位置づけ。</p>

<p>こんな感じで実行できる。（apache2 を再起動する例。）</p>

<pre><code>$ mc-service --with-class apache2 apache2 restart
$ mc-service --with-class apache2 --with-fact architecture=x86_64 apache2 restart
</code></pre>

<p>Puppet の特定のクラスを include してるホストでのみ実行とか、特定の fact (facter によって得られる値) にマッチするホストでのみ実行、という感じで Puppet と連動できる。</p>

<p><a href="http://projects.puppetlabs.com/projects/mcollective-plugins/wiki/AgentPuppetd">Puppetd Agent</a> というプラグインもあって、これを使うと、各ホストの puppet agent の操作を MCollective 経由でできる。つまり、puppet kick(古いバージョンだと puppetrun)の代わりに使える。これの何がうれしいのかというと、puppetrun では特定のクラスを include したホストだけを対象にする、ということをやろうと思うと、LDAP Nodes が必須だった（2.6 でもそうなのかは知らん）けど、このプラグインだとそれが不要になりそう、ってあたりかな。</p>

<p>あと、<a href="http://projects.puppetlabs.com/projects/mcollective-plugins/wiki/ToolPuppetcommander">Puppet Commander</a> というプラグインを使うと、puppet agent の同時起動数を制御できて、puppet master へ同時アクセスが集中しないようにコントロールできるらしい。大量にホストがある環境では良さそうですね。</p>

<p>それから、<a href="http://docs.puppetlabs.com/mcollective/simplerpc/agents.html">MCollective プラグインを書くためのドキュメントへのリンク</a> も載ってた。が本では詳しい説明はなし。</p>

<hr />

<p>というわけで、<a href="http://oreilly.com/catalog/0636920020875">Managing Infrastructure with Puppet</a> について気になった点は以上。次は <a href="http://www.apress.com/9781430230571">Pro Puppet</a> について、気が向いたら書きます。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/06/29/SubsonicThroughApacheProxy/">SubsonicThroughApacheProxy</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-06-29T22:40:54+09:00" pubdate>Jun 29<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/06/29/SubsonicThroughApacheProxy/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://twitter.com/#!/earlcyborg">@earlcyborg くん</a> に教えてもらった <a href="http://www.subsonic.org/pages/index.jsp">Subsonic</a> がよさげなので、家の中に環境作り、Apache mod_proxy 経由でアクセスしようとしたらはまったのでメモ。</p>

<p>結論: ProxyPreserveHost On を入れないとはまる。</p>

<p>最初、</p>

<pre><code>&lt;VirtualHost *&gt;
ServerName subsonic.mizzy.org
ProxyPass / http://192.168.10.14:4040/
ProxyPassReverse / http://192.168.10.14:4040/
&lt;/VirtualHost&gt;
</code></pre>

<p>という設定で http://subsonic.mizzy.org/ にアクセスしたら、http://192.168.10.14:4040/login.view? にリダイレクトされてしまった。Subsonic にホスト名を設定するところもなさそう。そこで、おそらく Host ヘッダに設定されたホストがリダイレクト先になるんじゃなかろうか、と仮説を立てて、以下のように設定してみた。</p>

<pre><code>&lt;VirtualHost *&gt;
ServerName subsonic.mizzy.org
ProxyPreserveHost On
ProxyPass / http://192.168.10.14:4040/
ProxyPassReverse / http://192.168.10.14:4040/
&lt;/VirtualHost&gt;
</code></pre>

<p>これでうまくいった。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/06/25/ModRuidTestAgain/">ModRuidTestAgain</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-06-25T12:30:43+09:00" pubdate>Jun 25<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/06/25/ModRuidTestAgain/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>3,4年ぐらい前に、[wiki:ModSuid2AndModRuidAndLinuxCapability  mod_suid2 とか mod_ruid とか Linux ケーパビリティとか] で、mod_ruid の setuid/setgid は、プロセス単位なのか、それともスレッド単位なのか、という実験をして、スレッド単位で setuid/setgid する、という結果が得られたんですが、Linux kernel 2.4 というだいぶ古い環境での実験だったので、比較的最近の環境で実験してみた。</p>

<p>OS はこんな感じ。</p>

<pre><code>$ uname -a
Linux h026.southpark 2.6.18-164.el5 #1 SMP Thu Sep 3 03:28:30 EDT 2009 x86_64 x86_64 x86_64 GNU/Linux
$ cat /etc/redhat-release
CentOS release 5.4 (Final)
</code></pre>

<p>httpd のバージョン。</p>

<pre><code>$ rpm -q httpd
httpd-2.2.3-45.el5.centos.1
</code></pre>

<p>ps でプロセス/スレッドが見やすいように /etc/httpd/conf/httpd.conf をいじる。</p>

<pre><code>&lt;IfModule worker.c&gt;
StartServers        1
MaxClients          1
MinSpareThreads     1
MaxSpareThreads     1
ThreadsPerChild     1
MaxRequestsPerChild  0
&lt;/IfModule&gt;
</code></pre>

<p>/etc/sysconfig/httpd の以下の行を有効にして worker mpm で動かす。</p>

<pre><code>HTTPD=/usr/sbin/httpd.worker
</code></pre>

<p>mod_ruid は処理が終わるとすぐに元のユーザに戻してしまうので、戻らないようにコメントアウト。</p>

<pre><code>#!diff
diff --git a/mod_ruid.c b/mod_ruid.c
index 5294d32..deed59b 100644
--- a/mod_ruid.c
+++ b/mod_ruid.c
@@ -269,9 +269,9 @@ static int ruid_suidback (request_rec * r)
        }
        cap_free(cap);

-       setgroups(0,NULL);
-       setgid(unixd_config.group_id);
-       setuid(unixd_config.user_id);
+       //setgroups(0,NULL);
+       //setgid(unixd_config.group_id);
+       //setuid(unixd_config.user_id);

        cap=cap_get_proc();
        capval[0]=CAP_SETUID;
</code></pre>

<p>apxs でビルド＆インストール。</p>

<pre><code>$ sudo /usr/sbin/apxs -a -i -l cap -c mod_ruid.c
</code></pre>

<p>/etc/init.d/httpd restart して、プロセスとスレッドの UID を確認。下3つは PID が同じなので、スレッドだと判断できる。UID はすべて apache。</p>

<pre><code>$ ps -eLf
UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD
root     13005     1 13005  0    1 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13011  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13013  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13014  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
</code></pre>

<p>ここで httpd へアクセスし、再度 ps で確認。</p>

<pre><code>UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD
root     13005     1 13005  0    1 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13011  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
100      13011 13005 13013  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13014  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
</code></pre>

<p>スレッドのひとつだけ UID が 100 になってる。これは mod_ruid.c に以下のようにデフォルトが定義されているから。</p>

<pre><code>#!c
#define SUID_DEFAULT_UID        100
#define SUID_DEFAULT_GID        100
</code></pre>

<p>というわけで、スレッド単位で setuid/setgid される、ということには変わりありませんでした、という結果に。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/06/25/DevOpsConference/">DevOpsConference</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-06-25T02:16:22+09:00" pubdate>Jun 25<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/06/25/DevOpsConference/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://partake.in/events/b5472f43-5bc0-42d0-9469-dc70d7d95b24">DevOps カンファレンス</a> に参加してきたので、個人的なまとめ＆補足など。</p>

<p>といっても <a href="http://twitter.com/#!/kuwa_tw">@kuwa_tw さん</a> の <a href="http://togetter.com/li/153695">togetter まとめ</a> が既にあるので、まとめというよりは、自分が話した内容の補足なんかをしてみようかと。</p>

<p>プレゼンに利用したスライドは <a href="http://www.slideshare.net/mizzy/10devops">slideshare にアップ</a> してますが、話すこと前提でスライドの内容は薄いので、togetter と併せてご覧下さい。</p>

<p>カンファレンスの内容が素晴らしかったのは自分が敢えてここで書く必要はないので、個人的に内容以外でよかった点を挙げると、</p>

<ul>
<li><a href="http://twitter.com/#!/kdmsnr">@kdmsnr</a> さんと初めてお会いして、ウェブオペレーションを献本頂いたお礼を直接言うことができた！</li>
<li><a href="http://twitter.com/#!/riywo">@riywo</a> さんとは以前からお会いしたいなー、と思っていたので、ようやくその願いが叶った！</li>
</ul>


<p>といったあたりですかね。</p>

<p>自分の発表では最初に、Dev な人、Ops な人、Dev &amp;&amp; Ops な人、!(Dev &amp;&amp; Ops) な人、それぞれで挙手してもらったんですが、Dev な人が意外と多い印象でした。プレゼンでも話しましたが、元々 Ops 発祥のムーブメントなので、Ops の人の方が圧倒的に多いんじゃないかと思ってましたが、意外な結果でした。</p>

<p>ただし、スピーカー陣は全員 Ops 寄りな人で、Ops の話がメインでしたね。（<a href="http://twitter.com/#!/hiroshi19790209">諸富さん</a> は Dev も Ops も兼ねてらっしゃるようですが、Ops の話がメインでしたしね。）</p>

<p>第2回では Dev な人のお話をぜひ聞いてみたいですね。<a href="http://twitter.com/#!/acotie/status/84302902939750400">@acotie が何かしゃべってくれそうです</a> 。</p>

<p>それから、プレゼンに盛り込もうと思っていたけど、時間の関係で断念したんですが、DevOps に対する批判、というものもあります。</p>

<ul>
<li><a href="http://www.rationalsurvivability.com/blog/?p=1890">Incomplete Thought: The DevOps Disconnect | Rational Survivability</a></li>
<li><a href="http://teddziuba.com/2011/03/devops-scam.html">Devops Is a Poorly Executed Scam</a></li>
</ul>


<p>このうちのひとつめのエントリに対する John Allspaw 氏のコメントをプレゼンでは引用させてもらいました。</p>

<p>まあ、批判する人はどこにでもいるし、批判の内容もわからんでもないんですが、それが何か？という感じですね。</p>

<p>帰り際に <a href="http://twitter.com/#!/marqs">@marqs さん</a> と、みんな同じような問題意識を抱えているんだな、ということ、ただそれを適切に表す言葉がいままでなかったために、お互いの共通認識として情報を共有する場を持てなかった、でも、DevOps という言葉が与えられることによって、それがはっきりと共通認識として浮かび上がり、共有する場を持てるようなった、それって、とても素晴らしいことだよね、なんて事を話して、がっちり握手を交わしてきました。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/05/27/UfwOnCentOS5/">UfwOnCentOS5</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2011-05-27T01:05:06+09:00" pubdate>May 27<span>th</span>, 2011</time>
        
         | <a href="/blog/2011/05/27/UfwOnCentOS5/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://d.hatena.ne.jp/tokuhirom/">tokuhirom</a> さんが IRC で「<a href="https://launchpad.net/ufw">ufw</a> べんり！」「iptables より簡単」っておっしゃっていて、日頃から iptables のコマンドインターフェースは最悪だと思っていたので、お、それは試してみたい、ってことで、ちょろっと触ってみました。</p>

<p>ufw って Ubuntu に標準で付属してるんですね。Ubuntu 使ってないんで知りませんでした。で、ufw の u は Ubuntu の u なのかな、と思ったら、Uncomplicated Firewall の略だそうで、だったら普段一番使ってる CentOS5 でも動くかも、と思って、パッケージ作ったり軽く動かしたりしてみたんで、その記録です。（CentOS の今後については色々言われてますが、まあそこは気にせずに。）</p>

<p>まず RPM パッケージをつくろう、ってことで、ググったら <a href="http://www.openmamba.org/pub/openmamba/devel-ercolinux/specs/ufw.spec">ufw.spec</a> を見つけたので、これを CentOS5 で動くようにカスタマイズして、<a href="http://svn.mizzy.org/public/yum/SRPMS/ufw-0.30.1-1.src.rpm">ソース RPM</a> と <a href="http://svn.mizzy.org/public/yum/RPMS/centos/5/x86_64/RPMS/ufw-0.30.1-1.x86_64.rpm">バイナリ RPM</a> を作成。ufw は python 2.5 以降が必要なんですが、CentOS5 デフォルトは 2.4 なので、python26 パッケージが必要です。あと、spec のカスタマイズも超適当だけど気にしないでください。</p>

<p>で、パッケージインストール後、iptables が動いてない状態から、ufw enable して iptables -L -n してみたら、以下のようにルールが設定されていた。</p>

<pre><code>$ sudo /usr/sbin/ufw enable
Password: 
Command may disrupt existing ssh connections. Proceed with operation (y|n)? y
Firewall is active and enabled on system startup

$ sudo /sbin/iptables -L -n
Chain INPUT (policy DROP)
target     prot opt source               destination         
ufw-before-logging-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-before-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-logging-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-reject-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-track-input  all  --  0.0.0.0/0            0.0.0.0/0           

Chain FORWARD (policy DROP)
target     prot opt source               destination         
ufw-before-logging-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-before-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-logging-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-reject-forward  all  --  0.0.0.0/0            0.0.0.0/0           

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
ufw-before-logging-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-before-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-logging-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-reject-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-track-output  all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-after-forward (1 references)
target     prot opt source               destination         

Chain ufw-after-input (1 references)
target     prot opt source               destination         
ufw-skip-to-policy-input  udp  --  0.0.0.0/0            0.0.0.0/0           udp dpt:137 
ufw-skip-to-policy-input  udp  --  0.0.0.0/0            0.0.0.0/0           udp dpt:138 
ufw-skip-to-policy-input  tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:139 
ufw-skip-to-policy-input  tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:445 
ufw-skip-to-policy-input  udp  --  0.0.0.0/0            0.0.0.0/0           udp dpt:67 
ufw-skip-to-policy-input  udp  --  0.0.0.0/0            0.0.0.0/0           udp dpt:68 
ufw-skip-to-policy-input  all  --  0.0.0.0/0            0.0.0.0/0           ADDRTYPE match dst-type BROADCAST 

Chain ufw-after-logging-forward (1 references)
target     prot opt source               destination         
LOG        all  --  0.0.0.0/0            0.0.0.0/0           limit: avg 3/min burst 10 LOG flags 0 level 4 prefix `[UFW BLOCK] ' 

Chain ufw-after-logging-input (1 references)
target     prot opt source               destination         
LOG        all  --  0.0.0.0/0            0.0.0.0/0           limit: avg 3/min burst 10 LOG flags 0 level 4 prefix `[UFW BLOCK] ' 

Chain ufw-after-logging-output (1 references)
target     prot opt source               destination         

Chain ufw-after-output (1 references)
target     prot opt source               destination         

Chain ufw-before-forward (1 references)
target     prot opt source               destination         
ufw-user-forward  all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-before-input (1 references)
target     prot opt source               destination         
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           state RELATED,ESTABLISHED 
ufw-logging-deny  all  --  0.0.0.0/0            0.0.0.0/0           state INVALID 
DROP       all  --  0.0.0.0/0            0.0.0.0/0           state INVALID 
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           icmp type 3 
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           icmp type 4 
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           icmp type 11 
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           icmp type 12 
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           icmp type 8 
ACCEPT     udp  --  0.0.0.0/0            0.0.0.0/0           udp spt:67 dpt:68 
ufw-not-local  all  --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     udp  --  0.0.0.0/0            224.0.0.251         udp dpt:5353 
ufw-user-input  all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-before-logging-forward (1 references)
target     prot opt source               destination         

Chain ufw-before-logging-input (1 references)
target     prot opt source               destination         

Chain ufw-before-logging-output (1 references)
target     prot opt source               destination         

Chain ufw-before-output (1 references)
target     prot opt source               destination         
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           state RELATED,ESTABLISHED 
ufw-user-output  all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-logging-allow (0 references)
target     prot opt source               destination         
LOG        all  --  0.0.0.0/0            0.0.0.0/0           limit: avg 3/min burst 10 LOG flags 0 level 4 prefix `[UFW ALLOW] ' 

Chain ufw-logging-deny (2 references)
target     prot opt source               destination         
RETURN     all  --  0.0.0.0/0            0.0.0.0/0           state INVALID limit: avg 3/min burst 10 
LOG        all  --  0.0.0.0/0            0.0.0.0/0           limit: avg 3/min burst 10 LOG flags 0 level 4 prefix `[UFW BLOCK] ' 

Chain ufw-not-local (1 references)
target     prot opt source               destination         
RETURN     all  --  0.0.0.0/0            0.0.0.0/0           ADDRTYPE match dst-type LOCAL 
RETURN     all  --  0.0.0.0/0            0.0.0.0/0           ADDRTYPE match dst-type MULTICAST 
RETURN     all  --  0.0.0.0/0            0.0.0.0/0           ADDRTYPE match dst-type BROADCAST 
ufw-logging-deny  all  --  0.0.0.0/0            0.0.0.0/0           limit: avg 3/min burst 10 
DROP       all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-reject-forward (1 references)
target     prot opt source               destination         

Chain ufw-reject-input (1 references)
target     prot opt source               destination         

Chain ufw-reject-output (1 references)
target     prot opt source               destination         

Chain ufw-skip-to-policy-forward (0 references)
target     prot opt source               destination         
DROP       all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-skip-to-policy-input (7 references)
target     prot opt source               destination         
DROP       all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-skip-to-policy-output (0 references)
target     prot opt source               destination         
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-track-input (1 references)
target     prot opt source               destination         

Chain ufw-track-output (1 references)
target     prot opt source               destination         
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           state NEW 
ACCEPT     udp  --  0.0.0.0/0            0.0.0.0/0           state NEW 

Chain ufw-user-forward (1 references)
target     prot opt source               destination         

Chain ufw-user-input (1 references)
target     prot opt source               destination         

Chain ufw-user-limit (0 references)
target     prot opt source               destination         
LOG        all  --  0.0.0.0/0            0.0.0.0/0           limit: avg 3/min burst 5 LOG flags 0 level 4 prefix `[UFW LIMIT BLOCK] ' 
REJECT     all  --  0.0.0.0/0            0.0.0.0/0           reject-with icmp-port-unreachable 

Chain ufw-user-limit-accept (0 references)
target     prot opt source               destination         
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-user-logging-forward (0 references)
target     prot opt source               destination         

Chain ufw-user-logging-input (0 references)
target     prot opt source               destination         

Chain ufw-user-logging-output (0 references)
target     prot opt source               destination         

Chain ufw-user-output (1 references)
target     prot opt source               destination         
</code></pre>

<p>で、今度は ufw disable してみたら、以下のようになった。chain は残る模様。</p>

<pre><code>$ sudo /usr/sbin/ufw disable
Firewall stopped and disabled on system startup

$ sudo /sbin/iptables -L -n
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
ufw-before-logging-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-before-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-logging-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-reject-input  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-track-input  all  --  0.0.0.0/0            0.0.0.0/0           

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination         
ufw-before-logging-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-before-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-logging-forward  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-reject-forward  all  --  0.0.0.0/0            0.0.0.0/0           

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
ufw-before-logging-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-before-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-after-logging-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-reject-output  all  --  0.0.0.0/0            0.0.0.0/0           
ufw-track-output  all  --  0.0.0.0/0            0.0.0.0/0           

Chain ufw-after-forward (1 references)
target     prot opt source               destination         

Chain ufw-after-input (1 references)
target     prot opt source               destination         

Chain ufw-after-logging-forward (1 references)
target     prot opt source               destination         

Chain ufw-after-logging-input (1 references)
target     prot opt source               destination         

Chain ufw-after-logging-output (1 references)
target     prot opt source               destination         

Chain ufw-after-output (1 references)
target     prot opt source               destination         

Chain ufw-before-forward (1 references)
target     prot opt source               destination         

Chain ufw-before-input (1 references)
target     prot opt source               destination         

Chain ufw-before-logging-forward (1 references)
target     prot opt source               destination         

Chain ufw-before-logging-input (1 references)
target     prot opt source               destination         

Chain ufw-before-logging-output (1 references)
target     prot opt source               destination         

Chain ufw-before-output (1 references)
target     prot opt source               destination         

Chain ufw-reject-forward (1 references)
target     prot opt source               destination         

Chain ufw-reject-input (1 references)
target     prot opt source               destination         

Chain ufw-reject-output (1 references)
target     prot opt source               destination         

Chain ufw-track-input (1 references)
target     prot opt source               destination         

Chain ufw-track-output (1 references)
target     prot opt source               destination         
</code></pre>

<p>とりあえず CentOS5 でも動くようなんで、色々遊んでみようと思う。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/3/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2011/11/15/octopress-on-heteml/">How to deploy a blog made by Octopress to Heteml</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/11/05/maglica-web/">Maglica Web</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/10/30/vimeo-tag-plugin/">Vimeo tag plugin</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/10/29/typo-to-octopress/">Typo to Octopress</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/10/21/twan-tag-plugin/">TWAN tag plugin for Jekyll</a>
      </li>
    
  </ul>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2011 - Gosuke Miyashita -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'mizzyorg';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
