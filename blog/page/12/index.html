
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Gosuke Miyashita</title>
  <meta name="author" content="Gosuke Miyashita">

  
  <meta name="description" content="Func に関するまとめ Wiki。内容はまだなし。
">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mizzy.org/blog/page/12">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Gosuke Miyashita" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-53984-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Gosuke Miyashita</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mizzy.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/08/Func/">Func</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-08T01:22:24+09:00" pubdate>Dec 8<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://hosted.fedoraproject.org/projects/func/">Func</a> に関するまとめ Wiki。内容はまだなし。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/07/PuppetDojo2/">Puppet Dojo2</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-07T15:50:13+09:00" pubdate>Dec 7<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://trombik.mine.nu/~cherry/w/index.php/2007/07/07/1014/puppet-dojo">以前行われた Puppet セミナー</a>の第2回目が開催されます。第1回目に引き続き、またお手伝いさせて頂きます。</p>

<p>今回は3日に渡って以下の様なスケジュールで行われます。</p>

<ul>
<li><p>2007/12/17(月) 19:00～20:30</p>

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=506">オープンソースでシステム管理の自動化を実現！ Puppetを使うこれだけの理由</a></li>
</ul>
</li>
<li><p>2007/12/18(火)</p>

<ul>
<li>15:00～17:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=507">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #1</a></li>
</ul>
</li>
<li>19:00～21:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=508">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #2</a></li>
</ul>
</li>
</ul>
</li>
<li><p>2007/12/19(水)</p>

<ul>
<li>15:00～17:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=509">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #1</a></li>
</ul>
</li>
<li>19:00～21:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=510">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #2</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<p>12/18 と 12/19 は同じ内容のものが実施されます。Puppet Dojo !#1 は前回のセミナーと同内容のものを少し簡略化した内容で、Puppet Dojo !#2 は新しい内容となります。詳細はリンク先をご参照ください。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/03/PacSec2007/">Pac Sec2007</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-03T23:50:14+09:00" pubdate>Dec 3<span>rd</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://trombik.mine.nu/~cherry/w/">桜井さん</a>のご好意により、11月29日, 30日に行われた、<a href="http://pacsec.jp/">PacSec 2007</a>というコンピュータセキュリティに関するカンファレンスに参加してきました。このカンファレンスは、日本以外でも、カナダ(CanSecWest)、イギリス(EuSecWest)で行われているようです。また、カンファレンスに先立って、27日、28日には<a href="http://www.pacsec.jp/dojo.html">セキュリティ・マスターズ道場</a>と題したトレーニングも行われていました。</p>

<p>自分はセキュリティ情報はあまりウォッチしておらず、苦手な分野ではあるのですが、その分知らないことだらけでとても新鮮で、刺激的なカンファレンスでした。内容の半分も理解できていませんが。</p>

<p>特に興味深かったセッションと簡単なメモです。（メモしたファイルは会社の PC にあって今見られないので、記憶を辿りながら書きます。間違いが多かったらすみません。）</p>

<ul>
<li>Microsoft Officeのゼロデイと悪いヤツら - Takumi Onodera Microsoft

<ul>
<li>Microsoft Office セキュリティに関する話。</li>
<li>SDL(Security Development Lifecycle)という言葉をはじめて聞いた。</li>
<li><a href="http://www.microsoft.com/technet/sysinternals/utilities/processexplorer.mspx">Process Explorer</a> とか <a href="http://www.microsoft.com/technet/sysinternals/utilities/processmonitor.mspx">Process Monitor</a> というツールをはじめて知った。</li>
<li>これらのツールをつかって、不正なバイナリコードが埋め込まれた PowerPoint ファイルを開き、不正コードへのファイルへの書き出しや実行が行われる様子を具体的に見ることができておもしろい。</li>
<li>「攻撃を防ぐための完璧な対策はない。攻撃される可能性を減らすための対策を積み重ねていくことが重要」</li>
</ul>
</li>
<li>TOMOYO Linux: Linuxサーバを理解し守る実践的な手法 - Toshiharu Harada 株式会社NTTデータ

<ul>
<li>専用のポリシーエディタが付属しており、init からはじまるプロセスが起動された状態をツリー構造で表示したり、各プロセスが読み書きするファイルを表示したり、各プロセスごとにアクセスポリシーを設定したり、ということができる。</li>
<li>SELinux はめんどくさすぎて使う気にはなれないけど、TOMOYO Linux のポリシーエディタは使いやすそうだ。</li>
<li>同じプロセスであっても「どのプロセスから起動されたか」によって別々のポリシーを設定することもできるらしい。</li>
</ul>
</li>
<li>Agent-oriented SQL Abuse - Fernando Russ &amp; Diego Tiscornia, Core

<ul>
<li><a href="http://www.coresecurity.com/">Core Security Technologies</a> という会社の人がスピーカ。</li>
<li>Python でできた、SQL を HTTP リクエストに変換して、SQL インジェクションのペネトレーションテストを行うためのフレームワーク。</li>
<li>残念ながら、ソースは公開されてなさそう。（おそらくこのツールによる自社の優位性、というのもあるだろうし、悪用される恐れもあるだろうし。）</li>
<li>他のセッションでも、Python で作られたツールの話があった。セキュリティ分野は Python がよく使われてるのかな？</li>
</ul>
</li>
<li>Fuzzing Frameworks, Fuzzing Languages!? - Stephen Ridley &amp; Colin Delaney, McAfee

<ul>
<li><a href="http://en.wikipedia.org/wiki/Fuzz_testing">Fuzzing</a> というテスト手法ははじめて聞いた。</li>
<li><a href="http://ruxxer.com/">Ruxxer</a> という Fuzzing のためのフレームワーク。</li>
<li>従来のツールは「使いやすいけど機能に乏し」かったり「機能は豊富だけど使いにくい」という問題がある。</li>
<li>それを解決するために、独自の言語を定義することによって「使いやすさ」を提供し、Python API によって「豊富な機能」を提供。</li>
</ul>
</li>
<li>Developing Fuzzers with Peach - Michael Eddington, Leviathan Security

<ul>
<li><a href="http://peachfuzz.sourceforge.net/">Peach</a> というツール。こちらも Fuzzing のためのフレームワーク。これも Python 製らしい。</li>
<li>Windows 上で動く GUI ツール。</li>
<li>Python APIや C, .NET, Java, COM, XPCOM のバインディングもある。</li>
</ul>
</li>
</ul>


<p>PacSec 2007 に関するインタビュー記事も見つけたので載せておきます。</p>

<ul>
<li>http://itpro.nikkeibp.co.jp/article/Interview/20071121/287737/</li>
<li>http://japan.zdnet.com/sp/interview/story/0,2000056426,20361870,00.htm</li>
</ul>


<p>主催の Dragos さんと軽く話をしたのですが、現地の運営スタッフが足りない、と嘆いていました。なので、来年はぜひ運営のお手伝いをさせてもらおうかな、と思っています。もし、運営スタッフやってもいいよ、という方がいらっしゃいましたら、gosukenator at gmail.com までご連絡ください。</p>

<p>参加者は半数ぐらいは海外の方で、懇親会では更に海外の方の割合が増す、という状態でしたので、海外のセキュリティエンジニアとお友達になりたい方にはチャンスですよ。</p>

<p>自分は <a href="http://search.cpan.org/dist/Apache-SMTP/">Apache::SMTP</a> という Apache を SMTP サーバにしてしまう mod_perl プログラムを書いてる方（ActiveState にいたこともあるそうです）や、OpenBSD の pf 開発者の一人である <a href="http://kerneltrap.org/node/2873">Ryan</a> さん（Puppet の OpenBSD まわりのメンテもしているそうです）とお話することができました。</p>

<p>が、自分の英語力不足もあってあまり深い話はできなかったので、<a href="http://www.iknow.co.jp/">iKnow!</a>で英語勉強します。（英語だけじゃなく、セキュリティ関連の知識不足もありますが…）</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/20/library-perl-trunk-Text-Trac-lib-Text-Trac.pm/">Library/Perl/Trunk/Text Trac/Lib/Text/Trac.Pm</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-20T23:20:38+09:00" pubdate>Nov 20<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>source:library/perl/trunk/Text-Trac/lib/Text/Trac.pm</p>

<h1>NAME</h1>

<p>Text::Trac - Perl extension for formatting text with Trac Wiki Style.</p>

<h1>VERSION</h1>

<p>Version 0.08</p>

<h1>SYNOPSIS</h1>

<pre><code>    use Text::Trac;

    my $parser = Text::Trac-&gt;new(
        trac_url      =&gt; 'http://trac.mizzy.org/public/',
        disable_links =&gt; [ qw( changeset ticket ) ],
    );

    $parser-&gt;parse($text);

    print $parser-&gt;html;
</code></pre>

<h1>DESCRIPTION</h1>

<p>Text::Trac parses text with Trac WikiFormatting and convert it to html format.</p>

<h1>METHODS</h1>

<h2>new</h2>

<p>Constructs Text::Trac object.</p>

<p>Available arguments are:</p>

<h3>trac_url</h3>

<p>Base URL for TracLinks.Default is /. You can specify each type of URL individually. Available URLs are:</p>

<p> trac_attachment_url::  trac_changeset_url::  trac_log_url::  trac_milestone_url::  trac_report_url::  trac_source_url::  trac_ticket_url::  trac_wiki_url::</p>

<h3>disable_links</h3>

<p>Specify TracLink types you want to disable. All types are enabled if you don&#8217;t specify this option.</p>

<pre><code>    my $parser = Text::Trac-&gt;new(
        disable_links =&gt; [ qw( changeset ticket ) ],
    );
</code></pre>

<h3>enable_links</h3>

<p>Specify TracLink types you want to enable.Other types are disabled. You cannot use both disable_links and enable_links at once.</p>

<pre><code>    my $parser = Text::Trac-&gt;new(
        enable_links =&gt; [ qw( changeset ticket ) ],
    );
</code></pre>

<h2>parse</h2>

<p>Parses text and converts it to html format.</p>

<h2>process</h2>

<p>An alias of parse method.</p>

<h2>html</h2>

<p>Return converted html string.</p>

<h1>SEE ALSO</h1>

<p> Text::Hatena::  Trac http://www.edgewall.com/trac/::  Trac WikiFormatting http://projects.edgewall.com/trac/wiki/WikiFormatting::</p>

<h1>AUTHORS</h1>

<p>Gosuke Miyashita, <code>&lt;gosukenator at gmail.com&gt;</code></p>

<p>Hideaki Tanaka, <code>&lt;drawn.boy at gmail.com)&gt;</code></p>

<h1>BUGS</h1>

<p>Please report any bugs or feature requests to <code>bug-text-trac at rt.cpan.org</code>, or through the web interface at http://rt.cpan.org/NoAuth/ReportBug.html?Queue=Text-Trac. I will be notified, and then you&#8217;ll automatically be notified of progress on your bug as I make changes.</p>

<h1>SUPPORT</h1>

<p>You can find documentation for this module with the perldoc command.</p>

<pre><code>    perldoc Text::Trac
</code></pre>

<p>You can also look for information at:</p>

<ul>
<li>AnnoCPAN: Annotated CPAN documentation</li>
</ul>


<p> http://annocpan.org/dist/Text-Trac</p>

<ul>
<li>CPAN Ratings</li>
</ul>


<p> http://cpanratings.perl.org/d/Text-Trac</p>

<ul>
<li>RT: CPAN&#8217;s request tracker</li>
</ul>


<p> http://rt.cpan.org/NoAuth/Bugs.html?Dist=Text-Trac</p>

<ul>
<li>Search CPAN</li>
</ul>


<p> http://search.cpan.org/dist/Text-Trac</p>

<h1>COPYRIGHT &amp; LICENSE</h1>

<p>Copyright 2006 Gosuke Miyashita, all rights reserved.</p>

<p>This program is free software; you can redistribute it and/or modify it under the same terms as Perl itself.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/17/SoftwareDesign200712Puppet/">Software Design200712 Puppet</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-17T00:37:00+09:00" pubdate>Nov 17<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Software Design 2007年12月号の Puppet 特集を執筆させて頂きました。</p>

<p>概要や各章のタイトルは <a href="http://d.hatena.ne.jp/software_design/20071116">Software Design 2007年12月号のお知らせ - Software Design×はてな</a> をご参照下さい。</p>

<p><a href="http://gihyo.jp/admin/serial/01/puppet">gihyo.jp での連載</a> をベースに、大幅に加筆、修正した内容となっており、リファレンスも含めて約50ページと、かなりのボリュームです。特にリファレンスは、各リソースタイプとパラメータがコンパクトにまとまっているので、手元に置いておくととても便利ですよ。</p>

<p>以上宣伝でした。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/16/Lisa07TechSession2ndDay/">Lisa07 Tech Session2nd Day</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-16T14:32:03+09:00" pubdate>Nov 16<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://www.usenix.org/events/lisa07/">LISA&#8217;07</a> テクニカルセッション2日目の、気になったテーマに関する簡単なメモ。</p>

<h1>Ganeti: An Open Source Multi-Node HA Cluster Based on Xen</h1>

<p>Google でつくられている Xen ベースのオープンソースなマルチノード HA クラスタ（タイトルまんま）。<a href="http://code.google.com/p/ganeti/">プロジェクトページはこちら</a>。</p>

<p>要するに HA + Virtualization。通常の HA は、実マシンから実マシンへフェイルオーバするけど、Ganeti では VM から VM へフェイルオーバーする、と。仮想化は Xen を利用しており、管理用コマンドラインツールには Python を、ディスク管理には LVM, DRBD, MD を、コマンドラインツールから各ノード（Xen dom0）やインスタンス（Xen domU）への命令実行は、Twisted や ssh を利用している。</p>

<p>管理コマンドはマスタノード上で実行する。</p>

<ul>
<li>gnt-node add/remove/list cluster nodes</li>
<li>gnt-instance

<ul>
<li>add/remove</li>
<li>failover</li>
<li>stop/start change params</li>
</ul>
</li>
<li>gnt-os: instance os definitions</li>
<li>gnt-cluster: cluster commands</li>
<li>gnt-backup: instance export and import</li>
</ul>


<p>すべてのコマンドには man ページとインタラクティブヘルプが用意されてる。</p>

<p>クラスタのセットアップは以下の様に実行する。（node0 というのがマスタノードらしい。）</p>

<pre><code>node0# gnt-cluster init mycluster
node0# gnt-node add node1
node0# gnt-node add node2
node0# gnt-node add node3
node0# gnt-cluster cmmand apt-get install ganeti-instance-etch
</code></pre>

<p>インスタンスの作成。</p>

<pre><code>node0# gnt-instance add -n node2:node1 -t drbd8 instance0
</code></pre>

<p>ノードがクラッシュした場合に別ノードに移行させる。</p>

<pre><code>node0# gnt-instance failover --ignore-consitency instance0
node0# gnt-instance replace-disks -s --new-secodary=node3 instance0
</code></pre>

<p>クラスタのステータスチェックコマンド。</p>

<pre><code>node0# gnt-instance list
node0# gnt-node list
</code></pre>

<p>サポートしているディスクタイプは、</p>

<ul>
<li>plain</li>
<li>local_raid1</li>
<li>remote_raid1</li>
<li>drbd8(new)</li>
</ul>


<p>remote_raid1 はなんかすごい複雑だった。こんな感じ。</p>

<pre><code>          +---------------+
          | instance disk |
          +---------------+
                  |
            +-----------+
            | MD device |
            +-----------+
                  |
           +-------------+
           | DRBD device |
           +-------------+
             |         |
  +------------+     +------------+
  | LVM volume |     | LVM volume |
  +------------+     +------------+
        |                  |
+----------------+ +----------------+
| Physical disks | | Physical disks |
|     node1      | |     node2      |
+----------------+ +----------------+
</code></pre>

<p>DRBD8 を使えば、もっとシンプルにできるらしい。</p>

<p>ネットワークまわりの機能。（いまいちよくわからなかった。）</p>

<ul>
<li>Separate replication network</li>
<li>multiple bridges/VLAN support</li>
<li>Tagging(new)</li>
</ul>


<p>Google での使われ方。</p>

<ul>
<li>20-node Ganeti cluster</li>
<li>64-bit nodes OS</li>
<li>80 virtual isntances</li>
<li>used for internal systems</li>
<li>not used for google.com</li>
<li>best for non-resource intensive systems</li>
</ul>


<p>将来的に追加したい機能。</p>

<ul>
<li>automatic instance failover（ってことは今は自動でフェイルオーバーしない？）</li>
<li>automatic node allocation</li>
<li>master node election</li>
<li>manage GUI / meta-cluster manager</li>
</ul>


<p>全体的に気になること、わからないことだらけなんだけど、ソースが公開されてるから使ってみるのがてっとりばやそうだ。HA クラスタは今後うまく活用していきたいし、仮想化によるサーバ集約も興味があるので、時間を作ってぜひ検証してみたい。</p>

<p>そういえば、以前いた会社では、メールサーバなんかはよく HA クラスタ構成でサーバ構築してたけど、最近 HA クラスタはご無沙汰だなぁ。</p>

<p>Eメール送信元のレピュテーション（評価）を集約してシェアしよう、という試み。<a href="http://www.usenix.org/events/lisa07/tech/singaraju.html">概要はこちら</a>。<a href="http://isr.uncc.edu/repuscore/">プロジェクトページもある。</a></p>

<p>SPF, DKIM, SenderID といったいわゆる送信者認証技術は、From ドメインと送信元サーバの組み合わせが正しいかどうかを判断することができるが、これが正しいからといって、スパマーかどうかは判断ができない。（実際、スパマーはいち早くこれらの送信者認証技術に対応してきているらしい。）それを補うのがこの RepuScore であり、送信元に関する評価を集合知的に集めてシェアすることが目的。</p>

<p>SpamAssassin 用プラグインを近々公開予定らしい。</p>

<p>RepuScore で興味深かったのは、不正なレポートを行う（Sybil attacksと呼んでいた）評価者の重みを下げることによって、評価全体への影響を低くして、不正なデータ操作が行えないようにする仕組みがあること。</p>

<p>他のレピュテーションシステムとしては、<a href="http://www.returnpath.net/">SenderPath&#8217;s Sender Score</a> や <a href="http://www.habeas.com/en-US/Receivers/SenderIndex/">Habeas&#8217; SenderIndex</a> といったものがあるが、これらは IP アドレスベースのレピュテーションであり、RepuScore はドメインベースのレピュテーションである、という違いがある。（IPアドレスは組織間でシェアされていることもあるので、こういったレピュテーションシステムには向いていない、という記述もある。）</p>

<p>Gmail も自前でユーザに通知させるレピュテーションの仕組みを持っているが、Gmail の中で閉じられている。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/16/LISA07TechSessionFirstDay/">Lisa07 Tech Session First Day</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-16T07:09:21+09:00" pubdate>Nov 16<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>現在、<a href="http://www.usenix.org/events/lisa07/">LISA</a> という大規模システム管理者向けカンファレンスへの参加のため、ダラスに来ています。自分は 11/14 - 11/16 に開催されるテクニカルセッションのみに参加していて、本日はテクニカルセッションの初日でした。今日聞いた中で気になったテーマについて、さらっとご紹介、というか自分用にまとめてみます。</p>

<h1>CAMP: A Common API for Measuring Performance</h1>

<p>名前の通り、パフォーマンス計測のための API。異なる OS が混在する分散システムでのパフォーマンステストを正確に行うために、共通な API を定義しよう、という試み。</p>

<p><a href="http://www.usenix.org/events/lisa07/tech/gabel.html">概要はこちら</a>。ここから論文すべて（HTML or PDF）を参照できる。（2008年11月までは、USENIX メンバーじゃないとアクセスできない、と書いてあるけど、アクセス制限はかかってないみたい。いいのかな？）</p>

<p>CAMP は Python で実装されていて、以下のようなコードでパフォーマンスデータが取得できる。</p>

<pre><code>#!python
# Calculate the current transfer rate (Both
# in and out) for the given network adapter.
def BulkByteTransferRate(adapter):
    # Query CAMP for the initial state.
    initial = GetNetBytesSent(adapter)
    initial += GetNetBytesRecvd(adapter)
    time.sleep(SAMPLE_INTERVAL)
    # Query CAMP for the final state.
    final = GetNetBytesSent(adapter)
    final += GetNetBytesRecvd(adapter)
    return (final - initial)/SAMPLE_INTERVAL
</code></pre>

<p>GetNetBytesSent や GetNetBytesRecvd が CAMP によって提供されているメソッド。</p>

<p>現在対応している OS は、</p>

<ul>
<li>Linux 2.6</li>
<li>Win32 (Windows NT/2000/XP)</li>
<li>Solaris (SunOS kernel 5.x)</li>
</ul>


<p>の3種類。パフォーマンスデータの取得は、Linux では proc、Windows では Microsoft&#8217;s performance data handler (PDH) interface、Solaris では proc と kstat を利用しているとのこと。</p>

<p>論文の中では、CAMP によって取得できるパフォーマンスデータの妥当性に関する検証や、CAMP 自体のパフォーマンス、オーバーヘッドに関する検証データも載っている。</p>

<p>proc ファイルシステムへのアクセスオーバヘッドの低さから、特に Linux でのパフォーマンスは高いみたい。</p>

<p>パフォーマンスデータを取得するのであれば、SNMP でもできるのでは、と思ったけど、これについても論文でちゃんと触れられていて、SNMP は UDP によるアプリケーションプロトコルであり、CAMP を利用することで OS に依存しない SNMP エージェントを実装する、といった形での住み分けができる、といったことが書かれていた。</p>

<p><a href="http://wiki.csc.calpoly.edu/camp">CAMP の Trac サイト</a>が存在するけど、内容はまだ何もない。「<strong> Download coming soon! </strong>」ということなので、ソースが公開されたら要チェック。</p>

<h1>Application Buffer-Cache Management for Performance: Running the World’s Largest MRTG</h1>

<p>OS のディスク I/O 先読みとバッファキャッシュは通常、アプリケーションのパフォーマンスを高めるものであるが、大規模ネットワークで MRTG を運用していると、逆にパフォーマンスを低下させてしまう、ということについて、何がボトルネックになっているのか、どうやってそのボトルネックを解消するのか、といったことに関する考察。<a href="http://www.usenix.org/events/lisa07/tech/plonka.html">概要はこちら</a>。</p>

<p>まず、大規模ネットワークサイトでの MRTG の処理時間がグラフで示されている。これによると、5分おきに MRTG を実行しているにも関わらず、半分ほどの処理が5分以内に完了していない、という結果に。そして、MRTG のボトルネックはディスク I/O であり、特に read の比率が高い、ということが示されている。</p>

<p>MRTG は RRDtool を利用しているが、RRD ファイルは特性として、一度の操作で読み書きするブロックがシーケンシャルになっていない。そのため、OS がシーケンシャルにファイルを先読みすることによって、読み込む必要のないブロックまで読み込んでしまい、余分な I/O が発生する、ということがボトルネックの一因。いわゆる余計なお世話。</p>

<p>また、必要のないブロックを読み込んでバッファキャッシュに載せるため、キャッシュに本当に載せてほしいブロックが載らずに、ページフォルトが発生する、というのもボトルネックの一因。</p>

<p>この調査のために、<a href="http://net.doit.wisc.edu/~plonka/fincore/">fincore</a> という、指定したファイルのどのページがバッファキャッシュに載っているのかを表示するツールを作っている。</p>

<p>ボトルネックを解消するアプローチのひとつは、独自のキャッシュライブラリを作成して、MRTG にこのライブラリ経由でファイル操作をさせる、というもの。これにより、ほとんどの処理が1分以内で完了するようになった。（ただし、キャッシュの処理は図を見るとちょっと複雑。）</p>

<p>もうひとつのアプローチは、アプリケーションのファイルアクセス特性を OS に伝えることによって、OS のディスクI/O に関する挙動を変えたり、キャッシュアルゴリズムを変えたり、といったことが可能な、<a href="http://docs.hp.com/ja/B2355-60129/fadvise.2.html">POSIX fadvise システムコール</a>を利用して MRTG を動かす、というもの。</p>

<p><a href="http://net.doit.wisc.edu/~plonka/fadvise/">fadvise を実行する Perl スクリプト</a> も作成している。</p>

<p>論文では FADV_RANDOM を指定することによって、OS に対してアプリケーションが、シーケンシャルではなくランダムにファイルアクセスすることを伝えている。これにより OS は先読みをしなくなり余計なI/Oが発生しないし、余分なデータを読み込まないのでバッファキャッシュも無駄なく利用できる。（FADV_RANDOM という言葉は出てないけど、たぶんそうだと思う。）</p>

<p>このアプローチでもほとんどの処理が1分以内に完了する、という結果に。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/12/PerlbalPluginProxyPass/">Perlbal Plugin Proxy Pass</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-12T00:15:48+09:00" pubdate>Nov 12<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Perlbal で Vpaths プラグインをつかって、</p>

<pre><code>LOAD vpaths

CREATE POOL apache
  POOL apache ADD 127.0.0.1

CREATE SERVICE apache_proxy
  SET role = reverse_proxy
  SET pool = apache
ENABLE apache_proxy

CREATE SERVICE selector
  SET   listen  = 0.0.0.0:8080
  SET   role    = selector
  SET   plugins = vpaths
  VPATH /apache = apache_proxy
ENABLE selector
</code></pre>

<p>みたいな設定をすると、</p>

<pre><code>http://localhost:8080/apache -&gt; http://localhost:80/apache
</code></pre>

<p>といった形でプロキシしてくれるんだけど、これを</p>

<pre><code>http://localhost:8080/apache -&gt; http://localhost:80/
</code></pre>

<p>としたくてプラグイン書いてみた。もしかしてプラグイン書かなくてもできるかもしれないけど、やり方がわからなかったのと、プラグインを書く練習ってことで。プラグイン名は Apache mod_proxy の ProxyPass ディレクティブにちなんでます。</p>

<pre><code>#!perl
package Perlbal::Plugin::ProxyPass;

use strict;
use warnings;

sub load {
    my $class = shift;

    Perlbal::register_global_hook('manage_command.proxypass', sub {
        my $mc = shift-&gt;parse(qr/proxypass\s+(?:(\w+)\s+)?(\S+)\s*=\s*(\S+)$/,
                              "usage: ProxyPass [&lt;service&gt;] &lt;source path&gt; = &lt;dest path&gt;");
        my ($selname, $source, $target) = $mc-&gt;args;
        unless ($selname ||= $mc-&gt;{ctx}{last_created}) {
            return $mc-&gt;err("omitted service name not implied from context");
        }

        my $ss = Perlbal-&gt;service($selname);
        return $mc-&gt;err("Service '$selname' is not a reverse_proxy service")
            unless $ss &amp;&amp; $ss-&gt;{role} eq "reverse_proxy";

        $ss-&gt;{extra_config}-&gt;{_proxypass} ||= [];
        push @{$ss-&gt;{extra_config}-&gt;{_proxypass}}, [ $source, $target ];

        return $mc-&gt;ok;
    });

    return 1;
}

sub register {
    my ($class, $svc) = @_;
    unless ($svc &amp;&amp; $svc-&gt;{role} eq "reverse_proxy") {
        die "You can't load the proxypass plugin on a service not of role reverse_proxy.\n";
    }

    $svc-&gt;register_hook(
        'ProxyPass' =&gt; 'start_proxy_request', sub {
            my Perlbal::ClientProxy $client = shift;
            for my $proxypass ( @{ $svc-&gt;{extra_config}-&gt;{_proxypass} } ) {
                my $source = $proxypass-&gt;[0];
                my $target = $proxypass-&gt;[1];
                $client-&gt;{req_headers}-&gt;{uri} =~ s/$source/$target/;
                $client-&gt;{req_headers}-&gt;{uri} =~ s!//!/!;
            }
            return 0;
        }
    );

    return 1;
}

1;
</code></pre>

<p>設定はこんな感じ。</p>

<pre><code>LOAD vpaths
LOAD ProxyPass

CREATE POOL apache
  POOL apache ADD 127.0.0.1

CREATE SERVICE apache_proxy
  SET       role    = reverse_proxy
  SET       pool    = apache
  SET       plugins = ProxyPass
  ProxyPass /apache = /   
ENABLE apache_proxy

CREATE SERVICE selector
  SET   listen  = 0.0.0.0:8080
  SET   role    = selector
  SET   plugins = vpaths
  VPATH /apache = apache_proxy
ENABLE selector
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/08/CampAndLisa/">Camp And Lisa</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-08T17:35:02+09:00" pubdate>Nov 8<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>今出張で福岡に来ていて、これから帰るところなのですが、帰ったと思ったら明日はペパボの<a href="http://www.paperboy.co.jp/next/osan/">開発合宿</a>です。</p>

<p>で、13日からは<a href="http://www.usenix.org/events/lisa07/">LISA</a>のテクニカルセッションへの参加のため、ダラスに行ってきます。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/10/28/ModSuid2AndModRuidAndLinuxCapability/">Mod Suid2 And Mod Ruid And Linux Capability</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-10-28T01:45:53+09:00" pubdate>Oct 28<span>th</span>, 2007</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Apache の suEXEC では setuid/setgid を使って、httpd 実行ユーザとは異なるユーザ権限で CGI プログラムや SSI プログラムを実行できるわけですが、mod_php で処理される PHP プログラムのように、httpd 内で処理されるプログラムは、httpd 実行ユーザの権限で実行されてしまいます。こういったものまで httpd とは異なるユーザ権限で実行するためのモジュールとして、<a href="http://bluecoara.net/download/mod_suid2/">mod_suid2</a> や <a href="http://websupport.sk/~stanojr/projects/mod_ruid/">mod_ruid</a> といったものがあります。</p>

<p>mod_suid2 は、httpd を root で起動しておいて、リクエストに応じて（VirtualHost 単位等で）setuid/setgid して実行ユーザを切り替える、という動作をします。そのため、以下のような問題があります。</p>

<ul>
<li>-DBIG_SECURITY_HOLE つきで Apache をコンパイルする必要がある。</li>
<li>root でプロセスを起動する危険性。</li>
<li>MaxRequestsPerChild が 1 に設定されることによるパフォーマンスの劣化。（一度 setuid/setgid してしまうと、root ではなくなり setuid/setgid できなくなるので、リクエストを処理するたびにプロセス/スレッドを殺す必要があるため）</li>
</ul>


<p>これに対し、mod_ruid は Linux に実装されている POSIX 1003.1e で定義された<a href="http://opentechpress.jp/security/03/08/06/0941214.shtml">ケーパビリティ</a> を利用して、root で httpd を起動することなく、setuid/segid できる権限のみ与えて、プロセス/スレッドの実行ユーザを切り替えています。そのため、mod_suid2 が抱える問題点の多くを解消しています。（また、mod_suid2 と違い、参照するファイルやディレクトリのユーザ/グループに実行権限を切り替える機能もあります。）</p>

<p>ここで気になったのは、「setuid/setgid って、プロセス単位じゃなくてスレッド単位でもできるの？」ということ。もしできないのであれば、worker ではなく prefork で動かす必要もある、ということになる。で、結論からいうと「できる」でした。<a href="http://d.hatena.ne.jp/naoya/20071010/1192040413">マルチスレッドのコンテキスト切り替えに伴うコスト - naoyaのはてなダイアリー</a> をご覧になると分かるように、スレッドを生成する毎に dup_task_struct(current) して、各スレッドが個別にプロセスディスクリプタを持つので、当然と言えば当然なのですが、mod_ruid を有効にした Apache のプロセス状態を表示することによって、スレッドごとに実行ユーザがちゃんと異なっていることを確認しました。（mod_ruid はリクエスト処理後に元のユーザに戻してしまうため、確認のため戻さないようにソースを少しいじってます。）</p>

<pre><code>$ ps -efL
UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD 
daemon    4156  4153  4188  0   27 20:48 ?        00:00:00 /usr/local/apache2/bin/httpd -k start 
miya      4156  4153  4189  0   27 20:48 ?        00:00:00 /usr/local/apache2/bin/httpd -k start
puppet    4156  4153  4225  0   27 20:48 ?        00:00:00 /usr/local/apache2/bin/httpd -k start
</code></pre>

<p>ちなみに、Linux での setuid の処理は、kernel/sys.c で以下のようになっています。</p>

<pre><code>#!c
asmlinkage long sys_setuid(uid_t uid)
{
    int old_euid = current-&gt;euid;
    int old_ruid, old_suid, new_suid;
    int retval;

    retval = security_task_setuid(uid, (uid_t)-1, (uid_t)-1, LSM_SETID_ID);
    if (retval)
        return retval;

    old_ruid = current-&gt;uid;
    old_suid = current-&gt;suid;
    new_suid = old_suid;

    if (capable(CAP_SETUID)) {
        if (uid != old_ruid &amp;&amp; set_user(uid, old_euid != uid) &lt; 0)
            return -EAGAIN;
        new_suid = uid;
    } else if ((uid != current-&gt;uid) &amp;&amp; (uid != new_suid))
        return -EPERM;

    if (old_euid != uid) {
        set_dumpable(current-&gt;mm, suid_dumpable);
        smp_wmb();
    }
    current-&gt;fsuid uid;
    current-&gt;suid = new_suid;

    key_fsuid_changed(current);
    proc_id_connector(current, PROC_EVENT_UID);

    return security_task_post_setuid(old_ruid, old_euid, old_suid, LSM_SETID_ID);
}
</code></pre>

<p>task_struct 構造体の、fsuid, euid, suid あたりを書き換えているようですね。</p>

<p>まとまりのないエントリになってしまいましたが、ケーパビリティとか、スレッド単位で setuid/setgid できるとか、はじめて知ることが多かったのでとりあえずメモ。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/13/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/11/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/03/31/puppet-report-ikachan/">puppet-report-ikachan</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/03/07/image-with-exif-tag-plugin/">Image with EXIF tag plugin</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/03/07/exif-tag-plugin/">EXIF tag plugin</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/03/04/rakuten-tag-plugin/">Rakuten tag plugin for Jekyll</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/02/29/paperboys-engineer-evaluation-system/">Paperboy&#8217;s engineer evaluation system</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Coderwall</h1>
  <p>
  <script type="text/javascript">
    function display_coderwall(args) {
        var badges = args["data"]["badges"];
        for ( var i = 0; i < badges.length; i++ ) {
            document.write('<img src="'+ badges[i]["badge"] + '" width="48" height="48" />');
        }
    }
  </script>
  <script src="http://coderwall.com/mizzy.json?callback=display_coderwall"></script>
  </p>
  <p style="text-align: right;"><a href="http://coderwall.com/mizzy">Powered by coderwall.com</a></p>
</section>


<section>
  <h1>Github Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/mizzy">@mizzy</a> on Github
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'mizzy',
            count: 30,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Gosuke Miyashita -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'mizzyorg';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
