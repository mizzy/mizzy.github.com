
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Gosuke Miyashita</title>
  <meta name="author" content="Gosuke Miyashita">

  
  <meta name="description" content="Open Tech Press で知った、Func がおもしろそうだ。 とりあえずどんなツールかを要約すると、 複数のサーバに対して、何らかの処理を一括でまとめて実行して結果が取得できる。たとえば、yum でパッケージをインストールとか。
「何らかの処理」の部分は、モジュールで拡張できる。
「 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mizzy.org/blog/page/11">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Gosuke Miyashita" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-53984-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Gosuke Miyashita</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mizzy.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/08/FuncIntro/">FuncIntro</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-08T01:58:14+09:00" pubdate>Dec 8<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/12/08/FuncIntro/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://opentechpress.jp/developer/07/12/06/0046247.shtml">Open Tech Press</a> で知った、<a href="https://hosted.fedoraproject.org/projects/func/">Func</a> がおもしろそうだ。</p>

<p>とりあえずどんなツールかを要約すると、</p>

<ul>
<li>複数のサーバに対して、何らかの処理を一括でまとめて実行して結果が取得できる。たとえば、yum でパッケージをインストールとか。</li>
<li>「何らかの処理」の部分は、モジュールで拡張できる。</li>
<li>「何らかの処理」はコマンドラインから実行して単に結果を表示、ということもできるし、Python API でプログラマブルに処理することもできる。</li>
<li>クライアント/サーバアーキテクチャ</li>
</ul>


<p>これだけだと何となくわかるようでわからない。触ってみるのが一番。というわけでまずはインストール。</p>

<h1>インストール</h1>

<p><a href="https://hosted.fedoraproject.org/projects/func/wiki/InstallAndSetupGuide">InstallAndSetupGuide</a> を読むと、（おそらく最近の）Fedora であれば yum 一発でインストールできるみたいだけど、手元にある CentOS 5 用のパッケージがなさそうなので、ソース RPM からパッケージをつくる。（noarch なので FC7 用でもそのまま入りそうだけど、せっかくだからつくってみる。）</p>

<p>まずは <a href="https://hosted.fedoraproject.org/projects/func/wiki/FuncReleases">FuncReleases</a> から func-0.13-3.fc7.src.rpm をゲット。</p>

<p>次にソース RPM からリビルドするために必要なパッケージをインストール。</p>

<pre><code>$ sudo yum -y install rpm-build python-devel python-setuptools 
</code></pre>

<p>リビルドしてインストール。依存パッケージの PyOpenSSL も忘れずに。</p>

<pre><code>$ sudo rpmbuild --rebuild func-0.13-3.fc7.src.rpm
$ sudo yum -y install pyOpenSSL
$ sudo rpm -ivh /usr/src/redhat/RPMS/noarch/func-0.13-3.noarch.rpm
</code></pre>

<p>サーバを起動する。サーバは master と呼ばれるみたい。</p>

<pre><code>$ sudo /etc/init.d/certmaster start
</code></pre>

<p>次にクライアント側。クライアントは minion と呼ばれているようだ。インストール手順は master と同じなので省略。</p>

<p>クライアント側では設定ファイル /etc/func/minion.conf を修正する必要がある。といっても、certmaster で master を指定してあげるだけでとりあえず OK。</p>

<pre><code># configuration for minions

[main]
log_level = DEBUG
certmaster = server.example.org
cert_dir = /etc/pki/func
acl_dir = /etc/func/minion-acl.d 
</code></pre>

<p>クライアント側で常駐するデーモン funcd を起動。</p>

<pre><code>$ sudo /etc/init.d/funcd start   
</code></pre>

<p>master と minion の通信は SSL 証明書での認証が必要なので、master 側で証明書リクエストに対して署名を行う。（この辺りはPuppetと一緒だ。）</p>

<pre><code>$ sudo certmaster-ca --list
client.example.org
$ sudo certmaster-ca --sign client.example.org
</code></pre>

<p>これで使うための準備はできた。</p>

<h1>コマンド実行</h1>

<p>master 上で func コマンドを実行する。まずは minion の一覧を表示。</p>

<pre><code>$ sudo func "*" list_minions
['https://client0.example.org:51234', 'https://client1.example.org:51234']
client0.example.org
client1.example.org
0
</code></pre>

<p>www ではじまる minion だけを表示。</p>

<pre><code>$ sudo func "www*" list_minions
['https://www0.example.org:51234', 'https://www1.example.org:51234']
www0.example.org
www1.example.org
0
</code></pre>

<p>各 minion で利用できるモジュールの一覧を表示。</p>

<pre><code>$ sudo func "*" call system list_modules
on https://client0.example.org:51234 running system list_modules ()
['command', 'copyfile', 'func_module', 'hardware', 'nagios-check', 'process', 'reboot', 'rpms', 'service', 'smart', 'snmp', 'test', 'yum']
on https://client1.example.org:51234 running system list_modules ()
['command', 'copyfile', 'func_module', 'hardware', 'nagios-check', 'process', 'reboot', 'rpms', 'service', 'smart', 'snmp', 'test', 'yum']
{'client0.example.org': ['command',
                        'copyfile',
                        'func_module',
                        'hardware',
                        'nagios-check',
                        'process',
                        'reboot',
                        'rpms',
                        'service',
                        'smart',
                        'snmp',
                        'test',
                        'yum'],
 'client1.example.org': ['command',
                        'copyfile',
                        'func_module',
                        'hardware',
                        'nagios-check',
                        'process',
                        'reboot',
                        'rpms',
                        'service',
                        'smart',
                        'snmp',
                        'test',
                        'yum']}   
</code></pre>

<p>service モジュールで使えるメソッド一覧を表示。</p>

<pre><code>$ sudo func "client0.example.org" call service list_methods
on https://client0.example.org:51234 running service list_methods ()
['status', 'reload', 'get_running', 'stop', 'start', 'inventory', 'get_enabled', 'restart', 'module_description', 'module_version', 'module_api_version', 'list_methods']
{'client0.example.org': ['status',
                        'reload',
                        'get_running',
                        'stop',
                        'start',
                        'inventory',
                        'get_enabled',
                        'restart',
                        'module_description',
                        'module_version',
                        'module_api_version',
                        'list_methods']} 
</code></pre>

<p>service モジュールの status メソッドで ntpd の起動状態を確認。以下はすべての minion で ntpd が停止してる状態での実行結果。</p>

<pre><code>$ sudo func "*" call service status ntpd
on https://client0.example.org:51234 running service status (ntpd)
3
on https://client1.example.org:51234 running service status (ntpd)
3
{'client1.example.org': 3, 'client0.example.org': 3}
</code></pre>

<p>ntpd を起動。</p>

<pre><code>$ sudo func "*" call service start ntpd
on https://client0.example.org:51234 running service start (ntpd)
0
on https://client1.example.org:51234 running service start (ntpd)
0
{'client1.example.org': 0, 'client0.example.org': 0}   
</code></pre>

<p>ntpd の起動状態を確認。</p>

<pre><code>$ sudo func "*" call service status ntpd
on https://client0.example.org:51234 running service status (ntpd)
0
on https://client1.example.org:51234 running service status (ntpd)
0
{'client1.example.org': 0, 'client0.example.org': 0}   
</code></pre>

<p>*.example.org のみをターゲットにする。</p>

<pre><code>$ sudo func "*.example.org" call service status ntpd
on https://client0.example.org:51234 running service status (ntpd)
0
on https://client1.example.org:51234 running service status (ntpd)
0
{'client1.example.org': 0, 'client0.example.org': 0}   
</code></pre>

<p>client0.example.org と client1.example.org のみをターゲットにする。</p>

<pre><code>$ sudo func "client0.example.org; client1.example.org" call service status ntpd
on https://client0.example.org:51234 running service status (ntpd)
0
on https://client1.example.org:51234 running service status (ntpd)
0
{'client1.example.org': 0, 'client0.example.org': 0}   
</code></pre>

<p>ここまで実行してみれば、何となく感じは掴めると思う。</p>

<h1>モジュール</h1>

<p>デフォルトで付属しているモジュールには以下のものがある。</p>

<ul>
<li>command</li>
<li>copyfile</li>
<li>func_module</li>
<li>hardware</li>
<li>nagios-check</li>
<li>process</li>
<li>reboot</li>
<li>rpms</li>
<li>service</li>
<li>smart</li>
<li>snmp</li>
<li>test</li>
<li>yum</li>
</ul>


<p><a href="https://hosted.fedoraproject.org/projects/func/#ListofStockModules">使い方はこの辺参照。</a></p>

<p>とりあえず</p>

<pre><code>$ sudo func client0.example.org system list_modules
</code></pre>

<p>で利用できるモジュールを調べて、</p>

<pre><code>$sudo func client0.example.org call module list_methods
</code></pre>

<p>でモジュールで使えるメソッド一覧を表示してみると、どんなモジュールがあるか、そのモジュールはどんなことができるのか、がおおよそわかるはず。</p>

<h1>モジュールの書き方</h1>

<p><a href="https://hosted.fedoraproject.org/projects/func/wiki/HowToWriteAndDistributeNewModules">ここに書かれてる。</a>これで自分が好きなように機能拡張ができる。</p>

<h1>Python プログラムから呼び出し</h1>

<p><a href="https://hosted.fedoraproject.org/projects/func/wiki/PythonApiExamples">ここにサンプルがある。</a></p>

<p>今後は [wiki:Func こちらの Wiki ページ] に情報まとめていく予定。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/08/Func/">Func</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-08T01:22:24+09:00" pubdate>Dec 8<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/12/08/Func/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://hosted.fedoraproject.org/projects/func/">Func</a> に関するまとめ Wiki。内容はまだなし。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/07/PuppetDojo2/">PuppetDojo2</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-07T15:50:13+09:00" pubdate>Dec 7<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/12/07/PuppetDojo2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://trombik.mine.nu/~cherry/w/index.php/2007/07/07/1014/puppet-dojo">以前行われた Puppet セミナー</a>の第2回目が開催されます。第1回目に引き続き、またお手伝いさせて頂きます。</p>

<p>今回は3日に渡って以下の様なスケジュールで行われます。</p>

<ul>
<li><p>2007/12/17(月) 19:00～20:30</p>

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=506">オープンソースでシステム管理の自動化を実現！ Puppetを使うこれだけの理由</a></li>
</ul>
</li>
<li><p>2007/12/18(火)</p>

<ul>
<li>15:00～17:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=507">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #1</a></li>
</ul>
</li>
<li>19:00～21:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=508">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #2</a></li>
</ul>
</li>
</ul>
</li>
<li><p>2007/12/19(水)</p>

<ul>
<li>15:00～17:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=509">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #1</a></li>
</ul>
</li>
<li>19:00～21:00

<ul>
<li><a href="http://www.pasonatech.co.jp/event/index.jsp?no=510">オープンソースでシステム管理の自動化を実現！ Puppet Dojo #2</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<p>12/18 と 12/19 は同じ内容のものが実施されます。Puppet Dojo !#1 は前回のセミナーと同内容のものを少し簡略化した内容で、Puppet Dojo !#2 は新しい内容となります。詳細はリンク先をご参照ください。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/12/03/PacSec2007/">PacSec2007</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-12-03T23:50:14+09:00" pubdate>Dec 3<span>rd</span>, 2007</time>
        
         | <a href="/blog/2007/12/03/PacSec2007/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://trombik.mine.nu/~cherry/w/">桜井さん</a>のご好意により、11月29日, 30日に行われた、<a href="http://pacsec.jp/">PacSec 2007</a>というコンピュータセキュリティに関するカンファレンスに参加してきました。このカンファレンスは、日本以外でも、カナダ(CanSecWest)、イギリス(EuSecWest)で行われているようです。また、カンファレンスに先立って、27日、28日には<a href="http://www.pacsec.jp/dojo.html">セキュリティ・マスターズ道場</a>と題したトレーニングも行われていました。</p>

<p>自分はセキュリティ情報はあまりウォッチしておらず、苦手な分野ではあるのですが、その分知らないことだらけでとても新鮮で、刺激的なカンファレンスでした。内容の半分も理解できていませんが。</p>

<p>特に興味深かったセッションと簡単なメモです。（メモしたファイルは会社の PC にあって今見られないので、記憶を辿りながら書きます。間違いが多かったらすみません。）</p>

<ul>
<li>Microsoft Officeのゼロデイと悪いヤツら - Takumi Onodera Microsoft

<ul>
<li>Microsoft Office セキュリティに関する話。</li>
<li>SDL(Security Development Lifecycle)という言葉をはじめて聞いた。</li>
<li><a href="http://www.microsoft.com/technet/sysinternals/utilities/processexplorer.mspx">Process Explorer</a> とか <a href="http://www.microsoft.com/technet/sysinternals/utilities/processmonitor.mspx">Process Monitor</a> というツールをはじめて知った。</li>
<li>これらのツールをつかって、不正なバイナリコードが埋め込まれた PowerPoint ファイルを開き、不正コードへのファイルへの書き出しや実行が行われる様子を具体的に見ることができておもしろい。</li>
<li>「攻撃を防ぐための完璧な対策はない。攻撃される可能性を減らすための対策を積み重ねていくことが重要」</li>
</ul>
</li>
<li>TOMOYO Linux: Linuxサーバを理解し守る実践的な手法 - Toshiharu Harada 株式会社NTTデータ

<ul>
<li>専用のポリシーエディタが付属しており、init からはじまるプロセスが起動された状態をツリー構造で表示したり、各プロセスが読み書きするファイルを表示したり、各プロセスごとにアクセスポリシーを設定したり、ということができる。</li>
<li>SELinux はめんどくさすぎて使う気にはなれないけど、TOMOYO Linux のポリシーエディタは使いやすそうだ。</li>
<li>同じプロセスであっても「どのプロセスから起動されたか」によって別々のポリシーを設定することもできるらしい。</li>
</ul>
</li>
<li>Agent-oriented SQL Abuse - Fernando Russ &amp; Diego Tiscornia, Core

<ul>
<li><a href="http://www.coresecurity.com/">Core Security Technologies</a> という会社の人がスピーカ。</li>
<li>Python でできた、SQL を HTTP リクエストに変換して、SQL インジェクションのペネトレーションテストを行うためのフレームワーク。</li>
<li>残念ながら、ソースは公開されてなさそう。（おそらくこのツールによる自社の優位性、というのもあるだろうし、悪用される恐れもあるだろうし。）</li>
<li>他のセッションでも、Python で作られたツールの話があった。セキュリティ分野は Python がよく使われてるのかな？</li>
</ul>
</li>
<li>Fuzzing Frameworks, Fuzzing Languages!? - Stephen Ridley &amp; Colin Delaney, McAfee

<ul>
<li><a href="http://en.wikipedia.org/wiki/Fuzz_testing">Fuzzing</a> というテスト手法ははじめて聞いた。</li>
<li><a href="http://ruxxer.com/">Ruxxer</a> という Fuzzing のためのフレームワーク。</li>
<li>従来のツールは「使いやすいけど機能に乏し」かったり「機能は豊富だけど使いにくい」という問題がある。</li>
<li>それを解決するために、独自の言語を定義することによって「使いやすさ」を提供し、Python API によって「豊富な機能」を提供。</li>
</ul>
</li>
<li>Developing Fuzzers with Peach - Michael Eddington, Leviathan Security

<ul>
<li><a href="http://peachfuzz.sourceforge.net/">Peach</a> というツール。こちらも Fuzzing のためのフレームワーク。これも Python 製らしい。</li>
<li>Windows 上で動く GUI ツール。</li>
<li>Python APIや C, .NET, Java, COM, XPCOM のバインディングもある。</li>
</ul>
</li>
</ul>


<p>PacSec 2007 に関するインタビュー記事も見つけたので載せておきます。</p>

<ul>
<li>http://itpro.nikkeibp.co.jp/article/Interview/20071121/287737/</li>
<li>http://japan.zdnet.com/sp/interview/story/0,2000056426,20361870,00.htm</li>
</ul>


<p>主催の Dragos さんと軽く話をしたのですが、現地の運営スタッフが足りない、と嘆いていました。なので、来年はぜひ運営のお手伝いをさせてもらおうかな、と思っています。もし、運営スタッフやってもいいよ、という方がいらっしゃいましたら、gosukenator at gmail.com までご連絡ください。</p>

<p>参加者は半数ぐらいは海外の方で、懇親会では更に海外の方の割合が増す、という状態でしたので、海外のセキュリティエンジニアとお友達になりたい方にはチャンスですよ。</p>

<p>自分は <a href="http://search.cpan.org/dist/Apache-SMTP/">Apache::SMTP</a> という Apache を SMTP サーバにしてしまう mod_perl プログラムを書いてる方（ActiveState にいたこともあるそうです）や、OpenBSD の pf 開発者の一人である <a href="http://kerneltrap.org/node/2873">Ryan</a> さん（Puppet の OpenBSD まわりのメンテもしているそうです）とお話することができました。</p>

<p>が、自分の英語力不足もあってあまり深い話はできなかったので、<a href="http://www.iknow.co.jp/">iKnow!</a>で英語勉強します。（英語だけじゃなく、セキュリティ関連の知識不足もありますが…）</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/20/library-perl-trunk-Text-Trac-lib-Text-Trac.pm/">library/perl/trunk/Text-Trac/lib/Text/Trac.pm</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-20T23:20:38+09:00" pubdate>Nov 20<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/11/20/library-perl-trunk-Text-Trac-lib-Text-Trac.pm/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>source:library/perl/trunk/Text-Trac/lib/Text/Trac.pm</p>

<h1>NAME</h1>

<p>Text::Trac - Perl extension for formatting text with Trac Wiki Style.</p>

<h1>VERSION</h1>

<p>Version 0.08</p>

<h1>SYNOPSIS</h1>

<pre><code>    use Text::Trac;

    my $parser = Text::Trac-&gt;new(
        trac_url      =&gt; 'http://trac.mizzy.org/public/',
        disable_links =&gt; [ qw( changeset ticket ) ],
    );

    $parser-&gt;parse($text);

    print $parser-&gt;html;
</code></pre>

<h1>DESCRIPTION</h1>

<p>Text::Trac parses text with Trac WikiFormatting and convert it to html format.</p>

<h1>METHODS</h1>

<h2>new</h2>

<p>Constructs Text::Trac object.</p>

<p>Available arguments are:</p>

<h3>trac_url</h3>

<p>Base URL for TracLinks.Default is /. You can specify each type of URL individually. Available URLs are:</p>

<p> trac_attachment_url::  trac_changeset_url::  trac_log_url::  trac_milestone_url::  trac_report_url::  trac_source_url::  trac_ticket_url::  trac_wiki_url::</p>

<h3>disable_links</h3>

<p>Specify TracLink types you want to disable. All types are enabled if you don&#8217;t specify this option.</p>

<pre><code>    my $parser = Text::Trac-&gt;new(
        disable_links =&gt; [ qw( changeset ticket ) ],
    );
</code></pre>

<h3>enable_links</h3>

<p>Specify TracLink types you want to enable.Other types are disabled. You cannot use both disable_links and enable_links at once.</p>

<pre><code>    my $parser = Text::Trac-&gt;new(
        enable_links =&gt; [ qw( changeset ticket ) ],
    );
</code></pre>

<h2>parse</h2>

<p>Parses text and converts it to html format.</p>

<h2>process</h2>

<p>An alias of parse method.</p>

<h2>html</h2>

<p>Return converted html string.</p>

<h1>SEE ALSO</h1>

<p> Text::Hatena::  Trac http://www.edgewall.com/trac/::  Trac WikiFormatting http://projects.edgewall.com/trac/wiki/WikiFormatting::</p>

<h1>AUTHORS</h1>

<p>Gosuke Miyashita, <code>&lt;gosukenator at gmail.com&gt;</code></p>

<p>Hideaki Tanaka, <code>&lt;drawn.boy at gmail.com)&gt;</code></p>

<h1>BUGS</h1>

<p>Please report any bugs or feature requests to <code>bug-text-trac at rt.cpan.org</code>, or through the web interface at http://rt.cpan.org/NoAuth/ReportBug.html?Queue=Text-Trac. I will be notified, and then you&#8217;ll automatically be notified of progress on your bug as I make changes.</p>

<h1>SUPPORT</h1>

<p>You can find documentation for this module with the perldoc command.</p>

<pre><code>    perldoc Text::Trac
</code></pre>

<p>You can also look for information at:</p>

<ul>
<li>AnnoCPAN: Annotated CPAN documentation</li>
</ul>


<p> http://annocpan.org/dist/Text-Trac</p>

<ul>
<li>CPAN Ratings</li>
</ul>


<p> http://cpanratings.perl.org/d/Text-Trac</p>

<ul>
<li>RT: CPAN&#8217;s request tracker</li>
</ul>


<p> http://rt.cpan.org/NoAuth/Bugs.html?Dist=Text-Trac</p>

<ul>
<li>Search CPAN</li>
</ul>


<p> http://search.cpan.org/dist/Text-Trac</p>

<h1>COPYRIGHT &amp; LICENSE</h1>

<p>Copyright 2006 Gosuke Miyashita, all rights reserved.</p>

<p>This program is free software; you can redistribute it and/or modify it under the same terms as Perl itself.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/17/SoftwareDesign200712Puppet/">SoftwareDesign200712Puppet</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-17T00:37:00+09:00" pubdate>Nov 17<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/11/17/SoftwareDesign200712Puppet/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Software Design 2007年12月号の Puppet 特集を執筆させて頂きました。</p>

<p>概要や各章のタイトルは <a href="http://d.hatena.ne.jp/software_design/20071116">Software Design 2007年12月号のお知らせ - Software Design×はてな</a> をご参照下さい。</p>

<p><a href="http://gihyo.jp/admin/serial/01/puppet">gihyo.jp での連載</a> をベースに、大幅に加筆、修正した内容となっており、リファレンスも含めて約50ページと、かなりのボリュームです。特にリファレンスは、各リソースタイプとパラメータがコンパクトにまとまっているので、手元に置いておくととても便利ですよ。</p>

<p>以上宣伝でした。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/16/Lisa07TechSession2ndDay/">Lisa07TechSession2ndDay</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-16T14:32:03+09:00" pubdate>Nov 16<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/11/16/Lisa07TechSession2ndDay/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://www.usenix.org/events/lisa07/">LISA&#8217;07</a> テクニカルセッション2日目の、気になったテーマに関する簡単なメモ。</p>

<h1>Ganeti: An Open Source Multi-Node HA Cluster Based on Xen</h1>

<p>Google でつくられている Xen ベースのオープンソースなマルチノード HA クラスタ（タイトルまんま）。<a href="http://code.google.com/p/ganeti/">プロジェクトページはこちら</a>。</p>

<p>要するに HA + Virtualization。通常の HA は、実マシンから実マシンへフェイルオーバするけど、Ganeti では VM から VM へフェイルオーバーする、と。仮想化は Xen を利用しており、管理用コマンドラインツールには Python を、ディスク管理には LVM, DRBD, MD を、コマンドラインツールから各ノード（Xen dom0）やインスタンス（Xen domU）への命令実行は、Twisted や ssh を利用している。</p>

<p>管理コマンドはマスタノード上で実行する。</p>

<ul>
<li>gnt-node add/remove/list cluster nodes</li>
<li>gnt-instance

<ul>
<li>add/remove</li>
<li>failover</li>
<li>stop/start change params</li>
</ul>
</li>
<li>gnt-os: instance os definitions</li>
<li>gnt-cluster: cluster commands</li>
<li>gnt-backup: instance export and import</li>
</ul>


<p>すべてのコマンドには man ページとインタラクティブヘルプが用意されてる。</p>

<p>クラスタのセットアップは以下の様に実行する。（node0 というのがマスタノードらしい。）</p>

<pre><code>node0# gnt-cluster init mycluster
node0# gnt-node add node1
node0# gnt-node add node2
node0# gnt-node add node3
node0# gnt-cluster cmmand apt-get install ganeti-instance-etch
</code></pre>

<p>インスタンスの作成。</p>

<pre><code>node0# gnt-instance add -n node2:node1 -t drbd8 instance0
</code></pre>

<p>ノードがクラッシュした場合に別ノードに移行させる。</p>

<pre><code>node0# gnt-instance failover --ignore-consitency instance0
node0# gnt-instance replace-disks -s --new-secodary=node3 instance0
</code></pre>

<p>クラスタのステータスチェックコマンド。</p>

<pre><code>node0# gnt-instance list
node0# gnt-node list
</code></pre>

<p>サポートしているディスクタイプは、</p>

<ul>
<li>plain</li>
<li>local_raid1</li>
<li>remote_raid1</li>
<li>drbd8(new)</li>
</ul>


<p>remote_raid1 はなんかすごい複雑だった。こんな感じ。</p>

<pre><code>          +---------------+
          | instance disk |
          +---------------+
                  |
            +-----------+
            | MD device |
            +-----------+
                  |
           +-------------+
           | DRBD device |
           +-------------+
             |         |
  +------------+     +------------+
  | LVM volume |     | LVM volume |
  +------------+     +------------+
        |                  |
+----------------+ +----------------+
| Physical disks | | Physical disks |
|     node1      | |     node2      |
+----------------+ +----------------+
</code></pre>

<p>DRBD8 を使えば、もっとシンプルにできるらしい。</p>

<p>ネットワークまわりの機能。（いまいちよくわからなかった。）</p>

<ul>
<li>Separate replication network</li>
<li>multiple bridges/VLAN support</li>
<li>Tagging(new)</li>
</ul>


<p>Google での使われ方。</p>

<ul>
<li>20-node Ganeti cluster</li>
<li>64-bit nodes OS</li>
<li>80 virtual isntances</li>
<li>used for internal systems</li>
<li>not used for google.com</li>
<li>best for non-resource intensive systems</li>
</ul>


<p>将来的に追加したい機能。</p>

<ul>
<li>automatic instance failover（ってことは今は自動でフェイルオーバーしない？）</li>
<li>automatic node allocation</li>
<li>master node election</li>
<li>manage GUI / meta-cluster manager</li>
</ul>


<p>全体的に気になること、わからないことだらけなんだけど、ソースが公開されてるから使ってみるのがてっとりばやそうだ。HA クラスタは今後うまく活用していきたいし、仮想化によるサーバ集約も興味があるので、時間を作ってぜひ検証してみたい。</p>

<p>そういえば、以前いた会社では、メールサーバなんかはよく HA クラスタ構成でサーバ構築してたけど、最近 HA クラスタはご無沙汰だなぁ。</p>

<p>Eメール送信元のレピュテーション（評価）を集約してシェアしよう、という試み。<a href="http://www.usenix.org/events/lisa07/tech/singaraju.html">概要はこちら</a>。<a href="http://isr.uncc.edu/repuscore/">プロジェクトページもある。</a></p>

<p>SPF, DKIM, SenderID といったいわゆる送信者認証技術は、From ドメインと送信元サーバの組み合わせが正しいかどうかを判断することができるが、これが正しいからといって、スパマーかどうかは判断ができない。（実際、スパマーはいち早くこれらの送信者認証技術に対応してきているらしい。）それを補うのがこの RepuScore であり、送信元に関する評価を集合知的に集めてシェアすることが目的。</p>

<p>SpamAssassin 用プラグインを近々公開予定らしい。</p>

<p>RepuScore で興味深かったのは、不正なレポートを行う（Sybil attacksと呼んでいた）評価者の重みを下げることによって、評価全体への影響を低くして、不正なデータ操作が行えないようにする仕組みがあること。</p>

<p>他のレピュテーションシステムとしては、<a href="http://www.returnpath.net/">SenderPath&#8217;s Sender Score</a> や <a href="http://www.habeas.com/en-US/Receivers/SenderIndex/">Habeas&#8217; SenderIndex</a> といったものがあるが、これらは IP アドレスベースのレピュテーションであり、RepuScore はドメインベースのレピュテーションである、という違いがある。（IPアドレスは組織間でシェアされていることもあるので、こういったレピュテーションシステムには向いていない、という記述もある。）</p>

<p>Gmail も自前でユーザに通知させるレピュテーションの仕組みを持っているが、Gmail の中で閉じられている。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/16/LISA07TechSessionFirstDay/">LISA07TechSessionFirstDay</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-16T07:09:21+09:00" pubdate>Nov 16<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/11/16/LISA07TechSessionFirstDay/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>現在、<a href="http://www.usenix.org/events/lisa07/">LISA</a> という大規模システム管理者向けカンファレンスへの参加のため、ダラスに来ています。自分は 11/14 - 11/16 に開催されるテクニカルセッションのみに参加していて、本日はテクニカルセッションの初日でした。今日聞いた中で気になったテーマについて、さらっとご紹介、というか自分用にまとめてみます。</p>

<h1>CAMP: A Common API for Measuring Performance</h1>

<p>名前の通り、パフォーマンス計測のための API。異なる OS が混在する分散システムでのパフォーマンステストを正確に行うために、共通な API を定義しよう、という試み。</p>

<p><a href="http://www.usenix.org/events/lisa07/tech/gabel.html">概要はこちら</a>。ここから論文すべて（HTML or PDF）を参照できる。（2008年11月までは、USENIX メンバーじゃないとアクセスできない、と書いてあるけど、アクセス制限はかかってないみたい。いいのかな？）</p>

<p>CAMP は Python で実装されていて、以下のようなコードでパフォーマンスデータが取得できる。</p>

<pre><code>#!python
# Calculate the current transfer rate (Both
# in and out) for the given network adapter.
def BulkByteTransferRate(adapter):
    # Query CAMP for the initial state.
    initial = GetNetBytesSent(adapter)
    initial += GetNetBytesRecvd(adapter)
    time.sleep(SAMPLE_INTERVAL)
    # Query CAMP for the final state.
    final = GetNetBytesSent(adapter)
    final += GetNetBytesRecvd(adapter)
    return (final - initial)/SAMPLE_INTERVAL
</code></pre>

<p>GetNetBytesSent や GetNetBytesRecvd が CAMP によって提供されているメソッド。</p>

<p>現在対応している OS は、</p>

<ul>
<li>Linux 2.6</li>
<li>Win32 (Windows NT/2000/XP)</li>
<li>Solaris (SunOS kernel 5.x)</li>
</ul>


<p>の3種類。パフォーマンスデータの取得は、Linux では proc、Windows では Microsoft&#8217;s performance data handler (PDH) interface、Solaris では proc と kstat を利用しているとのこと。</p>

<p>論文の中では、CAMP によって取得できるパフォーマンスデータの妥当性に関する検証や、CAMP 自体のパフォーマンス、オーバーヘッドに関する検証データも載っている。</p>

<p>proc ファイルシステムへのアクセスオーバヘッドの低さから、特に Linux でのパフォーマンスは高いみたい。</p>

<p>パフォーマンスデータを取得するのであれば、SNMP でもできるのでは、と思ったけど、これについても論文でちゃんと触れられていて、SNMP は UDP によるアプリケーションプロトコルであり、CAMP を利用することで OS に依存しない SNMP エージェントを実装する、といった形での住み分けができる、といったことが書かれていた。</p>

<p><a href="http://wiki.csc.calpoly.edu/camp">CAMP の Trac サイト</a>が存在するけど、内容はまだ何もない。「<strong> Download coming soon! </strong>」ということなので、ソースが公開されたら要チェック。</p>

<h1>Application Buffer-Cache Management for Performance: Running the World’s Largest MRTG</h1>

<p>OS のディスク I/O 先読みとバッファキャッシュは通常、アプリケーションのパフォーマンスを高めるものであるが、大規模ネットワークで MRTG を運用していると、逆にパフォーマンスを低下させてしまう、ということについて、何がボトルネックになっているのか、どうやってそのボトルネックを解消するのか、といったことに関する考察。<a href="http://www.usenix.org/events/lisa07/tech/plonka.html">概要はこちら</a>。</p>

<p>まず、大規模ネットワークサイトでの MRTG の処理時間がグラフで示されている。これによると、5分おきに MRTG を実行しているにも関わらず、半分ほどの処理が5分以内に完了していない、という結果に。そして、MRTG のボトルネックはディスク I/O であり、特に read の比率が高い、ということが示されている。</p>

<p>MRTG は RRDtool を利用しているが、RRD ファイルは特性として、一度の操作で読み書きするブロックがシーケンシャルになっていない。そのため、OS がシーケンシャルにファイルを先読みすることによって、読み込む必要のないブロックまで読み込んでしまい、余分な I/O が発生する、ということがボトルネックの一因。いわゆる余計なお世話。</p>

<p>また、必要のないブロックを読み込んでバッファキャッシュに載せるため、キャッシュに本当に載せてほしいブロックが載らずに、ページフォルトが発生する、というのもボトルネックの一因。</p>

<p>この調査のために、<a href="http://net.doit.wisc.edu/~plonka/fincore/">fincore</a> という、指定したファイルのどのページがバッファキャッシュに載っているのかを表示するツールを作っている。</p>

<p>ボトルネックを解消するアプローチのひとつは、独自のキャッシュライブラリを作成して、MRTG にこのライブラリ経由でファイル操作をさせる、というもの。これにより、ほとんどの処理が1分以内で完了するようになった。（ただし、キャッシュの処理は図を見るとちょっと複雑。）</p>

<p>もうひとつのアプローチは、アプリケーションのファイルアクセス特性を OS に伝えることによって、OS のディスクI/O に関する挙動を変えたり、キャッシュアルゴリズムを変えたり、といったことが可能な、<a href="http://docs.hp.com/ja/B2355-60129/fadvise.2.html">POSIX fadvise システムコール</a>を利用して MRTG を動かす、というもの。</p>

<p><a href="http://net.doit.wisc.edu/~plonka/fadvise/">fadvise を実行する Perl スクリプト</a> も作成している。</p>

<p>論文では FADV_RANDOM を指定することによって、OS に対してアプリケーションが、シーケンシャルではなくランダムにファイルアクセスすることを伝えている。これにより OS は先読みをしなくなり余計なI/Oが発生しないし、余分なデータを読み込まないのでバッファキャッシュも無駄なく利用できる。（FADV_RANDOM という言葉は出てないけど、たぶんそうだと思う。）</p>

<p>このアプローチでもほとんどの処理が1分以内に完了する、という結果に。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/12/PerlbalPluginProxyPass/">PerlbalPluginProxyPass</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-12T00:15:48+09:00" pubdate>Nov 12<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/11/12/PerlbalPluginProxyPass/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Perlbal で Vpaths プラグインをつかって、</p>

<pre><code>LOAD vpaths

CREATE POOL apache
  POOL apache ADD 127.0.0.1

CREATE SERVICE apache_proxy
  SET role = reverse_proxy
  SET pool = apache
ENABLE apache_proxy

CREATE SERVICE selector
  SET   listen  = 0.0.0.0:8080
  SET   role    = selector
  SET   plugins = vpaths
  VPATH /apache = apache_proxy
ENABLE selector
</code></pre>

<p>みたいな設定をすると、</p>

<pre><code>http://localhost:8080/apache -&gt; http://localhost:80/apache
</code></pre>

<p>といった形でプロキシしてくれるんだけど、これを</p>

<pre><code>http://localhost:8080/apache -&gt; http://localhost:80/
</code></pre>

<p>としたくてプラグイン書いてみた。もしかしてプラグイン書かなくてもできるかもしれないけど、やり方がわからなかったのと、プラグインを書く練習ってことで。プラグイン名は Apache mod_proxy の ProxyPass ディレクティブにちなんでます。</p>

<pre><code>#!perl
package Perlbal::Plugin::ProxyPass;

use strict;
use warnings;

sub load {
    my $class = shift;

    Perlbal::register_global_hook('manage_command.proxypass', sub {
        my $mc = shift-&gt;parse(qr/proxypass\s+(?:(\w+)\s+)?(\S+)\s*=\s*(\S+)$/,
                              "usage: ProxyPass [&lt;service&gt;] &lt;source path&gt; = &lt;dest path&gt;");
        my ($selname, $source, $target) = $mc-&gt;args;
        unless ($selname ||= $mc-&gt;{ctx}{last_created}) {
            return $mc-&gt;err("omitted service name not implied from context");
        }

        my $ss = Perlbal-&gt;service($selname);
        return $mc-&gt;err("Service '$selname' is not a reverse_proxy service")
            unless $ss &amp;&amp; $ss-&gt;{role} eq "reverse_proxy";

        $ss-&gt;{extra_config}-&gt;{_proxypass} ||= [];
        push @{$ss-&gt;{extra_config}-&gt;{_proxypass}}, [ $source, $target ];

        return $mc-&gt;ok;
    });

    return 1;
}

sub register {
    my ($class, $svc) = @_;
    unless ($svc &amp;&amp; $svc-&gt;{role} eq "reverse_proxy") {
        die "You can't load the proxypass plugin on a service not of role reverse_proxy.\n";
    }

    $svc-&gt;register_hook(
        'ProxyPass' =&gt; 'start_proxy_request', sub {
            my Perlbal::ClientProxy $client = shift;
            for my $proxypass ( @{ $svc-&gt;{extra_config}-&gt;{_proxypass} } ) {
                my $source = $proxypass-&gt;[0];
                my $target = $proxypass-&gt;[1];
                $client-&gt;{req_headers}-&gt;{uri} =~ s/$source/$target/;
                $client-&gt;{req_headers}-&gt;{uri} =~ s!//!/!;
            }
            return 0;
        }
    );

    return 1;
}

1;
</code></pre>

<p>設定はこんな感じ。</p>

<pre><code>LOAD vpaths
LOAD ProxyPass

CREATE POOL apache
  POOL apache ADD 127.0.0.1

CREATE SERVICE apache_proxy
  SET       role    = reverse_proxy
  SET       pool    = apache
  SET       plugins = ProxyPass
  ProxyPass /apache = /   
ENABLE apache_proxy

CREATE SERVICE selector
  SET   listen  = 0.0.0.0:8080
  SET   role    = selector
  SET   plugins = vpaths
  VPATH /apache = apache_proxy
ENABLE selector
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2007/11/08/CampAndLisa/">CampAndLisa</a></h1>
    
    
      <p class="meta">
        




  

<time datetime="2007-11-08T17:35:02+09:00" pubdate>Nov 8<span>th</span>, 2007</time>
        
         | <a href="/blog/2007/11/08/CampAndLisa/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>今出張で福岡に来ていて、これから帰るところなのですが、帰ったと思ったら明日はペパボの<a href="http://www.paperboy.co.jp/next/osan/">開発合宿</a>です。</p>

<p>で、13日からは<a href="http://www.usenix.org/events/lisa07/">LISA</a>のテクニカルセッションへの参加のため、ダラスに行ってきます。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/12/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/10/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/01/09/web-to-mobi-a-script-for-converting-web-sites-to-mobipocket-format/">Web-to-mobi - A script for converting web sites to mobipocket format</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/01/06/weechat-script-for-pushing-notification-to-im-dot-kayac-dot-com/">WeeChat script for pushing notification to im.kayac.com</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/20/lunar-eclipse/">Lunar Eclipse</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/20/a-picture-of-geminids/">A Picture of Geminids</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/12/13/maglica-presentation-at-hatena/">Maglica Presentation At Hatena</a>
      </li>
    
  </ul>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Gosuke Miyashita -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'mizzyorg';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
