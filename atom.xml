<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Gosuke Miyashita]]></title>
  <link href="http://mizzy.org/atom.xml" rel="self"/>
  <link href="http://mizzy.org/"/>
  <updated>2011-12-20T00:30:25+09:00</updated>
  <id>http://mizzy.org/</id>
  <author>
    <name><![CDATA[Gosuke Miyashita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A Picture of Geminids]]></title>
    <link href="http://mizzy.org/blog/2011/12/20/a-picture-of-geminids/"/>
    <updated>2011-12-20T00:12:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/12/20/a-picture-of-geminids</id>
    <content type="html"><![CDATA[<p>This is a picture of a shooting star of Gemnids I took on Dec. 15, 2011.I took over 2,000 pictures and only 3 pictures got a shooting star.</p>

<p><img src="http://mizzy.org/images/geminids-shooting-star.jpg" title="A shooting star of Geminids" ></p>

<p>A red bright star on left side is Aldebaran of Taurus and dense small stars on center are Pleiades.</p>

<p>It was so cold but looking at stars and shooting stars were so fun.It would never be boring for me.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maglica Presentation At Hatena]]></title>
    <link href="http://mizzy.org/blog/2011/12/13/maglica-presentation-at-hatena/"/>
    <updated>2011-12-13T21:14:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/12/13/maglica-presentation-at-hatena</id>
    <content type="html"><![CDATA[<p>I talked about <a href="https://github.com/mizzy/maglica">Maglica</a> at <a href="http://hatena.ne.jp/">Hatena</a> on Dec. 9, 2011.</p>

<p>I appreciate <a href="http://twitter.com/#!/kentaro">@kentaro</a>-san and Hatena staffs.I had a very good time to talking with you and drinking Dr Peppers :-)</p>

<p><a href="http://mizzy.org/slides/maglica/">This is the slide I talked</a>.</p>

<p>Maglica is a simple internal cloud tool I made.I don&#8217;t like complicated and blackboxed tools.It seems for me that existing internal cloud tools are so complicated and overengineered for my use case.So I made the simple one.</p>

<p>&#8220;Tenjin&#8221; font is embedded in this slide using CSS Fonts Module. <a href="http://twitter.com/#!/chocolatina">@chocolatina</a> made this cool font.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to deploy a blog made by Octopress to Heteml]]></title>
    <link href="http://mizzy.org/blog/2011/11/15/octopress-on-heteml/"/>
    <updated>2011-11-15T22:30:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/11/15/octopress-on-heteml</id>
    <content type="html"><![CDATA[<div><script src='https://gist.github.com/1367192.js?file='></script>
<noscript><pre><code>diff --git a/Rakefile b/Rakefile
index 7d7f6d8..41868ab 100644
--- a/Rakefile
+++ b/Rakefile
@@ -4,10 +4,10 @@ require &quot;stringex&quot;
 
 ## -- Rsync Deploy config -- ##
 # Be sure your public key is listed in your server's ~/.ssh/authorized_keys file
-ssh_user       = &quot;user@domain.com&quot;
-ssh_port       = &quot;22&quot;
-document_root  = &quot;~/website.com/&quot;
-deploy_default = &quot;rsync&quot;
+ssh_user       = &quot;xxx@usersXX.heteml.jp&quot;
+ssh_port       = &quot;2222&quot;
+document_root  = &quot;~/web/octopress&quot;
+deploy_default = &quot;scp&quot;
 
 # This will be configured for you when you run config_deploy
 deploy_branch  = &quot;gh-pages&quot;
@@ -224,6 +224,12 @@ task :rsync do
   ok_failed system(&quot;rsync -avze 'ssh -p #{ssh_port}' --delete #{public_dir}/ #{ssh_user}:#{document_root}&quot;)
 end
 
+desc &quot;Deploy website via scp&quot;
+task :scp do
+  puts &quot;## Deploying website via scp&quot;
+  ok_failed system(&quot;scp -r -P #{ssh_port} #{public_dir}/* #{ssh_user}:#{document_root}&quot;)
+end
+
 desc &quot;deploy public directory to github pages&quot;
 multitask :push do
   puts &quot;## Deploying branch to Github Pages &quot;
</code></pre></noscript></div>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maglica Web]]></title>
    <link href="http://mizzy.org/blog/2011/11/05/maglica-web/"/>
    <updated>2011-11-05T13:35:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/11/05/maglica-web</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/mizzy/maglica-web">Maglica Web is on GitHub</a></p>

<p><img src="http://img.logpi.jp/C58B4476-0769-11E1-8C19-9A01CD288735_o.png">
<img src="http://img.logpi.jp/024C01C4-05FE-11E1-A49E-9848058D85C2_o.jpg">
<img src="http://img.logpi.jp/01A75D3C-05E9-11E1-99E8-9701CD288735_o.jpg">
<img src="http://img.logpi.jp/65B4CEC4-05F1-11E1-9242-8909CD288735_o.jpg">
<img src="http://img.logpi.jp/2A1E7730-05FF-11E1-AE4A-9948058D85C2_o.jpg">
<img src="http://img.logpi.jp/7E9FA20A-0769-11E1-B29D-9801CD288735_o.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vimeo tag plugin]]></title>
    <link href="http://mizzy.org/blog/2011/10/30/vimeo-tag-plugin/"/>
    <updated>2011-10-30T23:27:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/10/30/vimeo-tag-plugin</id>
    <content type="html"><![CDATA[<iframe src="http://player.vimeo.com/video/24149087?color=ffffff" width="800" height="600" frameborder="0" webkitAllowFullScreen allowFullScreen></iframe>


<p><a href="http://vimeo.com/24149087">Black Hole Sun - Astronomic Landscape and Milky Way TimeLapse</a> from <a href="http://vimeo.com/user1722616">Christoph Malin</a> on <a href="http://vimeo.com">Vimeo</a>.</p>




<figure class='code'><figcaption><span>A Liquid tag for Jekyll sites that allows embedding vimeo movies (vimeo_tag.rb)</span> <a href='http://mizzy.org/downloads/code/vimeo_tag.rb'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class='rb'><span class='line'><span class="c1"># A Liquid tag for Jekyll sites that allows embedding vimeo movies</span>
</span><span class='line'><span class="c1"># by: Gosuke Miyashita</span>
</span><span class='line'><span class="c1">#</span>
</span><span class='line'><span class="c1"># Example usage: {% vimeo 28040685 800 600 %}</span>
</span><span class='line'>
</span><span class='line'><span class="nb">require</span> <span class="s1">&#39;open-uri&#39;</span>
</span><span class='line'><span class="nb">require</span> <span class="s1">&#39;multi_json&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">module</span> <span class="nn">Jekyll</span>
</span><span class='line'>  <span class="k">class</span> <span class="nc">VimeoTag</span> <span class="o">&lt;</span> <span class="no">Liquid</span><span class="o">::</span><span class="no">Tag</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">tag_name</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">token</span><span class="p">)</span>
</span><span class='line'>      <span class="k">super</span>
</span><span class='line'>      <span class="vi">@text</span> <span class="o">=</span> <span class="n">text</span>
</span><span class='line'>      <span class="vi">@cache_dir</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">expand_path</span> <span class="s2">&quot;../.vimeo-cache&quot;</span><span class="p">,</span> <span class="no">File</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="bp">__FILE__</span><span class="p">)</span>
</span><span class='line'>      <span class="no">FileUtils</span><span class="o">.</span><span class="n">mkdir_p</span> <span class="vi">@cache_dir</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
</span><span class='line'>      <span class="k">if</span> <span class="n">parts</span> <span class="o">=</span> <span class="vi">@text</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sr">/(\d+) (\d+) (\d+)/</span><span class="p">)</span>
</span><span class='line'>        <span class="nb">id</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">parts</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">strip</span><span class="p">,</span> <span class="n">parts</span><span class="o">[</span><span class="mi">2</span><span class="o">].</span><span class="n">strip</span><span class="p">,</span> <span class="n">parts</span><span class="o">[</span><span class="mi">3</span><span class="o">].</span><span class="n">strip</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">vimeo</span> <span class="o">=</span> <span class="n">get_vimeo</span><span class="p">(</span><span class="nb">id</span><span class="p">)</span>
</span><span class='line'>      <span class="o">&lt;&lt;-</span><span class="no">HTML</span>
</span><span class='line'><span class="sh">&lt;iframe src=&quot;http://player.vimeo.com/video/#{id}?color=ffffff&quot; width=&quot;#{width}&quot; height=&quot;#{height}&quot; frameborder=&quot;0&quot; webkitAllowFullScreen allowFullScreen&gt;&lt;/iframe&gt;&lt;p&gt;&lt;a href=&quot;http://vimeo.com/#{id}&quot;&gt;#{vimeo[&quot;title&quot;]}&lt;/a&gt; from &lt;a href=&quot;#{vimeo[&quot;author_url&quot;]}&quot;&gt;#{vimeo[&quot;author_name&quot;]}&lt;/a&gt; on &lt;a href=&quot;http://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;</span>
</span><span class='line'><span class="no">      HTML</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">get_vimeo</span><span class="p">(</span><span class="nb">id</span><span class="p">)</span>
</span><span class='line'>      <span class="n">cache_file</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">join</span> <span class="vi">@cache_dir</span><span class="p">,</span> <span class="nb">id</span>
</span><span class='line'>      <span class="k">if</span> <span class="no">File</span><span class="o">.</span><span class="n">exist?</span> <span class="n">cache_file</span>
</span><span class='line'>        <span class="no">MultiJson</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="no">File</span><span class="o">.</span><span class="n">read</span> <span class="n">cache_file</span><span class="p">)</span>
</span><span class='line'>      <span class="k">else</span>
</span><span class='line'>        <span class="n">json</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;http://vimeo.com/api/oembed.json?url=http%3A//vimeo.com/</span><span class="si">#{</span><span class="nb">id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span>
</span><span class='line'>        <span class="no">File</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">cache_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">io</span><span class="o">|</span>
</span><span class='line'>          <span class="n">io</span><span class="o">.</span><span class="n">write</span> <span class="n">json</span>
</span><span class='line'>        <span class="k">end</span>
</span><span class='line'>        <span class="no">MultiJson</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">json</span><span class="p">)</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span><span class='line'>
</span><span class='line'><span class="no">Liquid</span><span class="o">::</span><span class="no">Template</span><span class="o">.</span><span class="n">register_tag</span><span class="p">(</span><span class="s1">&#39;vimeo&#39;</span><span class="p">,</span> <span class="no">Jekyll</span><span class="o">::</span><span class="no">VimeoTag</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Typo to Octopress]]></title>
    <link href="http://mizzy.org/blog/2011/10/29/typo-to-octopress/"/>
    <updated>2011-10-29T21:34:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/10/29/typo-to-octopress</id>
    <content type="html"><![CDATA[<p>I&#8217;ve moved my <a href="http://fdv.github.com/typo/">Typo</a> blog contents to this octopress blog.</p>

<p>For this purpose I made this tiny script.</p>

<div><script src='https://gist.github.com/1324352.js?file='></script>
<noscript><pre><code>require &quot;rubygems&quot;
require &quot;active_record&quot;

ActiveRecord::Base.establish_connection(
    :adapter  =&gt; &quot;mysql2&quot;,
    :host     =&gt; &quot;192.168.10.12&quot;,
    :user     =&gt; &quot;root&quot;,
    :password =&gt; &quot;root&quot;,
    :database =&gt; &quot;typo&quot;,
    :encoding =&gt; &quot;utf8&quot;
)

class Content &lt; ActiveRecord::Base
  Content.inheritance_column = 'foo'
end

contents = Content.all

contents.each do |content|
  dt = content.published_at
  date = sprintf(&quot;%04s-%02d-%02d&quot;, dt.year, dt.month, dt.day)
  datetime = date + sprintf(&quot; %02d:%02d&quot;, dt.hour, dt.min)
  file = date + &quot;-&quot; + content.id.to_s + &quot;.markdown&quot;

  body = &lt;&lt;BODY
---
layout: post
title: &quot;#{content.title}&quot;
date: #{datetime}
comments: true
categories:
---
#{content.body}
BODY

  File.open(file, 'w') do |file|
    file.write(body)
  end
end
</code></pre></noscript></div>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TWAN tag plugin for Jekyll]]></title>
    <link href="http://mizzy.org/blog/2011/10/21/twan-tag-plugin/"/>
    <updated>2011-10-21T00:04:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/10/21/twan-tag-plugin</id>
    <content type="html"><![CDATA[<p>I&#8217;ve written <a href="https://github.com/mizzy/jekyll-plugins/blob/master/twan_tag.rb">TWAN tag plugin</a> for <a href="https://github.com/mojombo/jekyll">Jekyll</a> which shows the image of <a href="http://www.twanight.org/newTWAN/index.asp">The World At Night</a>.</p>

<p>If you call this plugin in a post like this:</p>

<pre><code>{% twan 3003406 %}
</code></pre>

<p>The image shows up like this.</p>

<p><a href="http://www.twanight.org/newTWAN/photos.asp?ID=3003406"><img src="http://mizzy.org/images/twan/3003406.jpg" /></a></br />
<a href="http://www.twanight.org/newTWAN/photos.asp?ID=3003406">Draconid Meteors Composite by Juan Carlos Casado</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[自宅サーバが死にました]]></title>
    <link href="http://mizzy.org/blog/2011/10/17/first-post/"/>
    <updated>2011-10-17T22:25:00+09:00</updated>
    <id>http://mizzy.org/blog/2011/10/17/first-post</id>
    <content type="html"><![CDATA[<p>10年ぐらい稼働していた mizzy.org の自宅サーバが死にました。（四男がコンセントぶち抜いたら起動してこなくなった。）</p>

<p>メールの方は Google Apps に移行したんですが、ブログはどうしようかなー、できれば GitHub でファイル管理したいなー、と思ってたところに、<a href="http://mattn.kaoriya.net/software/lang/ruby/20111017205717.htm">@mattn_jp さんのタイムリーなエントリ</a> が。</p>

<p>とても良さそうなので、しばらくこれで運用してみます。</p>

<p>過去エントリについては、Trac に入ってた分ぐらいは移行しようかな、と考えてます。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Resume]]></title>
    <link href="http://mizzy.org/blog/2011/10/05/MyResume/"/>
    <updated>2011-10-05T17:14:06+09:00</updated>
    <id>http://mizzy.org/blog/2011/10/05/MyResume</id>
    <content type="html"><![CDATA[<h1>Educations</h1>

<ul>
<li>Hokkaido University (1993-1997)

<ul>
<li>Department of Economics

<ul>
<li>Operations Research</li>
<li>Linear Programming</li>
<li>Multivariable Analysis</li>
<li>A theme of graduation thesis is &#8220;Analyze NBA Players ablility with Multivariable Analysis&#8221;</li>
</ul>
</li>
</ul>
</li>
</ul>


<hr />

<h1>Jobs</h1>

<ul>
<li><a href="http://www.ctc-g.co.jp/en/">CTC</a>

<ul>
<li>1997-

<ul>
<li>Netscape Server Software Products Engineer

<ul>
<li>Netscape Enterprise Server (Web Server)</li>
<li>Netscape Messaging Server (Mail Server)</li>
<li>Netscape Directory Server (LDAP Server)</li>
<li>and so on</li>
</ul>
</li>
</ul>
</li>
<li>1998-

<ul>
<li>Support Engineer of Netscape Server Software Products at Netscape Japan</li>
</ul>
</li>
<li>1999-2000

<ul>
<li>QA of I18N Netscpe Server Software Products at Netscape US</li>
<li>Working at Mountain View</li>
<li>Lining in Sunnyvale</li>
</ul>
</li>
<li>2000-2005

<ul>
<li>iPlanet(formerly known as Netscape) Server Software Products Engineer at CTC again.</li>
</ul>
</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><a href="http://www.netmarks.co.jp/english/index.html">Netmarks</a>

<ul>
<li>2005-

<ul>
<li>Testing Network Quarantine Systems

<ul>
<li>It is for blocking insecure computers automatically.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><a href="http://www.paperboy.co.jp/">paperboy&amp;co.</a> (Now)

<ul>
<li>2006-

<ul>
<li>Software Engineer</li>
<li>JugemKey (http://jugemkey.jp/)

<ul>
<li>Central authorization system for multiple services in paperboy&amp;co.</li>
<li>Write backend API with Perl</li>
</ul>
</li>
<li>JugemKey Authentication API

<ul>
<li>Similar to Flickr authentication API</li>
<li>Write frontend with PHP and backend with Perl</li>
</ul>
</li>
<li>JUGEM (http://jugem.jp/)

<ul>
<li>Blog service</li>
<li>Write accounting function by credit cards with PHP</li>
</ul>
</li>
</ul>
</li>
<li>2007-

<ul>
<li>Technical Manager</li>
<li>30days Album (http://30d.jp/)

<ul>
<li>A photo Album Service</li>
<li>In charge of overall architect design</li>
<li>Write some Perlbal plugins</li>
<li>Write frontend API for MogileFS

<ul>
<li>Perl + Catalyst</li>
</ul>
</li>
<li>Other technology stacks

<ul>
<li>Linux, Ruby On Rails, lighttpd, Gearman, TheSchwartz</li>
</ul>
</li>
</ul>
</li>
<li>Lolipop Rental Server (http://lolipop.jp/)

<ul>
<li>A plain old style rental servers</li>
<li>In charge of overall architect design in system renewal</li>
<li>Designed Internal API and implemented a proto type</li>
<li>Other technology stacks

<ul>
<li>Linux, Cobbler, LVS, Apache, MySQL, Postfix, qpsmtpd, Courier-IMAP, ClamAV, Puppet, Func</li>
</ul>
</li>
</ul>
</li>
<li>Improve development environments in the company

<ul>
<li>Introduce Subversion and Trac</li>
<li>Recently introduce Git and Jenkins CI</li>
<li>Now writing original internal cloud tool

<ul>
<li>Very simple system with kvm, libvirtd, virt-clone and zeromq

<ul>
<li><a href="https://github.com/mizzy/maglica">Maglica on GitHub</a></li>
<li><a href="http://mizzy.org/slides/maglica">Maglica Slide</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<hr />

<h1>Talks</h1>

<ul>
<li><a href="http://tokyo2007.yapcasia.org/blog/">YAPC::Asia 2007 Tokyo</a>

<ul>
<li><a href="http://tokyo2007.yapcasia.org/sessions/2007/02/assurer_a_pluggable_server_tes.html">Assurer - a pluggable server testing/monitoring framework</a></li>
<li><a href="http://www.slideshare.net/mizzy/assurer-a-pluggable-server-testingmonitoring-framework">SlideShare</a></li>
<li><a href="https://github.com/mizzy/Assurer">Code on github</a></li>
</ul>
</li>
<li><a href="http://conferences.yapcasia.org/ya2008/index.html">YAPC::Asia 2008 Tokyo</a>

<ul>
<li><a href="http://conferences.yapcasia.org/ya2008/talk/973">Easy system administration programming with a framework</a></li>
<li><a href="https://github.com/mizzy/Punc">Code on github</a></li>
</ul>
</li>
<li><a href="http://conferences.yapcasia.org/ya2009/">YAPC::Asia 2009 Tokyo</a>

<ul>
<li><a href="http://conferences.yapcasia.org/ya2009/talk/2166">How to use Perl in paperboy&amp;co.</a></li>
<li><a href="http://conferences.yapcasia.org/ya2009/talk/2220">How Danga::Socket handles asynchronous processing and how to write asynchronous Perlbal plugins</a></li>
</ul>
</li>
<li>Xen Summit 2008 Tokyo

<ul>
<li><a href="http://www.slideshare.net/mizzy/xen-summit-2008-tokyo-operating-xen-domains-through-llperlpython-with-libvirt-presentation">Operating Xen domains through LL(Perl/Python) with libvirt</a></li>
</ul>
</li>
<li><a href="http://www.tlug.jp/wiki/Meetings:2008:09">TLUG Meeting 2008/09/13</a>

<ul>
<li><a href="http://www.slideshare.net/mizzy/how-to-build-a-scalable-storage-system-at-tlug-meeting-20080913-presentation">How To Build A Scalable Storage System with OSS</a></li>
</ul>
</li>
<li><a href="http://dsas.blog.klab.org/archives/51208101.html">KLab Study #4</a>

<ul>
<li><a href="http://www.slideshare.net/mizzy/open-source-system-administration-framework-func">Open Source System Administration Framework - Func</a> (Japanese)</li>
</ul>
</li>
<li><a href="http://techlife.cookpad.com/2009/10/24/techlife_introduction/">techlife lightning talk at Cookpad</a>

<ul>
<li><a href="http://www.slideshare.net/mizzy/puppet-best-practices-at-cookpad">Puppet Best Practices?</a> (Japanese)</li>
</ul>
</li>
<li><a href="http://heartbeats.jp/hbstudy/2010/02/hbstudy8.html">hbstudy #8</a>

<ul>
<li><a href="http://www.slideshare.net/mizzy/puppet-3258268">About Puppet</a> (Japanese)</li>
</ul>
</li>
<li><a href="http://partake.in/events/b5472f43-5bc0-42d0-9469-dc70d7d95b24">DevOps Conference</a>

<ul>
<li><a href="http://www.slideshare.net/mizzy/10devops">DevOps in 10 minutes</a> (Japanese)</li>
</ul>
</li>
<li>Tech Talk at NTT Resonant Inc

<ul>
<li><a href="http://www.slideshare.net/mizzy/devops-4156440">What is DevOps?</a> (Japanese)</li>
</ul>
</li>
<li><a href="http://k-of.jp/2008/">Kansai Open Source 2008</a>

<ul>
<li><a href="http://www.slideshare.net/mizzy/2008-30days-album-presentation">Inside 30days Album&#8217;s Backend</a> (Japanese)</li>
</ul>
</li>
<li><a href="http://shibuya.pm.org/blosxom/techtalks/200610.html">Shibuya.pm Technical Talk #7</a>

<ul>
<li>LT: Plagger Plugins development process by using SVK</li>
</ul>
</li>
<li><a href="http://shibuya.pm.org/blosxom/techtalks/200710.html">Shibuya.pm Technical Talk #8</a>

<ul>
<li>LT: About Pushmi</li>
</ul>
</li>
</ul>


<hr />

<h1>Others</h1>

<ul>
<li>I4PC (Instagram for PC)

<ul>
<li>http://www.i4pc.jp/</li>
</ul>
</li>
<li>CPAN

<ul>
<li>http://search.cpan.org/~mizzy/</li>
</ul>
</li>
<li>GitHub

<ul>
<li>https://github.com/mizzy</li>
</ul>
</li>
<li>codewall

<ul>
<li>http://coderwall.com/mizzy</li>
</ul>
</li>
<li>twitter

<ul>
<li>http://twitter.com/gosukenator</li>
</ul>
</li>
<li>Facebook

<ul>
<li>http://www.facebook.com/gosukenator</li>
</ul>
</li>
<li>SlideShare

<ul>
<li>http://www.slideshare.net/mizzy/presentations</li>
</ul>
</li>
<li>Articles about Puppet in gihyo.jp (Japanese)

<ul>
<li>http://gihyo.jp/admin/serial/01/puppet</li>
</ul>
</li>
<li>Articles about Puppet in Software Design magazine (Japanese)

<ul>
<li>http://gihyo.jp/magazine/SD/archive/2007/200712</li>
</ul>
</li>
<li>Interview articles (Japanese)

<ul>
<li>http://japan.cnet.com/extra/paperboy_0907/story/0,3800098768,20394957,00.htm</li>
<li>http://web-engineer.buyuden.net/buyuden/2010/01/39paperboyco.html</li>
<li>http://jibun.atmarkit.co.jp/lcom01/rensai/comrade04/comrade01.html</li>
</ul>
</li>
<li>LinkedIn

<ul>
<li>http://www.linkedin.com/in/mizzy</li>
</ul>
</li>
<li>Personal sites

<ul>
<li>http://mizzy.org/</li>
<li>http://astralscape.tumblr.com/</li>
</ul>
</li>
</ul>


<hr />

<p>mailto: gosukenator at gmail.com</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSLCertOfLolipop]]></title>
    <link href="http://mizzy.org/blog/2011/09/03/SSLCertOfLolipop/"/>
    <updated>2011-09-03T01:41:19+09:00</updated>
    <id>http://mizzy.org/blog/2011/09/03/SSLCertOfLolipop</id>
    <content type="html"><![CDATA[<p><a href="http://blog2.or6.jp/ftpisdead">FFFTP開発終了で大騒ぎしている人たちへ</a> にて、</p>

<pre><code>SSL証明書がまともなものでないと接続時にエラーが出るのですが、ロリポップなんかだと
このエラーを無視するように公式ドキュメントに書いてあるので、かなり悪質です。
</code></pre>

<p>と書かれていますので、これについて説明させて頂きます。</p>

<p>この方が指摘されているのは、<del><a href="http://lolipop.jp/manual/hp/w-fz/">Win FileZillaの設定 / ホームページ / マニュアル - ロリポップ！</a> </del>(FileZilla非推奨のため現在は削除されています)の中の、</p>

<pre><code> 証明書の確認を行います。『今後もこの証明書を常に信用する(A)』にチェックを入れて、『OK』をクリックします。
</code></pre>

<p>という部分だと思われるのですが、確かに、無条件で信用するにチェックを入れるようお客様に指示するのは大変良くないですね。</p>

<p>ロリポップでは <a href="http://www.digicert.ne.jp/">DigiCert Inc社</a> によって発行されている証明書を利用しているのですが、Filezillaでは警告が出てしまうようです。</p>

<p>調べてみたところ、FilezillaはルートCAの証明書を保持しておらず、どのような証明書であっても、ユーザが「信用する」にチェックを入れなければ警告が出る仕様となっているようです。</p>

<p><a href="http://forum.filezilla-project.org/viewtopic.php?f=2&amp;t=20767">how to install root CA certificate on Filezilla</a></p>

<p>OR6 blog 様のご指摘により、このような証明書の検証をきちんと行っていないソフトウェアをお客様に推奨すべきではないと判断いたしましたので、Windows/Mac版ともに存在し、証明書の検証をきちんと行っている <a href="http://cyberduck.ch/">Cyberduck</a> を推奨するよう、マニュアルを変更させて頂くことになりました。</p>

<p>また、蛇足ですが、ロリポップの <a href="http://lolipop.jp/service/plan-chicappa/">チカッパプラン</a> では SSH サービスを提供していますので、FTPS の代わりに SCP/SFTP もご利用頂けます。</p>

<p>OR6 blog 様、この度はご指摘誠にありがとうございました。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MaglicaInternalCloudTool]]></title>
    <link href="http://mizzy.org/blog/2011/08/18/MaglicaInternalCloudTool/"/>
    <updated>2011-08-18T17:25:28+09:00</updated>
    <id>http://mizzy.org/blog/2011/08/18/MaglicaInternalCloudTool</id>
    <content type="html"><![CDATA[<h1>Overview</h1>

<p><a href="https://github.com/mizzy/maglica">Maglica</a> is a Python library and command-line tool for an internal cloud. (This tool is very primitive beta now.)</p>

<p>This is very simple and based on libvirt, virt-clone and zeromq (for RPC).</p>

<p>The name &#8220;Maglica&#8221; is derived from a Bosnian word that means &#8220;Nebula.&#8221;</p>

<p>I&#8217;m developing this tool because other internal cloud tools(CloudStack, OpenStack, Eucalyptus and so on) are so complicated for internal use.I need a simple tool.</p>

<hr />

<h1>Architecture of Maglica</h1>

<p>Maglica has four components.</p>

<ol>
<li>Library</li>
<li>CLI</li>
<li>Client worker</li>
<li>Host workers</li>
</ol>


<p>Maglica library is a main component of Maglica.Maglica CLI calls the library
to do the jobs.The library talks to libvirtd on other hosts directly to get
virtual machines information.</p>

<p>Maglica client worker is running on the same host on which CLI runs.
Client worker binds zeromq PUB socket to tcp://<em>:5555 and REP socket
to tcp://</em>:5556.</p>

<p>Client worker recieves requests from library through REP socket and throws
request to host workers through PUB socket.Also REP socket recives job results
from host workers.</p>

<p>Host workers are running on hosts which virtual machines are running on.</p>

<p>Host workers connect to the PUB socket of a client worker to receive job
requests and the REP socket of a client worker to throw job results.</p>

<p>[[Image(http://mizzy.org/img/maglica_architecture.jpg)]]</p>

<hr />

<h1>How to use Maglica</h1>

<p>You must setup libvirtd running on host machines and accessible through
tcp port. (See http://libvirt.org/remote.html)</p>

<p>Clone Maglica on a host machine and run the host worker.</p>

<pre><code># git clone git://github.com/mizzy/maglica.git
# cd maglica
# cp etc/maglica.conf.example etc/maglica.conf
</code></pre>

<p>Edit etc/maglica.conf that points to the correct client worker host and port.</p>

<pre><code># ./scripts/maglica_host_worker
</code></pre>

<p>Clone Maglica on a client machine.</p>

<pre><code># git clone git://github.com/mizzy/maglica.git
# cd maglica
# cp etc/maglica.conf.example etc/maglica.conf
</code></pre>

<p>Edit etc/maglica.conf that points to host machines.</p>

<p>Run the client worker.</p>

<pre><code># ./scripts/maglica_client_worker
</code></pre>

<p>Run maglica command to list up &#8220;original images&#8221;(which name is end with
the string &#8220;oroginal&#8221;).</p>

<pre><code># PYTHONPATH=. ./scripts/maglica image list
Name                                     Host
---------------------------------------------------------
SL6.0-x86_64.original                    host0.example.jp  
SL6.1-x86_64.original                    host0.example.jp  
SL6.0-x86_64.original                    host1.example.jp  
SL6.1-x86_64.original                    host1.example.jp  
</code></pre>

<p>Run maclica command to clone a virtual machine image.</p>

<pre><code># ./scripts/maglica vm clone --image=SL6.1-x86_64.original --hostname=vm0.example.jp
</code></pre>

<p>This command clones the image on a host and rewrites network setting of the image with libguestfs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HowToGetGraphiteWorkingOnScientificLinux6]]></title>
    <link href="http://mizzy.org/blog/2011/07/24/HowToGetGraphiteWorkingOnScientificLinux6/"/>
    <updated>2011-07-24T23:18:15+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/24/HowToGetGraphiteWorkingOnScientificLinux6</id>
    <content type="html"><![CDATA[<p>I found a interest tool, <a href="http://graphite.wikidot.com/">Graphite</a> when I was exploring https://github.com/etsy .(<a href="http://graphite.wikidot.com/screen-shots">Screen Shots of Graphite</a>.)</p>

<h1>Install Carbon</h1>

<p><a href="http://graphite.wikidot.com/carbon">Carbon</a> is a backend storage application for Graphite.</p>

<pre><code># wget http://launchpad.net/graphite/1.0/0.9.8/+download/carbon-0.9.8.tar.gz
# tar zxvf carbon-0.9.8.tar.gz
# pushd carbon-0.9.8
# python setup.py install
# popd
</code></pre>

<h1>Install Whisper</h1>

<p><a href="http://graphite.wikidot.com/whisper">Whisper</a> is an alternate to RRD.</p>

<pre><code># wget http://launchpad.net/graphite/1.0/0.9.8/+download/whisper-0.9.8.tar.gz
# tar zxvf whisper-0.9.8.tar.gz
# pushd whisper-0.9.8
# python setup.py install
# popd
</code></pre>

<h1>Install Graphite</h1>

<pre><code># wget http://launchpad.net/graphite/1.0/0.9.8/+download/graphite-web-0.9.8.tar.gz
# tar zxvf graphite-web-0.9.8.tar.gz
# pushd graphite-web-0.9.8      
</code></pre>

<p>Run check-dependencies.py.</p>

<pre><code># ./check-dependencies.py 
[FATAL] Unable to import the 'cairo' module, do you have pycairo installed for python 2.6.5?
[FATAL] Unable to import the 'django' module, do you have Django installed for python 2.6.5?
[WARNING] Unable to import the 'mod_python' module, do you have mod_python installed for python 2.6.5?
This means you will only be able to run graphite in the development server mode, which is not
recommended for production use.
[WARNING]
Unable to import the 'memcache' module, do you have python-memcached installed for python 2.6.5?
This feature is not required but greatly improves performance.

[WARNING]
Unable to import the 'ldap' module, do you have python-ldap installed for python 2.6.5?
Without python-ldap, you will not be able to use LDAP authentication in the graphite webapp.

[WARNING]
Unable to import the 'twisted' package, do you have Twisted installed for python 2.6.5?
Without Twisted, you cannot run carbon on this server.
[WARNING]
Unable to import the 'txamqp' module, this is required if you want to use AMQP.
Note that txamqp requires python 2.5 or greater.
2 necessary dependencies not met. Graphite will not function until these dependencies are fulfilled.
5 optional dependencies not met. Please consider the warning messages before proceeding.
</code></pre>

<p>I use a development server included in Graphite, so mod_python is not needed.</p>

<p>Install packages other than mod_python.</p>

<pre><code># yum install pycairo
# rpm -ivh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-5.noarch.rpm
# yum install Django python-twisted python-memcached python-ldap
# yum install python-setuptools gcc python-devel
# easy_install txamqp
</code></pre>

<p>You need bitmap fonts, so intall it.</p>

<pre><code># yum install bitmap-console-fonts
</code></pre>

<p>Install Graphite and setup it.</p>

<pre><code># python setup.py install
# python /opt/graphite/webapp/graphite/manage.py syncdb
# pushd /opt/graphite/conf
# cp carbon.conf.example carbon.conf
# cp storage-schemas.conf.example storage-schemas.conf
# cp dashboard.conf.example dashboard.conf
</code></pre>

<p>Edit dashborad.conf and uncomment these.</p>

<pre><code>[ui]
default_graph_width = 400
default_graph_height = 250
automatic_variants = true
refresh_interval = 60
</code></pre>

<p>Start Carbon.</p>

<pre><code># /opt/graphite/bin/carbon-cache.py start
</code></pre>

<p>Start example-client included in Graphite source code to send load average data to Carbon.</p>

<pre><code># popd
# python ./examples/example-client.py
</code></pre>

<p>Start a develepment server of Graphite.</p>

<pre><code># /opt/graphite/bin/run-graphite-devel-server.py /opt/graphite  
</code></pre>

<p>Access to port 8080 of this server and you&#8217;ll see the screen of Graphite.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HowDotCloudLazyCopyImplementsCopyOnWrite]]></title>
    <link href="http://mizzy.org/blog/2011/07/17/HowDotCloudLazyCopyImplementsCopyOnWrite/"/>
    <updated>2011-07-17T23:44:34+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/17/HowDotCloudLazyCopyImplementsCopyOnWrite</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/dotcloud/lazycopy">dotcloud/lazycopy</a> is a copy-on-write version of cp.It&#8217;s based on <a href="http://aufs.sourceforge.net/">aufs</a>.</p>

<p>Scientific Linux 5 has aufs rpm on its base repo.So I tried aufs and lazycopy on SL5.CentOS and SL6 don&#8217;t have aufs rpm.</p>

<p>I created source directories and files in them first.</p>

<pre><code># mkdir /tmp/source0
# mkdir /tmp/source1
# mkdir /tmp/source2
# echo source0 &gt; /tmp/source0/0
# echo source1 &gt; /tmp/source1/1
# echo source2 &gt; /tmp/source2/2
</code></pre>

<p>And copied these directories to /tmp/dest with lazycopy command.</p>

<pre><code># lazycopy /tmp/source0 /tmp/source1 /tmp/source2 /tmp/dest
['/tmp/source0', '/tmp/source1', '/tmp/source2'] -&gt; /tmp/dest
</code></pre>

<p>Confirmed that three files wiere there and the content of one of the files.</p>

<pre><code># ls /tmp/dest/
0  1  2
# cat /tmp/dest/0
source0
</code></pre>

<p>Changed the content of /tmp/dest/0 and confirmed that /tmp/source0/0 was not changed.</p>

<pre><code># echo dest &gt; /tmp/dest/0 
# cat /tmp/dest/0 
dest
# cat /tmp/source0/0 
source0
</code></pre>

<p>Lazycopy implements copy-on-write by mounting directories with aufs like this.</p>

<pre><code># mount
...
none on /tmp/dest type aufs (rw,br:/tmp/dest/.aufs/0=rw:/tmp/source0=ro:/tmp/source1=ro:/tmp/source2=ro)
</code></pre>

<p>Lazycopy creates .aufs/0 directory in the destination directory if it doesn&#8217;t exist and mounts it with rw mode as one of the aufs branch.Other source directories are mounted with ro mode, so files in these directories will not be changed.</p>

<p>Changed files and newly created files are saved under /tmp/dest/.aufs/0 directory.So you can see the directory structures like this after unmounting /tmp/dest.</p>

<pre><code># touch /tmp/dest/3
# umount /tmp/dest
# tree -a /tmp/dest
/tmp/dest
`-- .aufs
    `-- 0
        |-- .wh..wh..tmp
        |-- .wh..wh.aufs
        |-- .wh..wh.plnk
        |-- 0
        `-- 3
</code></pre>

<p>So if you unmount /tmp/dest directory and run lazycopy with same options again, you can see the changed files and created files again.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LinuxContainer00]]></title>
    <link href="http://mizzy.org/blog/2011/07/17/LinuxContainer00/"/>
    <updated>2011-07-17T16:33:08+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/17/LinuxContainer00</id>
    <content type="html"><![CDATA[<h1>Make and install lxc rpm packages</h1>

<p>The spec file for lxc is included in lxc source code.So you can make rpm packages of lxc easily.</p>

<pre><code># yum -y update kernel
# reboot
# yum -y install rpm-build libcap-devel docbook-utils kernel-devel gcc make
# wget http://lxc.sourceforge.net/download/lxc/lxc-0.7.4.2.tar.gz
# tar zxvf lxc-0.7.4.2.tar.gz
# mkdir -p ~/rpmbuild/SOURCES
# cp lxc-0.7.4.2.tar.gz ~/rpmbuild/SOURCES
# chown root:root lxc-0.7.4.2/lxc.spec
# rpmbuild -ba lxc-0.7.4.2/lxc.spec --define 'ksrc /usr/src/kernels/`uname -r`'
# rpm -Uvh ~/rpmbuild/RPMS/x86_64/lxc-0.7.4.2-1.x86_64.rpm
</code></pre>

<hr />

<h1>Check whether this os is lxc ready or not</h1>

<p>All statuses should be &#8220;enabled&#8221;.</p>

<pre><code># lxc-checkconfig 
Kernel config /proc/config.gz not found, looking in other places...
Found kernel config file /boot/config-2.6.32-131.2.1.el6.x86_64
--- Namespaces ---
Namespaces: enabled
Utsname namespace: enabled
Ipc namespace: enabled
Pid namespace: enabled
User namespace: enabled
Network namespace: enabled
Multiple /dev/pts instances: enabled

--- Control groups ---
Cgroup: enabled
Cgroup namespace: enabled
Cgroup device: enabled
Cgroup sched: enabled
Cgroup cpu account: enabled
Cgroup memory controller: enabled
Cgroup cpuset: enabled

--- Misc ---
Veth pair device: enabled
Macvlan: enabled
Vlan: enabled
File capabilities: enabled
enabled
</code></pre>

<hr />

<h1>Quick Start</h1>

<p>In the man of lxc, you can get how to start lxc quickly.</p>

<pre><code>QUICK START
       You are in a hurry, and you don’t want to read this man page. Ok, with-
       out warranty, here are the commands to launch a  shell  inside  a  con-
       tainer   with   a  predefined  configuration  template,  it  may  work.
       /usr/bin/lxc-execute -n foo -f /usr/share/doc/lxc/examples/
       lxc-macvlan.conf /bin/bash
</code></pre>

<p>But before running lxc-execute, you should mount croup.</p>

<pre><code># mount -t cgroup cgroup /cgroup
# /usr/bin/lxc-execute -n foo -f /usr/share/doc/lxc/examples/lxc-macvlan.conf /bin/bash
</code></pre>

<p>In the container, processes are like this.</p>

<pre><code># ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 10:54 ttyS0    00:00:00 /usr/lib64/lxc/lxc-init -- /bin/
root         2     1  0 10:54 ttyS0    00:00:00 /bin/bash
root        11     2  0 10:55 ttyS0    00:00:00 ps -ef
</code></pre>

<p>You can also see the processes in the container from the outside of the container.</p>

<pre><code># lxc-ps --name=foo
CONTAINER    PID TTY          TIME CMD
foo         1654 ttyS0    00:00:00 lxc-init
foo         1656 ttyS0    00:00:00 bash
</code></pre>

<p>The sample lxc conf is like this.</p>

<pre><code># cat /usr/share/doc/lxc/examples/lxc-macvlan.conf 
# Container with network virtualized using the macvlan device driver
lxc.utsname = alpha
lxc.network.type = macvlan
lxc.network.flags = up
lxc.network.link = eth0
lxc.network.hwaddr = 4a:49:43:49:79:bd
lxc.network.ipv4 = 1.2.3.4/24
lxc.network.ipv6 = 2003:db8:1:0:214:1234:fe0b:3596
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DotCloudCliSourceCodeReading00]]></title>
    <link href="http://mizzy.org/blog/2011/07/12/DotCloudCliSourceCodeReading00/"/>
    <updated>2011-07-12T01:43:32+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/12/DotCloudCliSourceCodeReading00</id>
    <content type="html"><![CDATA[<p>I wonder how &#8220;dotcloud push&#8221; acts, especially on uploading files, so I read the <a href="http://pypi.python.org/pypi/dotcloud.cli">dotcloud.cli source code</a>.</p>

<p>If you execute &#8220;dotcloud push&#8221; with &#8211;export option, you&#8217;ll get the response like this.</p>

<pre><code>$ dotcloud --export push helloworldapp
{
    "data": [
        [
            "upload", 
            ".", 
            "ssh://dotcloud@uploader.dotcloud.com:21122/helloworldapp", 
            {
                "rsync": {
                    "excludes": [
                        "*.pyc", 
                        ".git", 
                        ".hg"
                    ]
                }, 
                "check": true
            }
        ], 
        [
            "call", 
            "deploy helloworldapp.default"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>So you know that dotcloud command will run Remote.upload() method.(See DotCloudCliBehaviorOverView.)</p>

<p>You can see the upload() method in dotcloud/cli/remote.py.</p>

<pre><code>#!python
    def upload(self, local_dir, destination, args):
        if args.get('check'):
            local_dir = self.check_pushdir(local_dir)
        self.info('# upload {0} {1}'.format(local_dir, destination))
        if os.path.isdir(os.path.join(local_dir, '.hg')):
            return self.hg(local_dir, destination, args.get('hg', {}))
        if os.path.isdir(os.path.join(local_dir, '.git')):
            return self.git(local_dir, destination, args.get('git', {}))
        return self.rsync(local_dir, destination, args.get('rsync', {}))
</code></pre>

<p>If you have .hg directory, dotcloud command runs self.hg().If you have .git directory, dotcloud command runs self.git().Otherwise dotcloud command runs self.rsync().</p>

<p>You can see these methods in the same file.</p>

<pre><code>#!python
    def rsync(self, local_dir, destination, args):
        self.info('# rsync')
        excludes = args.get('excludes')
        url = utils.parse_url(destination)
        ssh = ' '.join(self._ssh_options)
        ssh += ' -p {0}'.format(url['port'])
        if not os.path.isfile(local_dir) and not local_dir.endswith('/'):
            local_dir += '/'
        rsync = (
                    'rsync', '-lpthrvz', '--delete', '--safe-links',
                ) + tuple('--exclude={0}'.format(e) for e in excludes) + (
                    '-e', ssh, local_dir,
                    '{user}@{host}:{dest}/'.format(user=url['user'],
                        host=url['host'], dest=url['path'])
                )
        try:
            ret = subprocess.call(rsync, close_fds=True)
            if ret != 0:
                self.warning_ssh()
            return ret
        except OSError:
            self.die('rsync')

    def hg(self, local_dir, destination, args):
        self.info('# hg')
        with utils.cd(local_dir):
            try:
                ssh = ' '.join(self._ssh_options)
                args = ('hg', 'push', '--ssh', ssh, '-f', destination)
                ret = subprocess.call(args, close_fds=True)
                if ret != 0:
                    self.warning_ssh()
                return ret
            except OSError:
                self.die('hg')

    def git(self, local_dir, destination, args):
        self.info('# git')
        with utils.cd(local_dir):
            try:
                os.environ['GIT_SSH'] = '__dotcloud_git_ssh'
                os.environ['DOTCLOUD_SSH_KEY'] = config.CONFIG_KEY
                ret = subprocess.call(('git', 'push', '-f', '--all',
                    destination), close_fds=True)
                if ret != 0:
                    self.warning_ssh()
                return ret
            except OSError:
                self.die('git')
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DotCloudCliBehaviorOverView]]></title>
    <link href="http://mizzy.org/blog/2011/07/10/DotCloudCliBehaviorOverView/"/>
    <updated>2011-07-10T20:20:07+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/10/DotCloudCliBehaviorOverView</id>
    <content type="html"><![CDATA[<p>Now I&#8217;m investigating the behavior of <a href="http://pypi.python.org/pypi/dotcloud.cli">dotcloud.cli</a>.I will write down the things I found.</p>

<p>With &#8211;export option, you can see the raw response of dotcloud API.</p>

<p>For example, if you execute dotcloud command for the first time with &#8211;export option, you will see the result like this.</p>

<pre><code>$ dotcloud --export
Warning: /Users/miya/.dotcloud/dotcloud.conf does not exist.
Enter your api key (You can find it at http://www.dotcloud.com/account/settings): XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
{
    "data": [
        [
            "key", 
            "-----BEGIN DSA PRIVATE KEY-----\nXXXXXXXXXX...\n-----END DSA PRIVATE KEY-----\n"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>If &#8216;&#8220;type&#8221;: &#8220;cmd&#8221;&#8217; is given, dotcloud command call the appropriate method.In this case, key() method of Remote class in dotcloud/cli/remote.py will be called and SSH key string will be written to ~/.dotcloud/dotcloud.key.</p>

<p>Which method is called are defined in dotcloud/cli/cli.py like this.</p>

<pre><code>#!python
def run_remote(cmd):
    r = remote.Remote()
    handlers = {
            'set_url': r.set_url,
            'run': r.run,
            'script': r.run_script,
            'sftp': r.sftp,
            'pull': r.pull,
            'push': r.push,
            'rsync': r.rsync,
            'git': r.git,
            'hg': r.hg,
            'upload': r.upload,
            'loop': lambda *x: run_loop(*x),
            'confirm': local.confirm,
            'call': lambda x: run_command(x, True),
            'echo': lambda x: sys.stdout.write('{0}\n'.format(x)),
            'echo_error': lambda x: sys.stderr.write('{0}\n'.format(x)),
            'set_verbose': r.set_verbose,
            'key': r.key
            }
</code></pre>

<p>Let&#8217;s see another command option.</p>

<pre><code>$ dotcloud --export create helloworldapp
{
    "data": "Created repos \"helloworldapp\"", 
    "type": "success"
}
</code></pre>

<p>In this case, type is not cmd, so dotcloud command will do nothing anymore.</p>

<p>In the case of option push, API response is like this.</p>

<pre><code>$ dotcloud --export push helloworldapp
{
    "data": [
        [
            "upload", 
            ".", 
            "ssh://dotcloud@uploader.dotcloud.com:21122/helloworldapp", 
            {
                "rsync": {
                    "excludes": [
                        "*.pyc", 
                        ".git", 
                        ".hg"
                    ]
                }, 
                "check": true
            }
        ], 
        [
            "call", 
            "deploy helloworldapp.default"
        ]
    ], 
    "type": "cmd"
}
</code></pre>

<p>&#8220;type&#8221; is &#8220;cmd&#8221;, so Remote.upload() will be called and run_command(&#8216;deploy helloworldapp.default&#8217;, True) will be called.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ProPuppet00]]></title>
    <link href="http://mizzy.org/blog/2011/07/10/ProPuppet00/"/>
    <updated>2011-07-10T10:12:32+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/10/ProPuppet00</id>
    <content type="html"><![CDATA[<h1>!html</h1>

<pre><code>&lt;img src="http://www.apress.com/media/catalog/product/cache/9/image/9df78eab33525d08d6e5fb8d27136e95/A/9/A9781430230571-3d_11.png" /&gt;
</code></pre>

<p>[wiki:ManagingInfrastructureWithPuppet Managing Infrastructure With Puppet] の中でも少しだけ触れた、<a href="http://www.apress.com/9781430230571">Pro Puppet</a> についてメモ。</p>

<p>こちらは内容盛りだくさんで、Puppet をヘビーに使っている人でも読みごたえがあるんじゃないかと。たとえば、バージョン違いの Puppet を混在させる方法、といったところもフォローされていたり。</p>

<p>ただし、Puppet や、Git といった周辺ツールのインストール方法まで詳細に書かれていて、この辺は自分には必要ないなー、と思ったりもした。</p>

<p>とはいえ、最近の Puppet 動向を追いかけていない自分には、とても有意義な内容が多かったので、その辺についてメモしてみる。</p>

<p>（あんまり書きすぎると出版社の人に怒られそうなんで、さらっと。あと、量が多くなりそうなので、何度かにわけて書く。）</p>

<hr />

<h1>モジュール化について</h1>

<p>Puppet 解説書なんで、当然のことながらマニフェストの書き方が最初の方に出てくるんだけど、本書ではいきなりモジュールを作成するところから始めていて驚いた。</p>

<p>このことで思ったのは、マニフェストはとにかく全部モジュール化しちゃう、というのがベストプラクティスなのかもしれない、ということ。</p>

<p><a href="http://gihyo.jp/admin/serial/01/puppet/0008">第8回　Puppet実践テクニック（その3）</a> の中で書いているデータファイルの構造は、modules ディレクトリはあるものの、すべてをモジュール化することは想定していないため、menifests ディレクトリの下に、クラス毎にマニフェストファイルを置いている。</p>

<p>このやり方だと、dist の下にもクラス毎にスタティックなファイルがあったり、templates の下にもクラス毎にテンプレートがあったりで、同じクラスで利用するマニフェスト、スタティックファイル、テンプレートがばらばらな場所にあって、非常にさがしづらい、といったはめになる。（なので上の記事の内容は今となっては真似しない方がいい。）</p>

<p>これがすべてモジュール化されていると、</p>

<pre><code>modules/
  |
  +--- ssh/
  |     |
  |     +--- files/
  |     |
  |     +--- manifets/
  |     |
  |     +--- templates/
  |
  +--- postfix/
        |
        +--- files/
        |
        +--- manifests/
        |
        +--- templates/
</code></pre>

<p>といった形で、関連するマニフェスト、スタティックファイル、テンプレートが1カ所にまとまっていて、非常に見通しが良い。</p>

<hr />

<h1>モジュールのマニフェストファイルとクラスの分け方</h1>

<p>本書では以下のようにマニフェストファイルをわけている。(ssh モジュールの例。ファイル内容は本とは少し変えてる。)</p>

<pre><code>ssh/
 |
 +--- manifets/
        |
        +--- init.pp
        |
        +--- params.pp
        |
        +--- install.pp
        |
        +--- config.pp
        |
        +--- service.pp
</code></pre>

<p>で、各ファイルの内容は以下のような感じ。</p>

<p><em>init.pp</em></p>

<p>ssh モジュールを利用をするために include ssh すると、このファイルが読み込まれ ssh モジュールが適用される。</p>

<p>このファイルでは、さらにモジュール内で細分化されたクラスを include しているだけ。</p>

<pre><code>class ssh {
    include ssh::params, ssh::install, ssh::config, ssh::service
}
</code></pre>

<ul>
<li>params.pp*</li>
</ul>


<p>環境毎に異なるパラメータをまとめるためのファイル。このファイル内にパラメータをまとめることによって、モジュール全体の見通しを良くする。</p>

<pre><code>class ssh::params {
    case $operatingsystem {
        Solaris: {
            $package_name = 'openssh'
            $service_name = 'sshd'
        }
        ...
    }
}
</code></pre>

<p><em>install.pp</em></p>

<p>必要なパッケージをインストールするためのマニフェスト。</p>

<pre><code>class ssh::install {
    package { $ssh::params::package_name: ensure =&gt; installed }
}
</code></pre>

<p><em>config.pp</em></p>

<p>設定ファイル用マニフェスト。</p>

<pre><code>class ssh::config {
    file { '/etc/ssh/sshd_config':
        ensure  =&gt; present,
        source  =&gt; 'puppet:///modules/ssh/sshd_config',
        require =&gt; Class['ssh::install'],
        notify  =&gt; Class['ssh::service'],
    }
}
</code></pre>

<p><em>service.pp</em></p>

<p>サービス用マニフェスト。</p>

<pre><code>class ssh::service {
    ensure  =&gt; running,
    enable  =&gt; true,
    require =&gt; Class['ssh::config'],
}
</code></pre>

<p>こういった形で、ssh モジュールの中でも、ssh::params, ssh::install, ssh::config, ssh::service といった形でクラスを役割毎に細分化して、ファイルもクラス毎に作成、といった形で、一ファイル内の見通しを良くする、というやり方が紹介されている。</p>

<p>もうひとつのポイントは、require や notify で Class 指定していること。（Class を require とかするのって以前のバージョンからできるんだっけ？）</p>

<p>たとえば、sercice.pp では、</p>

<pre><code>require =&gt; Class['ssh::config'],
</code></pre>

<p>といった指定があるが、これは以下のように、Class ではなく File でも指定できる。</p>

<pre><code>require =&gt; File['/etc/ssh/sshd_config'],
</code></pre>

<p>ひとつの設定ファイルから構成されているようなモジュールであればこれでも良いが、複数の設定ファイルから構成されるようなモジュールだと、変更に対して脆くなってしまう。例えば postfix モジュールで考えてみる。</p>

<p>最初は main.cf のみ Puppet で管理して、他の設定ファイルはデフォルトのまま、という状態を想定すると、マニフェストは以下のようになる。</p>

<pre><code>class postfix::config {
    file { '/etc/postfix/main.cf':
        source =&gt; 'file:///modules/postfix/main.cf',
    }
}

class postfix::service {
    service { 'postfix':
        ensure  =&gt; running,
        enable  =&gt; true,
        require =&gt; File['/etc/postfix/main.cf'],
    }
}
</code></pre>

<p>後から、master.cf もデフォルトのままではなくなったので、Puppet で管理することにすると、マニフェストは以下のように、postfix::config と postfix::service の両方を書き換えることになる。</p>

<pre><code>#!diff
diff --git a/postfix.pp b/postfix.pp
index f55234e..a032d65 100644
--- a/postfix.pp
+++ b/postfix.pp
@@ -2,12 +2,16 @@ class postfix::config {
     file { '/etc/postfix/main.cf':
         source =&gt; 'file:///modules/postfix/main.cf',
     }
+    file { '/etc/postfix/master.cf':
+        source =&gt; 'file:///modules/postfix/master.cf',
+    }
 }

 class postfix::service {
     service { 'postfix':
         ensure  =&gt; running,
         enable  =&gt; true,
-        require =&gt; File['/etc/postfix/main.cf'],
+        require =&gt; [ File['/etc/postfix/main.cf'], File['/etc/postfix/master.cf
     }
 }
</code></pre>

<p>もし、Class を require するようになっていれば、main.cf だけを管理する最初の状態では、マニフェストは</p>

<pre><code>class postfix::config {
    file { '/etc/postfix/main.cf':
        source =&gt; 'file:///modules/postfix/main.cf',
    }
}

class postfix::service {
    service { 'postfix':
        ensure  =&gt; running,
        enable  =&gt; true,
        require =&gt; Class['postfix::config'],
    }
}
</code></pre>

<p>となっており、master.cf を追加した場合、差分は</p>

<pre><code>#!diff
diff --git a/postfix.pp b/postfix.pp
index 9745478..e82621c 100644
--- a/postfix.pp
+++ b/postfix.pp
@@ -2,6 +2,9 @@ class postfix::config {
     file { '/etc/postfix/main.cf':
         source =&gt; 'file:///modules/postfix/main.cf',
     }
+    file { '/etc/postfix/master.cf':
+        source =&gt; 'file:///modules/postfix/master.cf',
+    }
 }

 class postfix::service {
</code></pre>

<p>だけになり、postfix::service はまったく変更する必要がない。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ManagingInfrastructureWithPuppet]]></title>
    <link href="http://mizzy.org/blog/2011/07/08/ManagingInfrastructureWithPuppet/"/>
    <updated>2011-07-08T02:36:30+09:00</updated>
    <id>http://mizzy.org/blog/2011/07/08/ManagingInfrastructureWithPuppet</id>
    <content type="html"><![CDATA[<h1>!html</h1>

<pre><code>&lt;img src="http://covers.oreilly.com/images/0636920020875/lrg.jpg" /&gt;
</code></pre>

<hr />

<p><a href="http://twitter.com/#!/kdmsnr">@kdmsnr さん</a> の tweet で、<a href="http://oreilly.com/catalog/0636920020875">Managing Infrastructure with Puppet</a> と <a href="http://www.apress.com/9781430230571">Pro Puppet</a> が発売されている事を知ったので読んでみた。まずは Managing Infrastructure with Puppet について。</p>

<p>この本はとても薄い。全体で40ページ強くらい。なので、Puppet をまったく知らない人には全体像を知るためには良い本だけど、既に知っている人には物足りないと思う。</p>

<p>とは言っても、自分は最近の Puppet の動向を追えてないので、その辺の知識不足を補ってくれるような内容もあって、そこは良かった。</p>

<p>また、<a href="http://www.puppetlabs.com/mcollective/introduction/">MCollective</a> についても書かれていて、元々は Puppet Labs とは別なところで開発されていたツールなんで、Puppet とは完全に独立したツールだと思ってたんだけど、Puppet Labs 配下になってから統合が進められたようで、その辺の情報が得られたのがよかった。</p>

<p>以下、内容で気になったところなんかのメモ。</p>

<hr />

<h1>puppet コマンド</h1>

<p>0.25 の次は 2.6 という風にバージョン体系が変わり、それまで puppetmasterd や puppetd といった形で独立していたコマンドが puppet コマンドに統一された、ってことは <a href="http://twitter.com/#!/tnmt">ペパボのイケメンインフラエンジニアの tnmt くん</a> が<a href="http://blog.tnmt.info/2010/11/23/puppet-2-6/">既にブログに書いてある</a> んだけど、それに伴い、コマンドオプションも増えて、やれることが増えてる模様。その中で特に気になったオプションを紹介。</p>

<h2>puppet describe</h2>

<p>リソースタイプのリストを表示してくれたり、指定したリソースタイプに関する説明を表示してくれる。</p>

<p><em>リソースタイプのリスト</em></p>

<pre><code>$ puppet describe --list
These are the types known to puppet:
augeas          - Apply the changes (single or array of changes ...
computer        - Computer object management using DirectorySer ...
cron            - Installs and manages cron jobs
exec            - Executes external commands
file            - Manages local files, including setting owners ...
filebucket      - A repository for backing up files
group           - Manage groups
host            - Installs and manages host entries
k5login         - Manage the `
...
</code></pre>

<p><em>package リソースタイプの説明</em></p>

<pre><code>$ puppet describe package

package
=======
Manage packages.  There is a basic dichotomy in package
support right now:  Some package types (e.g., yum and apt) can
retrieve their own package files, while others (e.g., rpm and sun) cannot. 
For those package formats that cannot retrieve
their own files, you can use the `source` parameter to point to
the correct file.

Puppet will automatically guess the packaging format that you are
using based on the platform you are on, but you can override it
using the `provider` parameter; each provider defines what it
requires in order to function, and you must meet those requirements
to use a given provider.
</code></pre>

<p><strong>Autorequires:</strong> If Puppet is managing the files specified as a package&#8217;s</p>

<pre><code>`adminfile`, `responsefile`, or `source`, the package resource will
autorequire
those files.


Parameters
----------

- **adminfile**
    A file containing package defaults for installing packages.
    This is currently only used on Solaris.  The value will be
    validated according to system rules, which in the case of
    Solaris means that it should either be a fully qualified path
    or it should be in `/var/sadm/install/admin`.

...
</code></pre>

<p>詳しくは puppet describe &#8211;help を参照。</p>

<h2>puppet resource</h2>

<p>コマンドを実行してるマシンの指定されたリソースの状態を、Puppet マニフェストで表示してくれる。</p>

<p><em>host リソースの表示</em></p>

<p>/etc/hosts の内容を Puppet マニフェストで表示。</p>

<pre><code>$ puppet resource host
host { 'localhost.localdomain':
  ensure       =&gt; 'present',
  host_aliases =&gt; ['localhost'],
  ip           =&gt; '127.0.0.1',
  target       =&gt; '/etc/hosts',
}
host { 'localhost6.localdomain6':
  ensure       =&gt; 'present',
  host_aliases =&gt; ['localhost6'],
  ip           =&gt; '::1',
  target       =&gt; '/etc/hosts',
}
</code></pre>

<p><em>service リソースの表示</em></p>

<p>サービスの状態を Puppet マニフェストで表示。</p>

<pre><code>$ puppet resource service
service { 'NetworkManager':
  ensure =&gt; 'stopped',
  enable =&gt; 'false',
}
service { 'acpid':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}
service { 'anacron':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}
service { 'atd':
  ensure =&gt; 'running',
  enable =&gt; 'true',
}
service { 'autofs':
  ensure =&gt; 'stopped',
  enable =&gt; 'true',
}

...
</code></pre>

<p>既に環境構築されたマシンから Puppet マニフェストの雛形を生成する、とかいった目的に使えそう。</p>

<h2>puppet apply</h2>

<p>Puppet マニフェストを即座に適用できる。</p>

<p><em>test.pp 内のマニフェストを適用する</em></p>

<pre><code>$ puppet apply test.pp
</code></pre>

<p><em>直接マニフェストを文字列で指定するが &#8211;noop つけてるので実際には何もしない</em></p>

<pre><code>$ puppet apply --noop -e 'file { "/etc/passwd": mode =&gt; 600 }'
notice: /Stage[main]//File[/etc/passwd]/mode: current_value 644, should be 600 (noop)
notice: Finished catalog run in 0.05 seconds
</code></pre>

<p>ちょっとした動作確認なんかするのに便利そう。</p>

<hr />

<h1>Parameterized Classes</h1>

<p>define でリソース定義して、呼び出すときにパラメータを渡す、なんてことは以前からできてたけど、2.6 からは Class にパラメータを渡すことができるようになったらしい。</p>

<p>クラス定義はこんな感じ。</p>

<pre><code>class ruby ( $version = '1.8.7') {
    package { 'ruby': ensure =&gt; $version }
}
</code></pre>

<p>Parameterized Classes ではない、従来のクラスの呼び出し方。これだと、Ruby 1.8.7 がインストールされる。</p>

<pre><code>node 'test.example.jp' {
    include ruby
}
</code></pre>

<p>パラメータを渡してやると、Ruby 1.9.2 がインストールされる。</p>

<pre><code>node 'test.example.jp' {
    class { 'ruby': version =&gt; '1.9.2' }
}
</code></pre>

<p>便利そうだけど、従来の include とだいぶ書式が変わるので、混乱しそう。</p>

<hr />

<h1>Puppet Forge</h1>

<p>Puppet モジュールを集めた <a href="http://forge.puppetlabs.com/">Puppet Forge</a> なんてサイトができてたんだね。Puppet 版 CPAN といった感じ。<a href="http://github.com/puppetlabs/puppet-module-tool">puppet-module-tool</a> というコマンドラインツールを使って、モジュールのインストールとかパッケージングとか色々できるようなんだけど、この本には詳しい説明がなかった。Pro Puppet には詳しい説明があったので、Pro Puppet についての感想を書くときに、この辺について少し詳しく書くつもり。</p>

<hr />

<h1>MCollective</h1>

<p>MCollective は、複数のホストに対して同じ処理を並列実行するためのもの。<a href="https://fedorahosted.org/func/">Func</a> とか <a href="http://fabfile.org/">Fabric</a> とか <a href="http://www.capify.org/">Capistrano</a> みたいな位置づけ。</p>

<p>こんな感じで実行できる。（apache2 を再起動する例。）</p>

<pre><code>$ mc-service --with-class apache2 apache2 restart
$ mc-service --with-class apache2 --with-fact architecture=x86_64 apache2 restart
</code></pre>

<p>Puppet の特定のクラスを include してるホストでのみ実行とか、特定の fact (facter によって得られる値) にマッチするホストでのみ実行、という感じで Puppet と連動できる。</p>

<p><a href="http://projects.puppetlabs.com/projects/mcollective-plugins/wiki/AgentPuppetd">Puppetd Agent</a> というプラグインもあって、これを使うと、各ホストの puppet agent の操作を MCollective 経由でできる。つまり、puppet kick(古いバージョンだと puppetrun)の代わりに使える。これの何がうれしいのかというと、puppetrun では特定のクラスを include したホストだけを対象にする、ということをやろうと思うと、LDAP Nodes が必須だった（2.6 でもそうなのかは知らん）けど、このプラグインだとそれが不要になりそう、ってあたりかな。</p>

<p>あと、<a href="http://projects.puppetlabs.com/projects/mcollective-plugins/wiki/ToolPuppetcommander">Puppet Commander</a> というプラグインを使うと、puppet agent の同時起動数を制御できて、puppet master へ同時アクセスが集中しないようにコントロールできるらしい。大量にホストがある環境では良さそうですね。</p>

<p>それから、<a href="http://docs.puppetlabs.com/mcollective/simplerpc/agents.html">MCollective プラグインを書くためのドキュメントへのリンク</a> も載ってた。が本では詳しい説明はなし。</p>

<hr />

<p>というわけで、<a href="http://oreilly.com/catalog/0636920020875">Managing Infrastructure with Puppet</a> について気になった点は以上。次は <a href="http://www.apress.com/9781430230571">Pro Puppet</a> について、気が向いたら書きます。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SubsonicThroughApacheProxy]]></title>
    <link href="http://mizzy.org/blog/2011/06/29/SubsonicThroughApacheProxy/"/>
    <updated>2011-06-29T22:40:54+09:00</updated>
    <id>http://mizzy.org/blog/2011/06/29/SubsonicThroughApacheProxy</id>
    <content type="html"><![CDATA[<p><a href="http://twitter.com/#!/earlcyborg">@earlcyborg くん</a> に教えてもらった <a href="http://www.subsonic.org/pages/index.jsp">Subsonic</a> がよさげなので、家の中に環境作り、Apache mod_proxy 経由でアクセスしようとしたらはまったのでメモ。</p>

<p>結論: ProxyPreserveHost On を入れないとはまる。</p>

<p>最初、</p>

<pre><code>&lt;VirtualHost *&gt;
ServerName subsonic.mizzy.org
ProxyPass / http://192.168.10.14:4040/
ProxyPassReverse / http://192.168.10.14:4040/
&lt;/VirtualHost&gt;
</code></pre>

<p>という設定で http://subsonic.mizzy.org/ にアクセスしたら、http://192.168.10.14:4040/login.view? にリダイレクトされてしまった。Subsonic にホスト名を設定するところもなさそう。そこで、おそらく Host ヘッダに設定されたホストがリダイレクト先になるんじゃなかろうか、と仮説を立てて、以下のように設定してみた。</p>

<pre><code>&lt;VirtualHost *&gt;
ServerName subsonic.mizzy.org
ProxyPreserveHost On
ProxyPass / http://192.168.10.14:4040/
ProxyPassReverse / http://192.168.10.14:4040/
&lt;/VirtualHost&gt;
</code></pre>

<p>これでうまくいった。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ModRuidTestAgain]]></title>
    <link href="http://mizzy.org/blog/2011/06/25/ModRuidTestAgain/"/>
    <updated>2011-06-25T12:30:43+09:00</updated>
    <id>http://mizzy.org/blog/2011/06/25/ModRuidTestAgain</id>
    <content type="html"><![CDATA[<p>3,4年ぐらい前に、[wiki:ModSuid2AndModRuidAndLinuxCapability  mod_suid2 とか mod_ruid とか Linux ケーパビリティとか] で、mod_ruid の setuid/setgid は、プロセス単位なのか、それともスレッド単位なのか、という実験をして、スレッド単位で setuid/setgid する、という結果が得られたんですが、Linux kernel 2.4 というだいぶ古い環境での実験だったので、比較的最近の環境で実験してみた。</p>

<p>OS はこんな感じ。</p>

<pre><code>$ uname -a
Linux h026.southpark 2.6.18-164.el5 #1 SMP Thu Sep 3 03:28:30 EDT 2009 x86_64 x86_64 x86_64 GNU/Linux
$ cat /etc/redhat-release
CentOS release 5.4 (Final)
</code></pre>

<p>httpd のバージョン。</p>

<pre><code>$ rpm -q httpd
httpd-2.2.3-45.el5.centos.1
</code></pre>

<p>ps でプロセス/スレッドが見やすいように /etc/httpd/conf/httpd.conf をいじる。</p>

<pre><code>&lt;IfModule worker.c&gt;
StartServers        1
MaxClients          1
MinSpareThreads     1
MaxSpareThreads     1
ThreadsPerChild     1
MaxRequestsPerChild  0
&lt;/IfModule&gt;
</code></pre>

<p>/etc/sysconfig/httpd の以下の行を有効にして worker mpm で動かす。</p>

<pre><code>HTTPD=/usr/sbin/httpd.worker
</code></pre>

<p>mod_ruid は処理が終わるとすぐに元のユーザに戻してしまうので、戻らないようにコメントアウト。</p>

<pre><code>#!diff
diff --git a/mod_ruid.c b/mod_ruid.c
index 5294d32..deed59b 100644
--- a/mod_ruid.c
+++ b/mod_ruid.c
@@ -269,9 +269,9 @@ static int ruid_suidback (request_rec * r)
        }
        cap_free(cap);

-       setgroups(0,NULL);
-       setgid(unixd_config.group_id);
-       setuid(unixd_config.user_id);
+       //setgroups(0,NULL);
+       //setgid(unixd_config.group_id);
+       //setuid(unixd_config.user_id);

        cap=cap_get_proc();
        capval[0]=CAP_SETUID;
</code></pre>

<p>apxs でビルド＆インストール。</p>

<pre><code>$ sudo /usr/sbin/apxs -a -i -l cap -c mod_ruid.c
</code></pre>

<p>/etc/init.d/httpd restart して、プロセスとスレッドの UID を確認。下3つは PID が同じなので、スレッドだと判断できる。UID はすべて apache。</p>

<pre><code>$ ps -eLf
UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD
root     13005     1 13005  0    1 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13011  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13013  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13014  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
</code></pre>

<p>ここで httpd へアクセスし、再度 ps で確認。</p>

<pre><code>UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD
root     13005     1 13005  0    1 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13011  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
100      13011 13005 13013  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
apache   13011 13005 13014  0    3 23:29 ?        00:00:00 /usr/sbin/httpd.worker
</code></pre>

<p>スレッドのひとつだけ UID が 100 になってる。これは mod_ruid.c に以下のようにデフォルトが定義されているから。</p>

<pre><code>#!c
#define SUID_DEFAULT_UID        100
#define SUID_DEFAULT_GID        100
</code></pre>

<p>というわけで、スレッド単位で setuid/setgid される、ということには変わりありませんでした、という結果に。</p>
]]></content>
  </entry>
  
</feed>
