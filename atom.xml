<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Gosuke Miyashita]]></title>
  <link href="http://mizzy.org/atom.xml" rel="self"/>
  <link href="http://mizzy.org/"/>
  <updated>2013-03-22T02:19:00+09:00</updated>
  <id>http://mizzy.org/</id>
  <author>
    <name><![CDATA[Gosuke Miyashita]]></name>
    
  </author>
  <generator uri="https://github.com/mizzy/stellar/">Stellar</generator>


  <entry>
    <title type="html"><![CDATA[puppet-lxc-test-box]]></title>
    <link href="http://mizzy.org/blog/2013/03/22/1/" />
    <updated>2013-03-22T02:19:00+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/22/1/</id>
    <content type="html"><![CDATA[
<p>新たな Puppet のベストプラクティスを求めて、マニフェストの大規模なリファクタリングを行っています。</p>

<p>で、リファクタリングするからにはテストが必要だよね、ってことで、<a href="http://rspec-puppet.com/">rspec-puppet</a> でテストを書いてるんだけど、rspec-puppet はマニフェストがコンパイルされた「カタログ」というものに対してテストするもので、実際にマニフェストを流し込んだ状態が正しいかテストするわけではないので、これだとテストとしては不完全。</p>

<p>というわけで、<a href="https://github.com/opscode/test-kitchen">Test Kitchen</a> みたいに、同時にいくつも VM を立ててテストを走らせる、ってなことをやりたいんだけど、会社では KVM ベースの VM を利用してるので、VirtualBox ベースの Vagrant は使えないし、そもそもテストを動かす大元のホストも VM なので、VirtualBox どころか KVM も利用できない。</p>

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>なので、まずは LXC のシステムコンテナをさくさくと作るための Puppet モジュールを書いてみた。</p>

<p><a href="https://github.com/mizzy/puppet-lxc-test-box">puppet-lxc-test-box</a></p>

<p>( <a href="https://github.com/fgrehm/vagrant-lxc">vagrant-lxc</a> というのもあるけど、&quot;Vagrant &gt;= 1.1.0, the lxc package and a Kernel higher than 3.5.0-17.28, which on Ubuntu 12.10 means something like&quot; ってなことが書かれていて、メインで使ってる RedHat 系 OS では動く気がしないのでスルー。)</p>

<p>使い方は次のような感じ。まず lxc-test-box モジュールと sysctl モジュールを持ってくる。</p>

<pre><code>$ git clone git://github.com/mizzy/puppet-lxc-test-box.git lxc-test-box
$ git clone git://github.com/duritong/puppet-sysctl.git sysctl
</code></pre>

<p>以下のように、Exec リソースのデフォルト値と、システムコンテナのホスト名と IP アドレスを書いたマニフェスト lxc-test-box.pp を作成。</p>

<pre><code>include lxc-test-box

Exec { path =&gt; &#39;/sbin:/usr/sbin:/bin:/usr/bin&#39; }

lxc-test-box::lxc::setup { &#39;base&#39;:   ipaddress =&gt; &#39;172.16.0.2&#39; }
lxc-tets-box::lxc::setup { &#39;manage&#39;: ipaddress =&gt; &#39;172.16.0.3&#39; }
lxc-test-box::lxc::setup { &#39;smtp&#39;:   ipaddress =&gt; &#39;172.16.0.4&#39; }
</code></pre>

<p>マニフェストを流し込む。</p>

<pre><code>$ sudo puppet apply --modulepath=. lxc-test-box.pp
</code></pre>

<p>これで、ホスト OS への lxc パッケージのインストール、ブリッジインターフェース br0 の作成、IP マスカレードの設定を行い、指定されたホスト名と IP アドレスでシステムコンテナを作成し、コンテナの起動までしてくれる。所要時間は、コンテナひとつあたり5分ぐらい。</p>

<p>起動したら、</p>

<pre><code>$ ssh root@base.lxc-test-box
</code></pre>

<p>で、ログインできる。ログイン用の鍵は Puppet で設定済み。（ただし、鍵は /root/.ssh 以下に置いてあるので、必要ならそこからコピーを。）テスト目的なのでホストOSとは通信できるけど、外部からは通信できない。ただし、ホスト OS で IP マスカレードの設定はしてあるので、コンテナから外部への通信は可能。</p>

<p>同梱している lxc パッケージは Scientifix Linux 6.2 + Kernel 2.6.32-358.2.1.el6.x86_64 上でビルドしたものなので、RedHat 6 系以外ではたぶん動かないし、カーネルバージョンが違うと動かないかもしれない。</p>

<p>これでテスト用のシステムコンテナを量産できるようになったので、次は実際にテストする仕組みを作り込む。</p>

<hr>

<p>KVM な VM の上で KVM な VM は動かせない、と思っていたら、<a href="https://twitter.com/ursm">@usrm</a> さんから、最近のカーネルであればネストできるはず、という情報をいただきました。</p>

<blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/gosukenator">gosukenator</a> 最近のカーネルであれば KVM のネストはできるはずです <a href="http://t.co/HZf5HhhUYs" title="http://networkstatic.net/nested-kvm-hypervisor-support/">networkstatic.net/nested-kvm-hyp…</a></p>&mdash; Keita Urashima (@ursm) <a href="https://twitter.com/ursm/status/314802865313042432">March 21, 2013</a></blockquote>

<p>とても有益な情報ありがとうございます！今度試してみよう。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[最小手順の Vagrant base box の作り方]]></title>
    <link href="http://mizzy.org/blog/2013/03/11/1/" />
    <updated>2013-03-11T22:28:50+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/11/1/</id>
    <content type="html"><![CDATA[
<p><a href="http://www.vagrantup.com/">Vagrant</a> の base box をつくるためのツールとして <a href="https://github.com/jedi4ever/veewee">VeeWee</a> があって、これはこれで素晴らしいツールなんだけど、VeeWee は裏で ISO イメージをダウンロードしたり、インストーラを走らせたりで、時間もかかるし大げさな感じがするので、もっと簡略化できないか、ってことでやってみた。</p>

<p><a href="/blog/2013/02/24/1/">最小手順のVMイメージの作り方</a> で紹介したシェルスクリプトで作成した VM イメージに対して、以下のようにコマンドを実行するだけで、package.box ができあがる。</p>

<pre><code class="text"># VBoxManage convertfromraw --format vmdk /tmp/sl63.img /tmp/sl63.vmdk
# VBoxManage createvm --name SL6.3-x86_64 --register
# VBoxManage modifyvm SL6.3-x86_64 --memory 512 --acpi on --nic1 nat
# VBoxManage storagectl SL6.3-x86_64 --name &quot;IDE Controller&quot; --add ide
# VBoxManage modifyvm SL6.3-x86_64 --hda /tmp/sl63.vmdk
# vagrant package --base SL6.3-x86_64
</code></pre>

<p>できあがった package.box に対して以下のようにすれば、VM が起動する。</p>

<pre><code class="text">$ vagrant box add sl63-x86_64 package.box
$ vagrant init sl63-x86_64
$ vagrant up
</code></pre>

<p>ただし、<a href="http://docs-v1.vagrantup.com/v1/docs/base_boxes.html">Vagrant Documentation - Documentation - Base Boxes</a> にあるような、vagrant ユーザの作成とか、鍵の設定なんかはしてないため、<code>vagrant ssh</code> ではログインできないので、<code>ssh root@localhost -p 2222</code> で、パスワードは root でログインする。</p>

<p>この辺の設定もシェルスクリプトに組み込んじゃえばいいんだろうけど、まずは base box を簡単に作れるかどうかだけ確かめたかったので、今日はここまで。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[最小手順のVMイメージの作り方（LVM 編）]]></title>
    <link href="http://mizzy.org/blog/2013/02/24/2/" />
    <updated>2013-02-24T22:53:17+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/24/2/</id>
    <content type="html"><![CDATA[
<p>開発や検証で利用する VM は、最初はディスクサイズを小さくして、後から必要に応じて大きくする、といったことをよくやるので、<a href="/blog/2013/02/24/1/">最小手順のVMイメージの作り方</a> のスクリプトを、/ と swap を LVM にするように変えてみた。</p>

<div><script src='https://gist.github.com/5023926.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>

<p>あとはディストリビューションを選択できるようにとか、指定したホスト名を設定する、とかもやりたいけど、シェルスクリプトは大きくなってくるとメンテナンス厳しいので、Ruby で書き直す。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[最小手順のVMイメージの作り方]]></title>
    <link href="http://mizzy.org/blog/2013/02/24/1/" />
    <updated>2013-02-24T12:29:37+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/24/1/</id>
    <content type="html"><![CDATA[
<p>先日カヤックさんの社内勉強会にお邪魔して話してきた <a href="http://www.slideshare.net/mizzy/maglica-techkayac">Maglica</a> は、既に作成済みの VM イメージを元にクローンをつくって必要な設定（root パスワードの設定やネットワーク設定など）を行う、といったことが簡単にできるが、元の VM イメージつくるのがめんどくさいことには変わりなくて、ここをなんとかしたいなー、と常々思ってた。</p>

<p>VM イメージをつくる手段としては、RedHat 系の場合は virt-manager, virt-install, Cobbler/Koan などがあるが、どれもインストーラを実行する形式であり、kickstart を利用すれば自動化できるとは言え、kickstart は問題が起きた場合の調査がやりにくい。（自分が効果的なやり方知らないだけかもしれないけど。）</p>

<p>また、virt-install はオプション覚えられないし、Cobbler は初期のセットアップとか、profile の設定とかめんどくさい。</p>

<p>そもそも、インストーラを実行しなくても、しかるべきファイルが含まれたイメージをつくればいいだけなので、インストーラの実行はとても無駄に思える。</p>

<p>そこで、<a href="https://twitter.com/hansode">@hansode</a> さんの <a href="https://github.com/hansode/vmbuilder">vmbuilder</a> の存在を思い出して、これを使ってみようと思ったんだけど、単に使うだけじゃなく、具体的にどういったことをやってるのか理解したくて、ソースコードを読んで手順を追い、単純化したスクリプトに落とし込んでみたのがこれ。</p>

<div><script src='https://gist.github.com/5020611.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>

<p>以前 AMI(Amazon Machine Image) をつくった時と基本的には同じだけど、AMI では 1 イメージファイル 1 パーティションだったのが、この手順では 1 イメージファイルにパーティンションが 2 つあるのが大きな違い。kpartx をつかって パーティション毎に loopback device を割り当てるやり方をはじめて知ったので、とても参考になった。</p>

<p>スクリプトの解説も書こうかと思ったけど、ここまで単純化されてれば、あとは man なり Google なりで調べればわかるはずなのでやめた。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[すぐにハッブル宇宙望遠鏡撮影画像を見れるGoogle Chromeの拡張作った。]]></title>
    <link href="http://mizzy.org/blog/2013/02/11/1/" />
    <updated>2013-02-11T00:54:51+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/11/1/</id>
    <content type="html"><![CDATA[
<p>生きていればつらいことがある。
しかし、つらいからと言って簡単に投げ出す事は出来ないということも多い。</p>

<p>みなさんもつらまってる時、よくハッブル宇宙望遠鏡が撮影した画像を見ると思う。
当然のごとく僕もそうである。</p>

<p>最近つらい事がよくある。
そんな時のために、ハッブル宇宙望遠鏡撮影画像を素早く表示する必要があった。
なので、ハッブル宇宙望遠鏡撮影画像をすぐ見れるGoogle Chromeの拡張を作った。</p>

<p><a href="https://github.com/mizzy/chrome-hst-images">mizzy/chrome-hst-images - GitHub</a></p>

<p>「だめだ。もうやってらねー」って時は、空の tab を表示すればすぐハッブル宇宙望遠鏡撮影画像に会える。最高。結婚したい。</p>

<p><img src="/images/2013/02/chrome-hst-image.jpg"></p>

<h2>合わせて読みたい</h2>

<p><a href="http://blog.hisaichi5518.com/entry/2013/02/01/003820">すぐに吉高由里子を見れるGoogle Chromeの拡張作った。 - パルカワ2</a></p>

<p><a href="http://soh335.hatenablog.com/entry/2013/02/10/011039">すぐに宮崎あおいを見れるGoogle Chromeの拡張作った。- soh335 memo</a></p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[MHA for MySQL の概要]]></title>
    <link href="http://mizzy.org/blog/2013/02/06/1/" />
    <updated>2013-02-06T01:50:17+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/06/1/</id>
    <content type="html"><![CDATA[
<p>MHA for MySQL の導入を検討していて、まずは社内の技術者向けに、MHA for MySQL の概要を伝えようと、主に <a href="http://code.google.com/p/mysql-master-ha/wiki/TableOfContents?tm=6">オフィシャルなドキュメント</a> からポイントを抜粋して社内向けの Wiki に書いてみた。本当なら、オフィシャルドキュメント全体に目を通してもらうのがいいんだけど、英語なので、はじめの一歩としては敷居が高く感じる人もいるだろう、ということで。</p>

<p>特に外に出してまずい情報があるわけでもないので、このブログでも曝しておきます。</p>

<hr>

<h2>MHA の概要</h2>

<p>MySQL エキスパートとして世界的にも著名な松信嘉範氏による、MySQL マスターの HA 化を行うためのツール。Perl 製。</p>

<p>最小限のダウンタイムで、データの不整合を防ぎつつ、マスターのフェイルオーバーを行う、というのが主な機能。</p>

<p>また、既に動作している MySQL に影響を与えることなく導入できる。</p>

<p>機能は大きくわけると以下の4つ。</p>

<ul>
<li>自動的なマスターの監視とフェイルオーバー

<ul>
<li>トータルダウンタイム10〜30秒ぐらいで切り替え可能</li>
</ul></li>
<li>手動によるマスターフェイルオーバー</li>
<li>自動的なマスターのフェイルオーバー（監視はしない）

<ul>
<li>監視を既存ソフトウェア（Pacemaker など）で行う場合に有用</li>
</ul></li>
<li>オンラインでマスターを別ホストに切り替え

<ul>
<li>マスターは動作してるが、ハードウェア的に怪しい兆候が見られるので、別ホストに事前に切り替えたい、などといった場合に有用</li>
<li>0.5〜2秒ほど書き込みブロックされるだけで切り替え可能</li>
</ul></li>
</ul>

<hr>

<h2>MHA のコンポーネントと動作概要</h2>

<p>マスターの監視とフェイルオーバーを MHA で自動的に行う場合の構成は以下のようになる。</p>

<p><img src="/images/2013/02/components_of_mha.png" title="Components of MHA" ></p>

<p>動作の流れは以下の通り。</p>

<ul>
<li>Manager が MySQL Master を監視</li>
<li>ダウンを検知すると、以下を実行

<ul>
<li>Master の最新のバイナリログを各 Slave に保存（可能であれば）</li>
<li>新マスターのリカバリ

<ul>
<li>スレーブのうちのひとつを新マスターにする</li>
<li>デフォルトでは一番新しいポジションまで進んでいるスレーブが選ばれる。設定で、このスレーブを次のマスターにする、といったこともできる。</li>
<li>新マスターにバイナリログの最新のポジションまでのデータを反映させる</li>
</ul></li>
<li>その他のスレーブのリカバリ 

<ul>
<li>バイナリログの最新のポジションまでのデータを反映させる</li>
<li>新マスターからレプリケーションを開始</li>
</ul></li>
</ul></li>
</ul>

<p>動作の詳細についてはオフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Sequences_of_MHA">Sequences of MHA</a> を参照。</p>

<hr>

<h2>Manager の拡張</h2>

<p>Manager の本体である masterha_manager には拡張ポイントがいくつかあり、設定ファイル中で以下のパラメータに対してスクリプトを指定することで、動作を拡張することができる。拡張ポイントは以下の通り。</p>

<ul>
<li>secondary_check_script</li>
<li>master_ip_failover_script</li>
<li>shutdown_script</li>
<li>report_script</li>
<li>init_conf_load_script</li>
<li>master_ip_online_change_script</li>
</ul>

<p>例えば、MHA 自体には、マスターがフェイルオーバーした時に VIP を付け替える機能はないが、以下のように VIP 付け替え用のスクリプトを設定ファイルで指定すると、フェイルオーバー時に VIP の付け替えをしてくれる。（スクリプトは自分で用意する。）</p>

<pre><code>master_ip_failover_script=/usr/local/sample/bin/master_ip_failover
</code></pre>

<p>詳細は <a href="http://code.google.com/p/mysql-master-ha/wiki/Architecture#Custom_Extensions">Custom Extensions</a> を参照。</p>

<hr>

<h2>Manager の設定例</h2>

<p>拡張スクリプトの設定など、必須ではないものも含む。</p>

<pre><code>[server default]
# mysql user and password
user=root
password=mysqlpass
# working directory on the manager
manager_workdir=/var/log/masterha/app1
# manager log file
manager_log=/var/log/masterha/app1/app1.log
# working directory on MySQL servers
remote_workdir=/var/log/masterha/app1
secondary_check_script= masterha_secondary_check -s remote_host1 -s remote_host2
ping_interval=3
master_ip_failover_script=/script/masterha/master_ip_failover
shutdown_script=/script/masterha/power_manager
report_script=/script/masterha/send_master_failover_mail

[server1]
hostname=host1
candidate_master=1 # 次のマスター候補

[server2]
hostname=host2

[server3]
hostname=host3
no_master=1 # このホストはマスターにしない
</code></pre>

<p>以下のように設定ファイルを指定して起動する。</p>

<pre><code class="text"># masterha_manager --conf=/etc/mha.cnf
</code></pre>

<p>設定パラメータ一覧はオフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Parameters">Parameters</a> を参照。</p>

<hr>

<h2>チュートリアル</h2>

<p>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Tutorial">Tutorial</a> を参照。</p>

<hr>

<h2>FAQ</h2>

<p><a href="http://code.google.com/p/mysql-master-ha/wiki/FAQ">FAQ</a> からいくつかピックアップ。超意訳。</p>

<ul>
<li>サポートされている MySQL のバージョンは？

<ul>
<li>5.0 以降がサポートされている。4.1 以下はサポート対象外。</li>
</ul></li>
<li>特定のスレーブホストをマスターに昇格したり、逆に特定のホストはマスターに昇格しない、といったことは可能か？

<ul>
<li><a href="http://code.google.com/p/mysql-master-ha/wiki/Parameters#candidate_master">cadidate_master</a> や <a href="http://code.google.com/p/mysql-master-ha/wiki/Parameters#no_master">no_master</a> といったパラメータで設定可能。</li>
</ul></li>
<li>インタラクティブ/手動でのフェイルオーバーは可能？

<ul>
<li><a href="http://code.google.com/p/mysql-master-ha/wiki/masterha_master_switch">masterha<em>master</em>switch</a> 使えばOK。</li>
</ul></li>
<li>MHA Manager 自体の冗長化は？

<ul>
<li>Pacemaker とか使っとけ。</li>
</ul></li>
</ul>

<hr>

<h2>よくあるエラーと対処方法</h2>

<p>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/TypicalErrors">TypicalErrors</a> を参照。</p>

<hr>

<h2>必要条件</h2>

<p>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Requirements">Requirements</a> からいくつかピックアップして超意訳。</p>

<p>MHA を動作させるためには、以下の設定が必要。<a href="http://code.google.com/p/mysql-master-ha/wiki/masterha_manager">masterha_manager</a> や <a href="http://code.google.com/p/mysql-master-ha/wiki/masterha_check_repl">masterha_check_repl</a> 実行時に自動的にチェックしてくれる。</p>

<ul>
<li>root で各ノード間での SSH 公開鍵認証ができること

<ul>
<li>masterha_check_ssh コマンドでチェックできる</li>
</ul></li>
<li>MySQL 5.0 以降のみサポート</li>
<li>マスター昇格候補のサーバで log-bin が enable になってること </li>
<li>マスター昇格候補サーバにレプリケーション用ユーザが存在すること</li>
<li>ステートメントベースのレプリケーションでは LOAD DATA INFILE を使用してはいけない</li>
</ul>

<hr>

<h2>その他</h2>

<ul>
<li>Semi-Synchronous Replication と組み合わせることで、マスターのハードウェア故障等によるデータロスのリスクを抑えることができる

<ul>
<li>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/UseCases#Using_together_with_Semi-Synchronous_Replication">Using together with Semi-Synchronous Replication</a> を参照</li>
<li>Semi-Synchronous Replication については <a href="http://nippondanji.blogspot.jp/2009/03/mysql-ha-semi-synchronous-replication.html">漢(オトコ)のコンピュータ道: 最強のMySQL HA化手法 - Semi-Synchronous Replication</a> が詳しい</li>
</ul></li>
</ul>

<hr>

<h2>参考 URL</h2>

<ul>
<li><a href="http://www.slideshare.net/matsunobu/mha-for-mysqldena">MHA for MySQL と DeNA のオープンソースの話</a></li>
<li><a href="http://code.google.com/p/mysql-master-ha/"> mysql-master-ha - MHA for MySQL: Master High Availability Manager and tools for MySQL - Google Project Hosting</a></li>
<li><a href="https://github.com/yoshinorim/mha4mysql-node">yoshinorim/mha4mysql-node on GitHub</a></li>
<li><a href="https://github.com/yoshinorim/mha4mysql-manager">yoshinorim/mha4mysql-manager on GitHub</a></li>
</ul>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[GitHub に coderwall バッヂの Organizations ができてる]]></title>
    <link href="http://mizzy.org/blog/2013/01/30/1/" />
    <updated>2013-01-30T01:04:31+09:00</updated>
    <id>http://mizzy.org/blog/2013/01/30/1/</id>
    <content type="html"><![CDATA[
<p><a href="http://github.com/">GitHub</a> の <a href="https://github.com/mizzy">自分のプロフィールページ</a> の Organizations のところに、<a href="http://coderwall.com/">coderwall</a> のバッヂが表示されてることに少し前に気づいていて、これは各バッヂに対応した組織アカウントのメンバーに自分が入れらてるから、なわけですが、デフォルトでは Publicize されてないので、他の人からは見ることができません。Publicize してあげると、他の人からもこんな風に見えるようになります。</p>

<p><img src="/images/2013/01/coderwall-organizations.png"></p>

<p>Publicize するには、各組織アカウントのページで「Members」タブを選択し、自分のアカウントの横の「Publicize membership」をクリックすれば良いです。</p>

<p><img src="/images/2013/01/publicize.png"></p>

<p>上の画像は、Publicize した後のものです。</p>

<p>Publicize は手動でやるのはだるいので、スクリプトをつくってみました。</p>

<div><script src='https://gist.github.com/4665462.js?file='></script>
<noscript><pre><code>#!/usr/bin/env ruby

require 'pit'
require 'octokit'

user = 'mizzy'

def octokit
  config = Pit.get('github', :require =&gt; {
                     'username' =&gt; 'Your user name of GitHub',
                     'password' =&gt; 'Your password of GitHub',
                   })
  Octokit::Client.new(:login =&gt; config['username'], :password =&gt; config['password'])
end

octokit.orgs.each do |org|
  org = org.login
  next unless org.match(/^coderwall/)
  unless octokit.organization_public_member?(org, user)
    puts &quot;Publicize membership of user #{user} in #{org} ..&quot;
    octokit.publicize_membership(org, user)
  end
end
</code></pre></noscript></div>

<p>余談ですが、<a href="https://github.com/pengwynn/octokit">octokit</a> で Publicize Membership するコードは、<a href="https://github.com/pengwynn/octokit/pull/89">自分がコントリビュートしたものです</a> 。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[How to manage RPM packages with Git]]></title>
    <link href="http://mizzy.org/blog/2013/01/19/1/" />
    <updated>2013-01-19T17:52:35+09:00</updated>
    <id>http://mizzy.org/blog/2013/01/19/1/</id>
    <content type="html"><![CDATA[
<p>Now I manage RPM packages like <a href="https://github.com/paperboy-sqale/sqale-yum">this repo</a>. I put source and binary packages in this repo.But this way has these problems.</p>

<ul>
<li>Binary packages&#39; size is too big.It takes long time to git clone, push, pull and so on.</li>
<li>I cannot see the history of each file in the packages.

<ul>
<li>It&#39;s not very meaningful to use Git.</li>
</ul></li>
</ul>

<p>I&#39;d like to change like this.</p>

<ul>
<li>Put the requisite minumum files to see the hisotory of each file.

<ul>
<li>Not put binary packages.(Source packages are OK if needed.)</li>
</ul></li>
<li>Build packages with files managed with Git.</li>
</ul>

<p>And I made the prototype of this idea like this.</p>

<p><a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git">mizzy/how-to-manage-rpm-packages-with-git</a></p>

<p>The file/directory strucure in this repo is like this.</p>

<pre><code>|-- build.rb
|-- ffmpeg
|   |-- ffmpeg-github-0.8.2.spec
|   |-- libavformat-muxer.paperboy.patch
|   |-- libx264-superfast_firstpass.ffpreset
|   `-- libx264-veryfast_firstpass.ffpreset
|-- memcached
|   |-- memcached-1.4.15-1.el6.src.rpm
|   `-- memcached.spec
`-- ngx_openresty
    `-- ngx_openresty.spec
</code></pre>

<p>Build rb is the package build script, and others are directories for each package.Which files should be managed is vary from package to package, so I arrange several patterns.</p>

<hr>

<h2>Pattern 1: ngx_openresty</h2>

<p>With <a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/tree/master/ngx_openresty">this pattern</a>, all I have to manage is spec file.In this spec file,</p>

<pre><code>Source0: http://agentzh.org/misc/nginx/ngx_openresty-%{version}.tar.gz
</code></pre>

<p>You can see this line.Build.rb gets this file, pust under ~/rpmbuild/SOURCES and build source and binary packages.This is the simplest pattern.</p>

<hr>

<h2>Pattern2: ffpmeg</h2>

<p><a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/tree/master/ffmpeg">This pattern</a> has a spec file, patch files and other files.If you need original patches and manage patch files with Git, this pattern is suitable.</p>

<pre><code>Source: http://www.ffmpeg.org/releases/ffmpeg-%{version}.tar.bz2
</code></pre>

<p>Build.rb get this source file in spec, put this source, patches and other files under ~/rpmbuild/SOURCE and build source and binary packages.</p>

<hr>

<h2>Pattern 3: memcached</h2>

<p>With <a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/tree/master/memcached">this pattern</a>, You&#39;d like to change the build options of the existence source package, but the sources in spec file is like this.</p>

<pre><code>Source0:        http://memcached.googlecode.com/files/%{name}-%{version}.tar.gz
Source1:        memcached.sysv
</code></pre>

<p>So you can&#39;t get the memcached.sysv through the network.But this file is included in the existence source package and you don&#39;t need to manage it with Git.</p>

<p>In this case, it&#39;s easy to put the existence source package under the Gir repo.</p>

<hr>

<p>With any of these patterns, you can see the history of each file, total file size in the repo is minimum and all files needed to build package are found in the repo.</p>

<hr>

<h2>Package Building and Deploying</h2>

<p>My final goal is, git clone these files, build packages with the script <a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/blob/master/build.rb">like this</a> and deploy the packages to yum servers automatically.</p>

<hr>

<h2>Other featuer</h2>

<p>Also I&#39;d like to write git url as source in the spec file like this.</p>

<pre><code>Source: git://github.com/torvalds/linux.git, ref: dfdeb
</code></pre>

<p>Build script will clone source files from this git url, build tar ball from these and build package.This idea is inspired by <a href="http://gembundler.com/">Bundler</a>.</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[RPM パッケージを Git で管理する方法（案）]]></title>
    <link href="http://mizzy.org/blog/2013/01/17/1/" />
    <updated>2013-01-17T18:05:44+09:00</updated>
    <id>http://mizzy.org/blog/2013/01/17/1/</id>
    <content type="html"><![CDATA[
<p><a href="https://twitter.com/trombik">@trombik</a> さんの</p>

<blockquote class="twitter-tweet"><p>弊社ではtinderbox+gitですべて統一させてる</p>&mdash; trombik (@trombik) <a href="https://twitter.com/trombik/status/284200636021608449" data-datetime="2012-12-27T07:34:46+00:00">December 27, 2012</a></blockquote>

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>という tweet を見て気になったので調べてみたところ、 <a href="http://tinderbox.marcuscom.com/">Tinderbox</a> はどうやら FreeBSD の ports を自動ビルドするためのシステムのようで、RPM でもこんなのないのかなー、と探してみたものの見つけられなかったし、Tinderbox が自分が求めてるものなのかどうかもいまいちピンと来なかったので、プロトタイプ的なものをつくってみることに。</p>

<p>現在 RPM パッケージの管理は、<a href="https://github.com/paperboy-sqale/sqale-yum">こんな感じで</a> ソース/バイナリパッケージを直接リポジトリに突っ込んじゃってるんだけど、これだと以下のような問題がある。</p>

<ul>
<li>バイナリパッケージのファイルサイズが大きすぎて、git clone や push や pull に時間がかかる</li>
<li>パッケージ丸ごと突っ込んでるので、ファイル個別の差分が確認できない

<ul>
<li>そもそも差分確認できないものを突っ込むのは git を使う意義がだいぶ削がれる</li>
</ul></li>
</ul>

<p>それをこんな風にしたい。</p>

<ul>
<li>必要最小限のファイルだけを git リポジトリに突っ込んでファイル個別に差分確認できるように</li>
<li>パッケージは突っ込まず、git で管理してるファイルからパッケージビルドする

<ul>
<li>ただしソースパッケージは必要なら突っ込んでもOK</li>
</ul></li>
</ul>

<p>で、プロトタイプ的なものをつくってみたのがこれ。</p>

<p><a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git">mizzy/how-to-manage-rpm-packages-with-git</a></p>

<p>このリポジトリの構成はこんな感じ。</p>

<pre><code>|-- build.rb
|-- ffmpeg
|   |-- ffmpeg-github-0.8.2.spec
|   |-- libavformat-muxer.paperboy.patch
|   |-- libx264-superfast_firstpass.ffpreset
|   `-- libx264-veryfast_firstpass.ffpreset
|-- memcached
|   |-- memcached-1.4.15-1.el6.src.rpm
|   `-- memcached.spec
`-- ngx_openresty
    `-- ngx_openresty.spec
</code></pre>

<p>build.rb がビルド用のスクリプトで、それ以外に各パッケージ用のディレクトリがある。で、どのファイルをバージョン管理するかは、パッケージによって異なるだろうな、ってことで、あり得そうなパターンをいくつか用意してみた。</p>

<hr>

<h2>パターン1: ngx_openresty</h2>

<p><a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/tree/master/ngx_openresty">これ</a> は spec ファイルだけを管理するパターン。spec の中に</p>

<pre><code>Source0: http://agentzh.org/misc/nginx/ngx_openresty-%{version}.tar.gz
</code></pre>

<p>という記述があるので、こいつをダウンロードして ~/rpmbuild/SOURCES に置き、ソースパッケージとバイナリパッケージをビルド、という一番シンプルなパターン。</p>

<p>configure オプションぐらいをカスタマイズできればOK、という場合はこのパターンになるはず。</p>

<hr>

<h2>パターン2: ffpmeg</h2>

<p><a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/tree/master/ffmpeg">これ</a> は spec ファイル＋パッチ（＋α）な構成。独自にパッチをあてて、パッチもバージョン管理したい、といったパターン。これも spec ファイルに</p>

<pre><code>Source: http://www.ffmpeg.org/releases/ffmpeg-%{version}.tar.bz2
</code></pre>

<p>という記述があるので、こいつをダウンロードし、他のパッチファイル等とともに ~/rpmbuild/SOURCES に置いて、ソースパッケージとバイナリパッケージをビルドする。</p>

<hr>

<h2>パターン3: memcached</h2>

<p><a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/tree/master/memcached">こいつ</a> は既存のソースパッケージのビルドオプションだけを変えたいんだけど、spec ファイル中のソースが</p>

<pre><code>Source0:        http://memcached.googlecode.com/files/%{name}-%{version}.tar.gz
Source1:        memcached.sysv
</code></pre>

<p>となっていて、memcached.sysv をネットワーク越しに取得できない、かといって、このファイルは既存ソースパッケージに入ってるものをそのまま使うので、特にバージョン管理の必要はない、といったケース。</p>

<p>このケースであれば、既存ソースパッケージ内のファイルは、spec 以外は修正することはないからバージョン管理の必要はないし、バイナリパッケージと比べればサイズは小さいから、そのまま突っ込んじゃう方が楽だろう、ということで、src.rpm ファイルをリポジトリにそのまま突っ込んでる。（別に memcached.sysv だけ取り出して置いといてもいいんだけど、memcached.sysv 以外にも付随するソースやパッチがもっとたくさんある場合は、この方が楽だろう、という判断。）</p>

<hr>

<p>今のところこれぐらいのパターンを網羅できれば大丈夫かなー、と。いずれのパターンでも、ファイル個別に差分の確認ができるし、管理すべきファイルのサイズも最小限に抑えられているし、ビルドに必要なファイルは一通り揃っている。</p>

<hr>

<h2>パッケージのビルド</h2>

<p>で、これらのファイルを git clone してきて、<a href="https://github.com/mizzy/how-to-manage-rpm-packages-with-git/blob/master/build.rb">build.rb</a> みたいなスクリプトでビルド＆yum サーバへのデプロイ、ってなことができればいいなー、というのが最終的な目論見。</p>

<hr>

<h2>その他</h2>

<p>とりあえず自分のアイデアを形にしてみて、意見をもらったりとか、それ○○でできるよ、みたいな反応がもらえるといいな、というのがこのブログエントリを書いた目的。</p>

<p>あと、こんなのできればいいなー、と思っているのは、Ruby の Bundler みたいに、</p>

<pre><code>Source: git://github.com/torvalds/linux.git, ref: dfdeb
</code></pre>

<p>とか spec に書いておくと、git clone して tar ball 作成して、そいつを使ってパッケージビルドできたりするといいなー、とか。</p>

<p>また、@trombik さんと twitter でやりとりしてる中で、<a href="https://fedorahosted.org/koji/wiki">koji</a> という RPM ビルドシステムを見つけたんだけど、これも使えないか調べてみる。（が、自分がやりたいこととはちょっと違う感じ。）</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[サーバエンジニアが「開発力」を持つ意味]]></title>
    <link href="http://mizzy.org/blog/2013/01/10/1/" />
    <updated>2013-01-10T22:39:30+09:00</updated>
    <id>http://mizzy.org/blog/2013/01/10/1/</id>
    <content type="html"><![CDATA[
<p>初出: <a href="http://gihyo.jp/magazine/SD/archive/2009/200904">Software Design 2009年4月号</a>（2009年3月18日発売）
宮下 剛輔</p>

<h2>サーバエンジニアの定義</h2>

<p>本特集では、サーバエンジニアが開発力を持つことにより、どのような力を得ることができるのか、日々の業務にどのように役立てることができるのか、具体例とともに紹介します。</p>

<p>本題に入る前にまずはここでのサーバエンジニアの定義を明確にし、特集全体のコンセプトについて説明します。</p>

<p>クライアント/サーバ型のシステムを考える場合、サーバ側は大まかに以下のようなレイヤーに区分できます。</p>

<ul>
<li>アプリケーションレイヤー</li>
<li>ミドルウェアレイヤー</li>
<li>OSレイヤー</li>
<li>ネットワークレイヤー</li>
</ul>

<p>これらのレイヤーのうち、ミドルウェアレイヤーとOSレイヤーを主担当とするエンジニアを、本特集記事でのサーバエンジニアと定義し、対象読者と想定します。その中でも特に、オープンソースソフトウェア（OSS）をメインで扱うエンジニアを対象としています。</p>

<p>この定義で言うと、サーバエンジニアはシステムを構成する要素のちょうど中間地点に位置するため、直接の担当であるミドルウェア/OSレイヤーに専念するだけではなく、上層のアプリケーションレイヤーや下層のネットワークレイヤーを、ミドルウェア/OSレイヤーとつなぐ役割も負っていると言えます。</p>

<h2>開発力とは</h2>

<p>一口に開発力と言っても、様々な言葉で表現できると思いますが、ここでは「開発力がある」というのを、非常に大雑把ではありますが、以下のように定義したいと思います。</p>

<ul>
<li>プログラムコードが書ける</li>
<li>プログラムコードが読める</li>
</ul>

<p>それぞれについて、もう少し具体的に見てみましょう。</p>

<h3>プログラムコードが書ける</h3>

<p>開発とは大雑把に言ってしまえば、コードを書くことである、と言えるかと思います。</p>

<p>ここで言う「コードが書ける」という状態は、大きなまとまったプログラムをいちから開発するだけではなく、簡単なシェルスクリプトやPerlのワンライナーを書いたり、既存プログラムを修正したり拡張することも含めます。つまり、何らかの目的を達成するためのコードが書ける能力を、開発力を構成する一要素と考えます。</p>

<p>本特集では主にこの部分にフォーカスを当てます。</p>

<h3>プログラムコードが読める</h3>

<p>コードが書けるだけではなく、読めることも開発力を構成する重要な要素だと考えられます。特に既存のプログラムを修正したり拡張する場合には、まずは既存のコードを読んで理解する必要があります。また、より良いコードを書くためには、他の人が書いた良いコードを読んで学ぶことも重要です。そこで、コードを読んで理解できる能力も、開発力を構成する要素に含めたいと思います。</p>

<p>後ほど、コードが読めることによって、サーバエンジニアにどのようなメリットがあるのかについて簡単に触れますが、いかにコードを読んで理解するか、といったコードリーディングの技術については、本特集の対象外とします。</p>

<h2>より高い開発力を持つためには</h2>

<p>「コードが書ける」「コードが読める」の2つを満たしていれば、開発力があると言ってよいとは思いますが、より高い開発力を持つためには、単にコードが読み書きできるのに加えて、様々な周辺知識が必要となってきます。いくつか例を挙げてみると、</p>

<ul>
<li>読みやすくメンテナンスしやすいコードを書くための知識</li>
<li>標準/非標準モジュールやライブラリに関する知識</li>
<li>バージョン管理ツールの利用</li>
<li>アーキテクチャパターンの理解</li>
</ul>

<p>といったものがあり、これら以外にもまだまだたくさんありますが、本特集で扱うにはテーマとして大きすぎますので、この章ではこれらのスキルがあると、サーバエンジニアにとってどのようなメリットがあるのか、簡単に触れるに留めておき、詳細は本特集の対象外とします。</p>

<h2>サーバエンジニアが開発力を持つ意味</h2>

<p>では、先ほど挙げたような開発力を構成する要素「コードが書ける」「コードが読める」「より高い開発力」をサーバエンジニアが持つことには、具体的にどのような意味があるのでしょうか？</p>

<h3>プログラムコードが書ける意味</h3>

<p>コードが書けることによるサーバエンジニアのメリットしてまず思い浮かぶのは、サーバ構築、設定変更、運用監視、インベントリ情報の収集、などといった日々のタスクの自動化が挙げられると思います。コードを書いてこれらのタスクを自動化することによって、以下のようなメリットが得られます。</p>

<ul>
<li>つまらないルーチンワークからの開放</li>
<li>手動の手順書が不要になるので、手順書の更新忘れがなくなる</li>
<li>手順書にもとづく手動作業にありがちな、作業漏れや作業間違いがなくなる</li>
</ul>

<p>特に対象となるサーバの台数が多ければ多いほど、コードを書くことによる自動化で受ける恩恵は大きなものとなります。</p>

<p>上記のようなタスクの自動化を行ってくれる既存のツールも存在しますが、既存のものだと機能が多すぎて複雑で使いにくかったり、その割にはかゆいところに手が届かなかったりすることもあるのではないしょうか。そんな場合でも、自分でコードが書ければ、必要な機能だけを実装できて、シンプルで使い勝手の良いものが作れますし、かゆいところにも手が届きます。</p>

<p>また、既存ツールでもプラグイン等で拡張できるものも多く存在しますが、コードが書ければやりたいことにマッチしたプラグインを書くこともでき、自分の手になじむようにカスタマイズすることができます。</p>

<h3>プログラムコードが読める意味</h3>

<p>OSSを日頃利用しているサーバエンジニアにとって、コードを読んで理解できることは大きな武器になります。</p>

<p>メリットのひとつとしては、普段利用しているOSSの内部動作に関する、深くて正確な理解を得ることができる、というものがあります。例えば、サーバの負荷状況を取得するためのツールであるtop、vmstat、iostatなどが示す数値が何を示すか、何となく理解していても、OSカーネルレベルでは具体的に何を示しているのか、ということは、ソースコードを読んで理解することによってはじめて正確な理解が得られます。システムの負荷対策を行うにあたっては、そもそも負荷とは何か、ということに関する正確な理解が必須であると筆者は考えます。</p>

<p>また、OSSを利用していて想定外の動作やバグに遭遇した場合に、コードが読めれば問題の箇所をつきとめることができ、更にコードを書くことができれば、自身で修正することもできます。</p>

<p>OSSなソフトウェアやライブラリには、とても便利なんだけどドキュメントが不足していて、使い方がよくわからない、想定どおりに動かないといったものも存在します。そういった場合でも、ソースコードを追うことができれば、利用方法を理解することができます。（もちろん、そこまでして利用する価値があるかどうか、という判断は必要になりますが、ドキュメント不足だからといってすぐ利用をあきらめるのはもったいないほど便利なソフトウェア、というものも世の中に存在します。）</p>

<p>他の人が書いた良いコードを読んで理解することも、開発力向上にとても役立ちます。</p>

<h3>より高い開発力を持つ意味</h3>

<p>単純にコードが読み書きできるだけではなく、更に高い開発力を持つことにより、どのようなメリットがあるのかを考えてみます。</p>

<p>読みやすくメンテナンスしやすいコードを書くための知識は非常に重要です。読みにくいコードは書いた本人すら理解できなくなることもあり、そのようなコードは具体的に何を目的として何を実行しているのかが不明瞭になるため、正常に動いている間はいいですが、何か問題が発生した場合や、修正が必要になった際に、容易にコードを変更することができなくなります。</p>

<p>メンテナンスしやすいコードを書くための知識としては、例えばオブジェクト指向があります。オブジェクト指向がもたらす変数や関数の局所化は、メンテナンスしやすいコードを書くのに大いに役立ちます。また、コードのテストに関する知識も、メンテナンスしやすいコードを書くためにはとても重要です。</p>

<p>各言語の標準/非標準モジュールや便利なライブラリを多く知っていると、目的を達成するためのコードを非常に簡単に書けるようになり、本来の目的の処理を書くことのみに注力できるとともに、コードも簡単になるため、メンテナンスしやすく、バグの出にくいコードを書くことができます。</p>

<p>Subversion等のバージョン管理ツールは開発者のためのツールと思われがちですが、サーバエンジニアが作成するコードの管理にもとても役立ちますし、コードの管理だけではなく、設定ファイル等の管理にも大いに役立ちます。</p>

<p>アーキテクチャパターンは先人達の知恵の集合ですので、多くのパターンを知ることにより、先人達が悩み乗り越えてきた道をショートカットできるようになります。例えば、MVCパターンは耳にしたことのある方も多いと思いますが、これは一般ユーザをターゲットとしたUIを持つアプリケーションだけではなく、アプリケーションレイヤーと接続するAPIを持ったシステム管理用プログラムの開発にも大いに役立ちます。</p>

<h2>まとめ</h2>

<p>この章では、本特集がターゲットとするサーバエンジニアについての定義を行い、サーバエンジニアが開発力を持つことにより、どのようなことができるようになるのかを、簡単にですが紹介しました。</p>

<p>次章以降では開発力のうちの「コードを書く」をテーマとして、更に具体的に、サーバエンジニアが開発力を持つとどのようなことができるようになるのか、紹介したいと思います。</p>

<hr>

<p>これは、Software Design 2009年4月号に寄稿した特集記事『～サーバエンジニアがプログラムを知る意味～ システム運用/管理に役立つ「開発力」 ～楽天,mixi,paperboy&amp;co.の事例紹介!～』において、自分が執筆を担当した第1章の内容を、技術評論社様の許可を得て、全文を転載しています。</p>

<p>現在では「サーバエンジニア」ではなく「インフラエンジニア」の方がおそらく一般的な呼び方でしょうね。（それも変わりつつあるようですが。）</p>

<p>なおこの記事は <a href="http://gihyo.jp/book/2011/978-4-7741-4600-3">サーバ/インフラエンジニア養成読本</a> にも掲載されています。</p>

]]></content>
  </entry>


</feed>
