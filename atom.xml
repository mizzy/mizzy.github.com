<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Gosuke Miyashita]]></title>
  <link href="http://mizzy.org/atom.xml" rel="self"/>
  <link href="http://mizzy.org/"/>
  <updated>2013-03-24T17:35:20+09:00</updated>
  <id>http://mizzy.org/</id>
  <author>
    <name><![CDATA[Gosuke Miyashita]]></name>
    
  </author>
  <generator uri="https://github.com/mizzy/stellar/">Stellar</generator>


  <entry>
    <title type="html"><![CDATA[構築済みサーバを RSpec でテストする serverspec という gem をつくった]]></title>
    <link href="http://mizzy.org/blog/2013/03/24/3/" />
    <updated>2013-03-24T17:35:20+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/24/3/</id>
    <content type="html"><![CDATA[
<p><a href="/blog/2013/03/23/1/">Puppet や Chef で構築したサーバを RSpec でテストする</a> で書いた仕組みを使いやすくするために <a href="https://github.com/mizzy/serverspec">serverspec</a> という名前で gem 化してみた。</p>

<p>rubygems.org にも登録してあるので、gem install でインストールできる。</p>

<pre><code>$ gem install serverspec
</code></pre>

<p>インストールしたら、適当なディレクトリで serverspec-init を実行。すると、雛形となるディレクトリやファイルを生成する。</p>

<pre><code>$ serverspec-init
 + spec/
 + spec/www.example.jp/
 + spec/www.example.jp/httpd_spec.rb
 + spec/spec_helper.rb
 + Rakefile
</code></pre>

<p>spec/<a href="http://www.example.jp/httpd_spec.rb">www.example.jp/httpd_spec.rb</a> がサンプルテストコードで、こんな感じになってる。</p>

<pre><code>require &#39;spec_helper&#39;

describe &#39;httpd&#39; do
  it { should be_installed }
  it { should be_enabled   }
  it { should be_running   }
end

describe &#39;port 80&#39; do
  it { should be_listening }
end

describe &#39;/etc/httpd/conf/httpd.conf&#39; do
  it { should be_file }
  it { should contain &quot;ServerName www.example.jp&quot; }
end
</code></pre>

<p>これに倣って spec/target.example.jp/xxxxx_spec.rb というファイルをつくって、テストを書いていく。</p>

<p>テスト対象のホストには SSH でアクセスするので、パスワード入力しなくて良いように、~/.ssh/config を書いたり、ssh-agent を利用したりすると良いでしょう。</p>

<pre><code>Host *.example.jp
   User root
   IdentityFile ~/.ssh/for_serverspec_rsa
</code></pre>

<p>rake spec でテストを実行。</p>

<pre><code>$ rake spec
/usr/bin/ruby -S rspec spec/www.example.jp/httpd_spec.rb
......

Finished in 0.99715 seconds
6 examples, 0 failures
</code></pre>

<p>Red Hat 系 Linux 前提のつくりになってしまっているので、他のディストリビューションや OS で利用したい、という方は、ぜひプルリクエストください。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Testing servers provisioned by Puppet or Chef with RSpec]]></title>
    <link href="http://mizzy.org/blog/2013/03/24/2/" />
    <updated>2013-03-24T02:29:42+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/24/2/</id>
    <content type="html"><![CDATA[
<p><a href="/blog/2013/03/24/1/">I&#39;ve made a Puppet module for creating LXC system containers</a>.Next I&#39;ve tried to the basis for writing test code easily.</p>

<p>With <a href="https://github.com/mizzy/rspec-lxc-test-box">rspec-lxc-test-box</a>, you can write code for testing server status like this.</p>

<pre><code class="ruby">require &#39;container_spec_helper&#39;

describe &#39;nrpe&#39; do
  it { should be_installed }
  it { should be_enabled   }
  it { should be_running   }
end

describe &#39;nagios-plugins-all&#39; do
  it { should be_installed }
end

describe &#39;/etc/nagios/nrpe.cfg&#39; do
  it { should be_file }
  it { should contain &#39;server_port=5666&#39; }
end

describe &#39;/etc/nrpe.d/01base.cfg&#39; do
  it { should be_file }
end

describe &#39;port 5666&#39; do
  it { should be_listening }
end
</code></pre>

<p>This code accesses to a container through SSH and execute commands to check whether files exist, packages are installed, files contain some strings, services run, some ports listen and so on.Very simple.(But code base are specific for Red Hat and its clone OS.)</p>

<p>You can see how I make it simply <a href="https://github.com/mizzy/rspec-lxc-test-box/tree/master/spec/support/matchers">with these codes</a>.</p>

<p>This test code works with any servers provisioned by any tools(Puppet, Chef, CFEngine, Shell Script, Hands and so on).</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Create LXC system containers easily with Puppet]]></title>
    <link href="http://mizzy.org/blog/2013/03/24/1/" />
    <updated>2013-03-24T01:47:23+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/24/1/</id>
    <content type="html"><![CDATA[
<h2>Overview</h2>

<p>I&#39;m refactoring <a href="https://puppetlabs.com/">Puppet</a> manifests and refactoring requires automated testing.</p>

<p><a href="http://rspec-puppet.com/">rspec-puppet</a> and <a href="http://projects.puppetlabs.com/projects/cucumber-puppet/wiki">cucumber-puppet</a> test Puppet catalog, but I need to test actual server status that Puppet manifests applied to.</p>

<p>For actual testing, several virtual machines are needed. <a href="http://www.vagrantup.com/">Vagrant</a> is the one for creating virtual machines for testing easily.</p>

<p>But I&#39;m using <a href="http://www.linux-kvm.org/page/Main_Page">KVM</a> mainly and would like to create virtual machines for testing on a KVM based virtual machine.</p>

<p><a href="http://lxc.sourceforge.net/">LXC</a> suits that purpose.</p>

<p>For testing purpose, how to create LXC system containers easily is important. So I&#39;ve created a Puppet module to create LXC system containers easily.</p>

<p><a href="https://github.com/mizzy/puppet-lxc-test-box">mizzy/puppet-lxc-test-box</a></p>

<hr>

<h2>How To Use</h2>

<p>First, git clone puppet-lxc-test-box module and puppet-sysctl module.</p>

<pre><code>$ git clone git://github.com/mizzy/puppet-lxc-test-box.git lxc-test-box
$ git clone git://github.com/duritong/puppet-sysctl.git sysctl
</code></pre>

<p>Next, write a manifest to create system containers.</p>

<pre><code>include lxc-test-box

Exec { path =&gt; &#39;/sbin:/usr/sbin:/bin:/usr/bin&#39; }

lxc-test-box::lxc::setup { &#39;proxy&#39;: ipaddress =&gt; &#39;172.16.0.2&#39; }
lxc-tets-box::lxc::setup { &#39;www&#39;:   ipaddress =&gt; &#39;172.16.0.3&#39; }
lxc-test-box::lxc::setup { &#39;db&#39;:    ipaddress =&gt; &#39;172.16.0.4&#39; }
</code></pre>

<p>Apply this manifest.</p>

<pre><code>$ sudo puppet apply --modulepath=. lxc-test-box.pp
</code></pre>

<p>3 containers will be created.</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[Puppet や Chef で構築したサーバを RSpec でテストする]]></title>
    <link href="http://mizzy.org/blog/2013/03/23/1/" />
    <updated>2013-03-23T22:34:15+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/23/1/</id>
    <content type="html"><![CDATA[
<p>Puppet マニフェストをリファクタリングするからテスト書くぞ、ってことで、 <a href="/blog/2013/03/22/1/">puppet-lxc-test-box</a> に書いたように、テストするためのシステムコンテナを簡単に作る仕組みをつくったので、今度は実際にテストコードを書くためのベースをつくってみた。</p>

<p><a href="https://github.com/mizzy/rspec-lxc-test-box">rspec-lxc-test-box</a></p>

<p>こんな感じでテストが書ける。</p>

<pre><code class="ruby">require &#39;container_spec_helper&#39;

describe &#39;nrpe&#39; do
  it { should be_installed }
  it { should be_enabled   }
  it { should be_running   }
end

describe &#39;nagios-plugins-all&#39; do
  it { should be_installed }
end

describe &#39;/etc/nagios/nrpe.cfg&#39; do
  it { should be_file }
  it { should contain &#39;server_port=5666&#39; }
end

describe &#39;/etc/nrpe.d/01base.cfg&#39; do
  it { should be_file }
end

describe &#39;port 5666&#39; do
  it { should be_listening }
end
</code></pre>

<p>やってることはすごく単純で、システムコンテナに対して SSH でアクセスしてコマンドを叩いて、パッケージがインストールされているか、とか、ファイルが存在するか、とか、ファイルに特定の文字列が含まれてるか、とか、サービスが動いているか、とか、特定のポートで Listen してるか、とかを確認してる。（ただし、Red Hat 系 OS を対象としてるので、他の OS ではそのままでは動かない部分もある。）</p>

<p>具体的にどんなことをやってるかは、<a href="https://github.com/mizzy/rspec-lxc-test-box/tree/master/spec/support/matchers">この辺</a> を見てもらえば、すごく単純だということがわかると思う。</p>

<p>実際にコンテナに SSH でアクセスしてテストするので、別に LXC じゃなくても、KVM でも VirtualBox でも VMWare でも物理マシンでも OK だし、Puppet だろうが Chef だろうが CFEngine だろうがシェルスクリプトだろうが手動での構築だろうが、どんな構築手段でも利用できる。</p>

<p><a href="https://github.com/opscode/test-kitchen">Test Kitchen</a> で同じようなことできるんだから、おとなしく Puppet と LXC じゃなくて Chef と Vagrant 使えばいいじゃん、って思われるかもしれないけど、Test Kitchen はなんか大げさすぎて肌に合わない。見通しがいい小さなツールを組み合わせるのが好きなので、<a href="/blog/2013/03/22/1/">puppet-lxc-test-box</a> とかこれとか作ってる。</p>

<p>これと同じようなことは、実は <a href="https://twitter.com/hiboma">@hiboma</a> が既に Sqale で Chef と組み合わせてやっていて、色々参考にさせてもらった。Chef Casual Talk とかがあれば、たぶんこの辺の話をしてくれるんじゃないかな。</p>

<p>こういったテスト駆動サーバ構築的なアプローチは、実は <a href="http://shibuya.pm.org/blosxom/techtalks/200702.html">デブサミ2007出張Shibuyaイベント</a> や <a href="http://tokyo2007.yapcasia.org/sessions/2007/02/assurer_a_pluggable_server_tes.html">YAPC::Asia 2007 Tokyo</a> で発表した <a href="http://www.slideshare.net/mizzy/assurer-a-pluggable-server-testingmonitoring-framework">Assurer というツール</a> でやろうとしてた。</p>

<p>ただ Assurer は、最初から汎用的にしようと意識しすぎて、プラガブルにしたり、複数の OS にも対応できる仕組みを入れたり、といった感じで、構想がでかすぎて自分の手に負えないものになってしまって、使わなくなってしまった。（余談。ツールとしては失敗だったけど、これきっかけで <a href="https://twitter.com/lamanotrama">@lamanotrama</a> とメールのやりとりがあって、その後ペパボに入社してくれたので、ある意味成功だったと言える。）</p>

<p>これで Puppet マニフェストをリファクタリングするためのベースとなる仕組みはできたので、次は実際にガリガリとテストコードを書いていく予定。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[puppet-lxc-test-box]]></title>
    <link href="http://mizzy.org/blog/2013/03/22/1/" />
    <updated>2013-03-22T02:19:00+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/22/1/</id>
    <content type="html"><![CDATA[
<p>新たな Puppet のベストプラクティスを求めて、マニフェストの大規模なリファクタリングを行っています。</p>

<p>で、リファクタリングするからにはテストが必要だよね、ってことで、<a href="http://rspec-puppet.com/">rspec-puppet</a> でテストを書いてるんだけど、rspec-puppet はマニフェストがコンパイルされた「カタログ」というものに対してテストするもので、実際にマニフェストを流し込んだ状態が正しいかテストするわけではないので、これだとテストとしては不完全。</p>

<p>というわけで、<a href="https://github.com/opscode/test-kitchen">Test Kitchen</a> みたいに、同時にいくつも VM を立ててテストを走らせる、ってなことをやりたいんだけど、会社では KVM ベースの VM を利用してるので、VirtualBox ベースの Vagrant は使えないし、そもそもテストを動かす大元のホストも VM なので、VirtualBox どころか KVM も利用できない。</p>

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>なので、まずは LXC のシステムコンテナをさくさくと作るための Puppet モジュールを書いてみた。</p>

<p><a href="https://github.com/mizzy/puppet-lxc-test-box">puppet-lxc-test-box</a></p>

<p>( <a href="https://github.com/fgrehm/vagrant-lxc">vagrant-lxc</a> というのもあるけど、&quot;Vagrant &gt;= 1.1.0, the lxc package and a Kernel higher than 3.5.0-17.28, which on Ubuntu 12.10 means something like&quot; ってなことが書かれていて、メインで使ってる RedHat 系 OS では動く気がしないのでスルー。)</p>

<p>使い方は次のような感じ。まず lxc-test-box モジュールと sysctl モジュールを持ってくる。</p>

<pre><code>$ git clone git://github.com/mizzy/puppet-lxc-test-box.git lxc-test-box
$ git clone git://github.com/duritong/puppet-sysctl.git sysctl
</code></pre>

<p>以下のように、Exec リソースのデフォルト値と、システムコンテナのホスト名と IP アドレスを書いたマニフェスト lxc-test-box.pp を作成。</p>

<pre><code>include lxc-test-box

Exec { path =&gt; &#39;/sbin:/usr/sbin:/bin:/usr/bin&#39; }

lxc-test-box::lxc::setup { &#39;base&#39;:   ipaddress =&gt; &#39;172.16.0.2&#39; }
lxc-tets-box::lxc::setup { &#39;manage&#39;: ipaddress =&gt; &#39;172.16.0.3&#39; }
lxc-test-box::lxc::setup { &#39;smtp&#39;:   ipaddress =&gt; &#39;172.16.0.4&#39; }
</code></pre>

<p>マニフェストを流し込む。</p>

<pre><code>$ sudo puppet apply --modulepath=. lxc-test-box.pp
</code></pre>

<p>これで、ホスト OS への lxc パッケージのインストール、ブリッジインターフェース br0 の作成、IP マスカレードの設定を行い、指定されたホスト名と IP アドレスでシステムコンテナを作成し、コンテナの起動までしてくれる。所要時間は、コンテナひとつあたり5分ぐらい。</p>

<p>起動したら、</p>

<pre><code>$ ssh root@base.lxc-test-box
</code></pre>

<p>で、ログインできる。ログイン用の鍵は Puppet で設定済み。（ただし、鍵は /root/.ssh 以下に置いてあるので、必要ならそこからコピーを。）テスト目的なのでホストOSとは通信できるけど、外部からは通信できない。ただし、ホスト OS で IP マスカレードの設定はしてあるので、コンテナから外部への通信は可能。</p>

<p>同梱している lxc パッケージは Scientifix Linux 6.2 + Kernel 2.6.32-358.2.1.el6.x86_64 上でビルドしたものなので、RedHat 6 系以外ではたぶん動かないし、カーネルバージョンが違うと動かないかもしれない。</p>

<p>これでテスト用のシステムコンテナを量産できるようになったので、次は実際にテストする仕組みを作り込む。</p>

<hr>

<p>KVM な VM の上で KVM な VM は動かせない、と思っていたら、<a href="https://twitter.com/ursm">@usrm</a> さんから、最近のカーネルであればネストできるはず、という情報をいただきました。</p>

<blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/gosukenator">gosukenator</a> 最近のカーネルであれば KVM のネストはできるはずです <a href="http://t.co/HZf5HhhUYs" title="http://networkstatic.net/nested-kvm-hypervisor-support/">networkstatic.net/nested-kvm-hyp…</a></p>&mdash; Keita Urashima (@ursm) <a href="https://twitter.com/ursm/status/314802865313042432">March 21, 2013</a></blockquote>

<p>とても有益な情報ありがとうございます！今度試してみよう。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[最小手順の Vagrant base box の作り方]]></title>
    <link href="http://mizzy.org/blog/2013/03/11/1/" />
    <updated>2013-03-11T22:28:50+09:00</updated>
    <id>http://mizzy.org/blog/2013/03/11/1/</id>
    <content type="html"><![CDATA[
<p><a href="http://www.vagrantup.com/">Vagrant</a> の base box をつくるためのツールとして <a href="https://github.com/jedi4ever/veewee">VeeWee</a> があって、これはこれで素晴らしいツールなんだけど、VeeWee は裏で ISO イメージをダウンロードしたり、インストーラを走らせたりで、時間もかかるし大げさな感じがするので、もっと簡略化できないか、ってことでやってみた。</p>

<p><a href="/blog/2013/02/24/1/">最小手順のVMイメージの作り方</a> で紹介したシェルスクリプトで作成した VM イメージに対して、以下のようにコマンドを実行するだけで、package.box ができあがる。</p>

<pre><code class="text"># VBoxManage convertfromraw --format vmdk /tmp/sl63.img /tmp/sl63.vmdk
# VBoxManage createvm --name SL6.3-x86_64 --register
# VBoxManage modifyvm SL6.3-x86_64 --memory 512 --acpi on --nic1 nat
# VBoxManage storagectl SL6.3-x86_64 --name &quot;IDE Controller&quot; --add ide
# VBoxManage modifyvm SL6.3-x86_64 --hda /tmp/sl63.vmdk
# vagrant package --base SL6.3-x86_64
</code></pre>

<p>できあがった package.box に対して以下のようにすれば、VM が起動する。</p>

<pre><code class="text">$ vagrant box add sl63-x86_64 package.box
$ vagrant init sl63-x86_64
$ vagrant up
</code></pre>

<p>ただし、<a href="http://docs-v1.vagrantup.com/v1/docs/base_boxes.html">Vagrant Documentation - Documentation - Base Boxes</a> にあるような、vagrant ユーザの作成とか、鍵の設定なんかはしてないため、<code>vagrant ssh</code> ではログインできないので、<code>ssh root@localhost -p 2222</code> で、パスワードは root でログインする。</p>

<p>この辺の設定もシェルスクリプトに組み込んじゃえばいいんだろうけど、まずは base box を簡単に作れるかどうかだけ確かめたかったので、今日はここまで。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[最小手順のVMイメージの作り方（LVM 編）]]></title>
    <link href="http://mizzy.org/blog/2013/02/24/2/" />
    <updated>2013-02-24T22:53:17+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/24/2/</id>
    <content type="html"><![CDATA[
<p>開発や検証で利用する VM は、最初はディスクサイズを小さくして、後から必要に応じて大きくする、といったことをよくやるので、<a href="/blog/2013/02/24/1/">最小手順のVMイメージの作り方</a> のスクリプトを、/ と swap を LVM にするように変えてみた。</p>

<div><script src='https://gist.github.com/5023926.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>

<p>あとはディストリビューションを選択できるようにとか、指定したホスト名を設定する、とかもやりたいけど、シェルスクリプトは大きくなってくるとメンテナンス厳しいので、Ruby で書き直す。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[最小手順のVMイメージの作り方]]></title>
    <link href="http://mizzy.org/blog/2013/02/24/1/" />
    <updated>2013-02-24T12:29:37+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/24/1/</id>
    <content type="html"><![CDATA[
<p>先日カヤックさんの社内勉強会にお邪魔して話してきた <a href="http://www.slideshare.net/mizzy/maglica-techkayac">Maglica</a> は、既に作成済みの VM イメージを元にクローンをつくって必要な設定（root パスワードの設定やネットワーク設定など）を行う、といったことが簡単にできるが、元の VM イメージつくるのがめんどくさいことには変わりなくて、ここをなんとかしたいなー、と常々思ってた。</p>

<p>VM イメージをつくる手段としては、RedHat 系の場合は virt-manager, virt-install, Cobbler/Koan などがあるが、どれもインストーラを実行する形式であり、kickstart を利用すれば自動化できるとは言え、kickstart は問題が起きた場合の調査がやりにくい。（自分が効果的なやり方知らないだけかもしれないけど。）</p>

<p>また、virt-install はオプション覚えられないし、Cobbler は初期のセットアップとか、profile の設定とかめんどくさい。</p>

<p>そもそも、インストーラを実行しなくても、しかるべきファイルが含まれたイメージをつくればいいだけなので、インストーラの実行はとても無駄に思える。</p>

<p>そこで、<a href="https://twitter.com/hansode">@hansode</a> さんの <a href="https://github.com/hansode/vmbuilder">vmbuilder</a> の存在を思い出して、これを使ってみようと思ったんだけど、単に使うだけじゃなく、具体的にどういったことをやってるのか理解したくて、ソースコードを読んで手順を追い、単純化したスクリプトに落とし込んでみたのがこれ。</p>

<div><script src='https://gist.github.com/5020611.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>

<p>以前 AMI(Amazon Machine Image) をつくった時と基本的には同じだけど、AMI では 1 イメージファイル 1 パーティションだったのが、この手順では 1 イメージファイルにパーティンションが 2 つあるのが大きな違い。kpartx をつかって パーティション毎に loopback device を割り当てるやり方をはじめて知ったので、とても参考になった。</p>

<p>スクリプトの解説も書こうかと思ったけど、ここまで単純化されてれば、あとは man なり Google なりで調べればわかるはずなのでやめた。</p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[すぐにハッブル宇宙望遠鏡撮影画像を見れるGoogle Chromeの拡張作った。]]></title>
    <link href="http://mizzy.org/blog/2013/02/11/1/" />
    <updated>2013-02-11T00:54:51+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/11/1/</id>
    <content type="html"><![CDATA[
<p>生きていればつらいことがある。
しかし、つらいからと言って簡単に投げ出す事は出来ないということも多い。</p>

<p>みなさんもつらまってる時、よくハッブル宇宙望遠鏡が撮影した画像を見ると思う。
当然のごとく僕もそうである。</p>

<p>最近つらい事がよくある。
そんな時のために、ハッブル宇宙望遠鏡撮影画像を素早く表示する必要があった。
なので、ハッブル宇宙望遠鏡撮影画像をすぐ見れるGoogle Chromeの拡張を作った。</p>

<p><a href="https://github.com/mizzy/chrome-hst-images">mizzy/chrome-hst-images - GitHub</a></p>

<p>「だめだ。もうやってらねー」って時は、空の tab を表示すればすぐハッブル宇宙望遠鏡撮影画像に会える。最高。結婚したい。</p>

<p><img src="/images/2013/02/chrome-hst-image.jpg"></p>

<h2>合わせて読みたい</h2>

<p><a href="http://blog.hisaichi5518.com/entry/2013/02/01/003820">すぐに吉高由里子を見れるGoogle Chromeの拡張作った。 - パルカワ2</a></p>

<p><a href="http://soh335.hatenablog.com/entry/2013/02/10/011039">すぐに宮崎あおいを見れるGoogle Chromeの拡張作った。- soh335 memo</a></p>

]]></content>
  </entry>

  <entry>
    <title type="html"><![CDATA[MHA for MySQL の概要]]></title>
    <link href="http://mizzy.org/blog/2013/02/06/1/" />
    <updated>2013-02-06T01:50:17+09:00</updated>
    <id>http://mizzy.org/blog/2013/02/06/1/</id>
    <content type="html"><![CDATA[
<p>MHA for MySQL の導入を検討していて、まずは社内の技術者向けに、MHA for MySQL の概要を伝えようと、主に <a href="http://code.google.com/p/mysql-master-ha/wiki/TableOfContents?tm=6">オフィシャルなドキュメント</a> からポイントを抜粋して社内向けの Wiki に書いてみた。本当なら、オフィシャルドキュメント全体に目を通してもらうのがいいんだけど、英語なので、はじめの一歩としては敷居が高く感じる人もいるだろう、ということで。</p>

<p>特に外に出してまずい情報があるわけでもないので、このブログでも曝しておきます。</p>

<hr>

<h2>MHA の概要</h2>

<p>MySQL エキスパートとして世界的にも著名な松信嘉範氏による、MySQL マスターの HA 化を行うためのツール。Perl 製。</p>

<p>最小限のダウンタイムで、データの不整合を防ぎつつ、マスターのフェイルオーバーを行う、というのが主な機能。</p>

<p>また、既に動作している MySQL に影響を与えることなく導入できる。</p>

<p>機能は大きくわけると以下の4つ。</p>

<ul>
<li>自動的なマスターの監視とフェイルオーバー

<ul>
<li>トータルダウンタイム10〜30秒ぐらいで切り替え可能</li>
</ul></li>
<li>手動によるマスターフェイルオーバー</li>
<li>自動的なマスターのフェイルオーバー（監視はしない）

<ul>
<li>監視を既存ソフトウェア（Pacemaker など）で行う場合に有用</li>
</ul></li>
<li>オンラインでマスターを別ホストに切り替え

<ul>
<li>マスターは動作してるが、ハードウェア的に怪しい兆候が見られるので、別ホストに事前に切り替えたい、などといった場合に有用</li>
<li>0.5〜2秒ほど書き込みブロックされるだけで切り替え可能</li>
</ul></li>
</ul>

<hr>

<h2>MHA のコンポーネントと動作概要</h2>

<p>マスターの監視とフェイルオーバーを MHA で自動的に行う場合の構成は以下のようになる。</p>

<p><img src="/images/2013/02/components_of_mha.png" title="Components of MHA" ></p>

<p>動作の流れは以下の通り。</p>

<ul>
<li>Manager が MySQL Master を監視</li>
<li>ダウンを検知すると、以下を実行

<ul>
<li>Master の最新のバイナリログを各 Slave に保存（可能であれば）</li>
<li>新マスターのリカバリ

<ul>
<li>スレーブのうちのひとつを新マスターにする</li>
<li>デフォルトでは一番新しいポジションまで進んでいるスレーブが選ばれる。設定で、このスレーブを次のマスターにする、といったこともできる。</li>
<li>新マスターにバイナリログの最新のポジションまでのデータを反映させる</li>
</ul></li>
<li>その他のスレーブのリカバリ 

<ul>
<li>バイナリログの最新のポジションまでのデータを反映させる</li>
<li>新マスターからレプリケーションを開始</li>
</ul></li>
</ul></li>
</ul>

<p>動作の詳細についてはオフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Sequences_of_MHA">Sequences of MHA</a> を参照。</p>

<hr>

<h2>Manager の拡張</h2>

<p>Manager の本体である masterha_manager には拡張ポイントがいくつかあり、設定ファイル中で以下のパラメータに対してスクリプトを指定することで、動作を拡張することができる。拡張ポイントは以下の通り。</p>

<ul>
<li>secondary_check_script</li>
<li>master_ip_failover_script</li>
<li>shutdown_script</li>
<li>report_script</li>
<li>init_conf_load_script</li>
<li>master_ip_online_change_script</li>
</ul>

<p>例えば、MHA 自体には、マスターがフェイルオーバーした時に VIP を付け替える機能はないが、以下のように VIP 付け替え用のスクリプトを設定ファイルで指定すると、フェイルオーバー時に VIP の付け替えをしてくれる。（スクリプトは自分で用意する。）</p>

<pre><code>master_ip_failover_script=/usr/local/sample/bin/master_ip_failover
</code></pre>

<p>詳細は <a href="http://code.google.com/p/mysql-master-ha/wiki/Architecture#Custom_Extensions">Custom Extensions</a> を参照。</p>

<hr>

<h2>Manager の設定例</h2>

<p>拡張スクリプトの設定など、必須ではないものも含む。</p>

<pre><code>[server default]
# mysql user and password
user=root
password=mysqlpass
# working directory on the manager
manager_workdir=/var/log/masterha/app1
# manager log file
manager_log=/var/log/masterha/app1/app1.log
# working directory on MySQL servers
remote_workdir=/var/log/masterha/app1
secondary_check_script= masterha_secondary_check -s remote_host1 -s remote_host2
ping_interval=3
master_ip_failover_script=/script/masterha/master_ip_failover
shutdown_script=/script/masterha/power_manager
report_script=/script/masterha/send_master_failover_mail

[server1]
hostname=host1
candidate_master=1 # 次のマスター候補

[server2]
hostname=host2

[server3]
hostname=host3
no_master=1 # このホストはマスターにしない
</code></pre>

<p>以下のように設定ファイルを指定して起動する。</p>

<pre><code class="text"># masterha_manager --conf=/etc/mha.cnf
</code></pre>

<p>設定パラメータ一覧はオフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Parameters">Parameters</a> を参照。</p>

<hr>

<h2>チュートリアル</h2>

<p>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Tutorial">Tutorial</a> を参照。</p>

<hr>

<h2>FAQ</h2>

<p><a href="http://code.google.com/p/mysql-master-ha/wiki/FAQ">FAQ</a> からいくつかピックアップ。超意訳。</p>

<ul>
<li>サポートされている MySQL のバージョンは？

<ul>
<li>5.0 以降がサポートされている。4.1 以下はサポート対象外。</li>
</ul></li>
<li>特定のスレーブホストをマスターに昇格したり、逆に特定のホストはマスターに昇格しない、といったことは可能か？

<ul>
<li><a href="http://code.google.com/p/mysql-master-ha/wiki/Parameters#candidate_master">cadidate_master</a> や <a href="http://code.google.com/p/mysql-master-ha/wiki/Parameters#no_master">no_master</a> といったパラメータで設定可能。</li>
</ul></li>
<li>インタラクティブ/手動でのフェイルオーバーは可能？

<ul>
<li><a href="http://code.google.com/p/mysql-master-ha/wiki/masterha_master_switch">masterha<em>master</em>switch</a> 使えばOK。</li>
</ul></li>
<li>MHA Manager 自体の冗長化は？

<ul>
<li>Pacemaker とか使っとけ。</li>
</ul></li>
</ul>

<hr>

<h2>よくあるエラーと対処方法</h2>

<p>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/TypicalErrors">TypicalErrors</a> を参照。</p>

<hr>

<h2>必要条件</h2>

<p>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/Requirements">Requirements</a> からいくつかピックアップして超意訳。</p>

<p>MHA を動作させるためには、以下の設定が必要。<a href="http://code.google.com/p/mysql-master-ha/wiki/masterha_manager">masterha_manager</a> や <a href="http://code.google.com/p/mysql-master-ha/wiki/masterha_check_repl">masterha_check_repl</a> 実行時に自動的にチェックしてくれる。</p>

<ul>
<li>root で各ノード間での SSH 公開鍵認証ができること

<ul>
<li>masterha_check_ssh コマンドでチェックできる</li>
</ul></li>
<li>MySQL 5.0 以降のみサポート</li>
<li>マスター昇格候補のサーバで log-bin が enable になってること </li>
<li>マスター昇格候補サーバにレプリケーション用ユーザが存在すること</li>
<li>ステートメントベースのレプリケーションでは LOAD DATA INFILE を使用してはいけない</li>
</ul>

<hr>

<h2>その他</h2>

<ul>
<li>Semi-Synchronous Replication と組み合わせることで、マスターのハードウェア故障等によるデータロスのリスクを抑えることができる

<ul>
<li>オフィシャルドキュメントの <a href="http://code.google.com/p/mysql-master-ha/wiki/UseCases#Using_together_with_Semi-Synchronous_Replication">Using together with Semi-Synchronous Replication</a> を参照</li>
<li>Semi-Synchronous Replication については <a href="http://nippondanji.blogspot.jp/2009/03/mysql-ha-semi-synchronous-replication.html">漢(オトコ)のコンピュータ道: 最強のMySQL HA化手法 - Semi-Synchronous Replication</a> が詳しい</li>
</ul></li>
</ul>

<hr>

<h2>参考 URL</h2>

<ul>
<li><a href="http://www.slideshare.net/matsunobu/mha-for-mysqldena">MHA for MySQL と DeNA のオープンソースの話</a></li>
<li><a href="http://code.google.com/p/mysql-master-ha/"> mysql-master-ha - MHA for MySQL: Master High Availability Manager and tools for MySQL - Google Project Hosting</a></li>
<li><a href="https://github.com/yoshinorim/mha4mysql-node">yoshinorim/mha4mysql-node on GitHub</a></li>
<li><a href="https://github.com/yoshinorim/mha4mysql-manager">yoshinorim/mha4mysql-manager on GitHub</a></li>
</ul>

]]></content>
  </entry>


</feed>
